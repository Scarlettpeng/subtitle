1
00:00:12,870 --> 00:00:13,470


2
00:00:14,400 --> 00:00:15,270
大家好

3
00:00:15,330 --> 00:00:19,410
今天我们开启TIDB业务开发与优化课程到第二讲

4
00:00:22,530 --> 00:00:24,630
首先我先自我介绍一下

5
00:00:24,690 --> 00:00:25,950
我是侯召墩

6
00:00:26,010 --> 00:00:28,440
隶属于全球技术服务事业部

7
00:00:28,560 --> 00:00:32,340
现在负责TIDB产品，部分用户的商业交付

8
00:00:32,700 --> 00:00:34,200
今天课程的内容

9
00:00:34,230 --> 00:00:37,290
也是结合用户的一些反馈和经验

10
00:00:37,380 --> 00:00:42,090
实际测试或迁移过程中遇到了一些场景和问题进行总结

11
00:00:42,210 --> 00:00:44,010
一块和大家探讨一下

12
00:00:47,130 --> 00:00:49,200
我们先来看一下今天课程的内容？

13
00:00:49,560 --> 00:00:50,520
我们知道

14
00:00:50,580 --> 00:00:53,280
TIDB作为一个通用的数据库产品

15
00:00:53,310 --> 00:00:55,980
必然要面临着技术选型和测试

16
00:00:56,160 --> 00:01:00,240
那就需要我们去了解数据库产品常见的压测

17
00:01:00,480 --> 00:01:01,710
工具和方式

18
00:01:01,980 --> 00:01:05,610
相信参与课程的同学对这一块应该也比较了解

19
00:01:06,000 --> 00:01:09,270
我们知道数据库的测试包含非常多的阶段

20
00:01:09,360 --> 00:01:10,260
纬度

21
00:01:10,265 --> 00:01:11,190
指标

22
00:01:11,340 --> 00:01:14,250
不同的测试阶段，我们需要关注不同的内容

23
00:01:14,400 --> 00:01:17,730
面临的挑战和投入也是有很大的区别

24
00:01:18,000 --> 00:01:20,880
而且TIDB默认设计为乐观锁

25
00:01:21,120 --> 00:01:25,020
在实际业务开发过程中也会遇到不少的问题

26
00:01:25,440 --> 00:01:27,150
今天这个课程的目的

27
00:01:27,180 --> 00:01:29,280
就是帮助大家理解

28
00:01:29,430 --> 00:01:31,920
TIDB上的这些最佳的一些实践

29
00:01:34,290 --> 00:01:35,700
我们先来看第一部分

30
00:01:35,970 --> 00:01:39,390
第一部分内容是TIDB锁的机制和应用适配

31
00:01:39,540 --> 00:01:41,250
为什么有这一节课呢？

32
00:01:41,640 --> 00:01:46,950
是因为TIDB别于传统市面数据库的第一个特性就是锁的差异

33
00:01:47,520 --> 00:01:52,380
很多人不清楚，乐观锁和悲观锁的区别以及它们的优缺点

34
00:01:52,620 --> 00:01:55,590
按照悲观锁的思维，使用TIDB

35
00:01:55,650 --> 00:01:59,100
多少少总会遇到一些困惑？所以

36
00:01:59,250 --> 00:02:03,990
今天最重要的话题之一，就是要理解TIDB锁的机制和使用

37
00:02:08,700 --> 00:02:09,300


38
00:02:10,410 --> 00:02:12,960
这节课的目学习目标呢？有六个

39
00:02:12,965 --> 00:02:13,800
首先

40
00:02:13,830 --> 00:02:17,190
第一点了解乐观锁和悲观锁的区别

41
00:02:17,400 --> 00:02:18,540
然后第二点

42
00:02:18,630 --> 00:02:22,560
了解为什么TIDB的初始化设计为乐观锁

43
00:02:22,740 --> 00:02:25,920
我们还要在未来的版本中兼容悲观锁

44
00:02:26,040 --> 00:02:28,080
开启两个锁共存的时代

45
00:02:28,230 --> 00:02:33,540
然后第三点，在现有的版本中，业务开发过程中，乐观锁的逻辑

46
00:02:34,080 --> 00:02:36,360
判断事物成功的条件是怎样的？

47
00:02:36,540 --> 00:02:37,440
第四点

48
00:02:37,500 --> 00:02:39,030
我们来看几个例子

49
00:02:39,210 --> 00:02:42,870
TIDB适用的场景以及不适应的场景的一些解决方案

50
00:02:43,020 --> 00:02:43,860
第五点

51
00:02:44,010 --> 00:02:49,260
结合主流的微服务框架Spring来探讨一下乐观所改造的一些例子？

52
00:02:49,620 --> 00:02:52,530
OK，我们开始今天的主题

53
00:02:56,550 --> 00:02:57,810
TIDB锁的类型

54
00:02:58,320 --> 00:03:03,630
分布式事物里面一般会采用某种锁的机制来处理事物的冲突

55
00:03:03,750 --> 00:03:06,060
从而提高并发或者吞吐

56
00:03:06,300 --> 00:03:10,650
从并发控制的角度，我们可以把锁分为乐观锁和悲观锁

57
00:03:10,890 --> 00:03:13,380
无论是悲观锁还是乐观锁

58
00:03:13,440 --> 00:03:15,330
其实都是定义出来的概念

59
00:03:15,450 --> 00:03:17,130
可以认为是一种思想

60
00:03:17,280 --> 00:03:19,860
我们简单解答一下，两个手的区别

61
00:03:20,880 --> 00:03:22,470
我们先来看悲观说

62
00:03:22,740 --> 00:03:27,660
悲观锁是现在传统数据库里面

63
00:03:27,665 --> 00:03:29,130
做默认的锁的类型

64
00:03:29,370 --> 00:03:32,730
就是悲观锁，对整个事物持悲观的态度

65
00:03:32,880 --> 00:03:34,710
认为冲突

66
00:03:34,890 --> 00:03:36,600
大概率会发生

67
00:03:36,605 --> 00:03:39,240
所以每次读写都要先上锁

68
00:03:39,330 --> 00:03:41,880
成功后才进行后续的一些操作

69
00:03:42,000 --> 00:03:44,220
而乐观锁则反其道了

70
00:03:44,490 --> 00:03:49,800
则认为冲突发生的概率比较小，只有在提交前

71
00:03:49,805 --> 00:03:51,210
才进行冲突的检测

72
00:03:51,270 --> 00:03:54,000
所以说，乐观锁适用于

73
00:03:54,480 --> 00:03:56,400
写比较少的一些场景会

74
00:03:56,880 --> 00:04:01,950
即使冲突真的很少发生的时候，这样也可以省去锁了一些开销

75
00:04:02,310 --> 00:04:03,930
加大系统的整个吞吐

76
00:04:04,230 --> 00:04:09,540
如果是多写的情况，那么一般在乐观锁的场景下会产生非常多的冲突

77
00:04:09,720 --> 00:04:12,540
就会导致上层应用，而不断的进行从事

78
00:04:12,570 --> 00:04:14,160
这样反倒是降低的性能

79
00:04:14,370 --> 00:04:18,420
所以说一般多写的场景下，悲观锁就相对比较合适

80
00:04:19,800 --> 00:04:21,780
那TIDB当时为什么

81
00:04:22,110 --> 00:04:23,580
会选择乐观锁呢？

82
00:04:23,610 --> 00:04:26,160
按照我的理解的话，简单来说有三点

83
00:04:26,310 --> 00:04:27,000
第一点

84
00:04:27,120 --> 00:04:32,430
乐观锁实现起来相对比较容易，尤其是在早期，当时研发人员比较少

85
00:04:32,910 --> 00:04:33,570


86
00:04:33,600 --> 00:04:34,560
第二天

87
00:04:34,770 --> 00:04:38,550
TIDB被设计之初，最主要的聚焦是互联网的一些场景

88
00:04:38,640 --> 00:04:43,200
最主要的解决的问题呢，也是MYSQL分布分表的替换方案

89
00:04:43,350 --> 00:04:47,970
当时的定位呢，是怎么样更高的提高整个集群的一个吞吐？

90
00:04:49,050 --> 00:04:49,890
第三点

91
00:04:50,040 --> 00:04:51,870
悲观锁在分布式

92
00:04:52,080 --> 00:04:54,480
系统里面实现相对比较复杂

93
00:04:55,170 --> 00:04:57,090
而且存在的死锁

94
00:04:57,180 --> 00:05:02,190
那么对比乐观锁呢？在某些场景下会也会遇到一些典型的性的问题

95
00:05:02,610 --> 00:05:05,310
所以当时TIDB就选择了乐观锁

96
00:05:05,820 --> 00:05:09,270
但是，随着传统行业客户的应用的接入

97
00:05:09,300 --> 00:05:11,400
悲观锁的呼声越来越高

98
00:05:11,430 --> 00:05:15,240
银行核心的业务需求，业务框架的改造成本

99
00:05:15,390 --> 00:05:18,630
开发人员的惯性开发思维等等各方面的因素

100
00:05:18,660 --> 00:05:21,690
就是我们提升了悲观锁的开发的优先级

101
00:05:21,780 --> 00:05:24,000
所以我们在3.0

102
00:05:25,350 --> 00:05:27,660
这个版本里面引入到悲观锁

103
00:05:28,050 --> 00:05:33,360
从左下方的这个配置项里面也可以人为的更改悲观锁的配置

104
00:05:33,480 --> 00:05:36,510
把整个悲观锁的这个参数配置给打开

105
00:05:36,600 --> 00:05:39,390
开启之后，默认就是悲观锁的行为

106
00:05:39,450 --> 00:05:44,040
但是这个悲观锁的功能在目前还在 PoC（测试）的这个阶段

107
00:05:44,045 --> 00:05:47,280
我们计划在4.0版本面的正式GA

108
00:05:48,420 --> 00:05:51,960
另外看看右下方的这个例子

109
00:05:51,965 --> 00:05:54,900
我们其实还支持语句级别的悲观锁

110
00:05:54,905 --> 00:05:57,990
可以通过配置hint的方式来使用悲观锁

111
00:05:58,200 --> 00:06:02,400
所以说在未来，TIDB将实现乐观锁和悲观锁并传

112
00:06:07,770 --> 00:06:11,400
刚才我也简单地体现了，为什么选择乐观锁

113
00:06:11,460 --> 00:06:15,180
这个地方也对当前TIDB锁机制做了简单的总结

114
00:06:15,330 --> 00:06:16,320


115
00:06:16,470 --> 00:06:19,140
乐观锁通常适用于大规模分布式节点的分布式处理系统


116
00:06:19,200 --> 00:06:22,350
而且是锁冲突不多的场景，如果你的写入模式是针对单行频繁更新的场景，那乐观锁其实是不适用的。
处理系统，而且是锁冲突不多的场景

117
00:06:22,530 --> 00:06:26,790
如果你的写入模式是针对单行数据频繁更新的场景

118
00:06:26,910 --> 00:06:29,190
那你乐观锁其实是不适用的

119
00:06:29,340 --> 00:06:34,650
并且，乐观锁的实现更加简单，也不会每次操作都带来锁的开销

120
00:06:34,770 --> 00:06:36,810
对性能也有非常大的好处，也可以有效的避免死锁。在所以也适用于
对性能也有非常大的好处

121
00:06:36,900 --> 00:06:39,510
也可以有效的避免死锁，所以

122
00:06:40,110 --> 00:06:41,340
也适用于

123
00:06:41,400 --> 00:06:43,860
互联网快速发展对高吞吐的场景

124
00:06:43,980 --> 00:06:44,850
那对比

125
00:06:44,970 --> 00:06:48,360
悲观锁，乐观锁同样也暴露出来了很多的问题


126
00:06:48,390 --> 00:06:52,980
常见的开发框架不友好，需要结合锁的机制

127
00:06:53,040 --> 00:06:55,110
来进行调试和验证

128
00:06:55,200 --> 00:06:56,340
业务的逻辑

129
00:06:56,460 --> 00:06:57,630


130
00:06:58,080 --> 00:07:00,150
业务场景本身需要悲观事务等等

131
00:07:00,360 --> 00:07:03,930
这是现阶段TIDB，存在的一个问题

132
00:07:04,110 --> 00:07:06,090
也是必须要解决的一个问题

133
00:07:10,140 --> 00:07:11,550
我们来看一段代码

134
00:07:11,700 --> 00:07:14,610
这段代码相信做开发的同学比较熟悉

135
00:07:14,760 --> 00:07:17,100
Spring里面声明了注解式

136
00:07:17,105 --> 00:07:22,410
按照传统数据库的思维，通过啊，affectrows结果来判断事务成功是没有问题的。


137
00:07:22,415 --> 00:07:23,310
没有问题的

138
00:07:23,520 --> 00:07:25,080
但在乐观锁里面

139
00:07:25,230 --> 00:07:29,400
是在事务提交的阶段，才可以判断事物的成功

140
00:07:29,490 --> 00:07:32,880
你虽然获取了result的结果是大于零的

141
00:07:32,910 --> 00:07:35,970
但是你的事物最后不一定提交成功

142
00:07:36,120 --> 00:07:36,990
举个例子

143
00:07:37,080 --> 00:07:39,630
假设你有十个用户去并发

144
00:07:39,720 --> 00:07:41,400
执行如下代码

145
00:07:41,460 --> 00:07:42,270
首先

146
00:07:42,420 --> 00:07:45,180
对test的表加了select for update的锁

147
00:07:45,300 --> 00:07:48,030
然后去并发的更新其中的一行

148
00:07:48,150 --> 00:07:49,200


149
00:07:49,205 --> 00:07:53,880
应为各个用户的操作在commit的阶段之前是相互不影响

150
00:07:53,885 --> 00:07:58,200
所以可能会出现多个用户的result的结果为一的情况

151
00:07:59,850 --> 00:08:03,600
因为select for update也是在提交的时候进行逻辑的判断

152
00:08:03,630 --> 00:08:08,940
所以除了用result大于零这个条件判断之外，还需要补获乐观锁冲突的异常

153
00:08:09,630 --> 00:08:12,000
那么正确的判断应该怎么做呢？

154
00:08:12,060 --> 00:08:13,530
我们看右侧的代码

155
00:08:17,730 --> 00:08:21,210
首先，我们需要先关闭注解事物改为显示声明

156
00:08:21,215 --> 00:08:22,530
这个时候的第一步

157
00:08:22,590 --> 00:08:27,030
来开启事物，相对test表进行select for update 加锁

158
00:08:27,210 --> 00:08:28,020
第二步

159
00:08:28,200 --> 00:08:30,450
去更新对应行的值

160
00:08:30,570 --> 00:08:32,550
第三步进行commit

161
00:08:32,555 --> 00:08:33,180
注意

162
00:08:33,540 --> 00:08:35,340
一并捕获Commit的异常

163
00:08:36,660 --> 00:08:41,970
10个用户同时去加select for update的锁场景，有可能会出现

164
00:08:42,420 --> 00:08:47,730
select for update因为时间误差问题而锁定这行的时候，实际上已经可能被其他用户更新完成

165
00:08:47,735 --> 00:08:48,510


166
00:08:48,570 --> 00:08:51,420
所以这部分用户出现了一个现象就是

167
00:08:51,425 --> 00:08:56,010
执行Commit的也成功了，但是affecta rows有0的情况

168
00:08:56,550 --> 00:09:01,860
这部分用户是不会抛出异常的，所以我们还要通过affecta rows大于零的判断

169
00:09:01,865 --> 00:09:04,830
来到这一部分用户来进行重试

170
00:09:05,580 --> 00:09:07,560
这一点是需要大家特别注意的

171
00:09:09,510 --> 00:09:11,670
OK，那我们总结一下

172
00:09:12,870 --> 00:09:13,590


173
00:09:13,595 --> 00:09:18,900
第一点，在乐观锁里面啊，affect rows其实是不可信的，SQL返回的结果也是不可信

174
00:09:18,905 --> 00:09:21,450
需要校验事务提交请求的返回值

175
00:09:21,570 --> 00:09:22,380
第二点

176
00:09:22,500 --> 00:09:25,770
乐观锁应尽量避免冲突的业务场景

177
00:09:25,830 --> 00:09:27,330
通过业务来解决问题

178
00:09:27,420 --> 00:09:30,150
而不要让数据库来不断的进行重试

179
00:09:30,210 --> 00:09:33,510
我们在后面会有一些例子或者是场景的一些说明

180
00:09:33,630 --> 00:09:34,500
第三点

181
00:09:34,650 --> 00:09:37,950
可以通过调整参数来减少重试的次数

182
00:09:38,100 --> 00:09:40,290
现在十个用户去并发的

183
00:09:40,295 --> 00:09:44,130
执行更新同一行，事物冲突在TIDB内部的

184
00:09:44,135 --> 00:09:45,810
乐观锁默认会

185
00:09:45,960 --> 00:09:47,220
重试的十次

186
00:09:47,310 --> 00:09:52,620
而应用侧如果有从事的机制的话，那对整个资源的消耗和性能

187
00:09:53,130 --> 00:09:54,840
会带来非常大的一些影响

188
00:09:55,200 --> 00:09:55,980
第四点

189
00:09:56,010 --> 00:09:58,650
一定要捕获数据库提交请求的异常

190
00:09:58,770 --> 00:10:00,810
进行业务重试或者处理

191
00:10:00,930 --> 00:10:06,240
这一点其实不区分乐观锁和悲观锁，所有的数据库提交请求的异常

192
00:10:06,245 --> 00:10:09,300
业务一般都会有从事或者熔断的一些机制

193
00:10:09,720 --> 00:10:11,040
上面这部分呢？

194
00:10:11,100 --> 00:10:14,100
还是需要我们业务开发的同事特别

195
00:10:14,160 --> 00:10:14,850
关注

196
00:10:18,180 --> 00:10:21,930
现实中有很多客户问到计数器秒杀的场景

197
00:10:21,990 --> 00:10:23,880
在TIDB里面怎么实现的

198
00:10:24,060 --> 00:10:27,540
采用传统的select for update来进行加锁

199
00:10:27,660 --> 00:10:30,240
是的，测试的结果是性能好差


200
00:10:30,270 --> 00:10:32,760
乐观锁天然不适用于这种场景

201
00:10:32,880 --> 00:10:36,840
在这儿建议大家在遇到技术性秒杀这类场景的时候

202
00:10:36,930 --> 00:10:40,200
可以把这块功能上上移到缓存

203
00:10:40,440 --> 00:10:41,700
里面来进行处理

204
00:10:41,820 --> 00:10:43,770
通用的方案就是通过

205
00:10:44,010 --> 00:10:46,710
例如，在redis codis

206
00:10:46,715 --> 00:10:48,690
里面来 etcd 实现分布式锁


207
00:10:49,020 --> 00:10:50,460
分布式锁的实现

208
00:10:50,610 --> 00:10:53,790
过程其实是网络上也有比较成熟的一些案例

209
00:10:53,795 --> 00:10:57,300
这个地方我就不做过多的介绍，大家可以自行百度

210
00:10:57,360 --> 00:10:59,670
这个地方我结合一个客户的例子

211
00:10:59,730 --> 00:11:02,310
来分享一下客户的一个处理思路

212
00:11:04,200 --> 00:11:07,500
这个应用场景的是商品变价处理

213
00:11:07,620 --> 00:11:09,600
有一张商品的一张明细表

214
00:11:10,140 --> 00:11:15,270
买家卖家和平台都会操作这张表，其实行为非常的频繁

215
00:11:15,600 --> 00:11:17,070
假设某一事件

216
00:11:17,400 --> 00:11:22,710
买家变价，平台修改，用户下单三个行为同时发生，


217
00:11:22,715 --> 00:11:24,810
那三者之间的冲突怎么去解决呢？

218
00:11:24,960 --> 00:11:30,270
客户就采用了通过分布式锁的机制，让三个操作执行之前都去 etcd


219
00:11:30,275 --> 00:11:32,670
里面抢占商品号维度的 key


220
00:11:32,940 --> 00:11:36,210
操作完成之后来进行unlock的方式来进行处理

221
00:11:36,660 --> 00:11:41,490
选择功能是基于ETCD来实现的，暴露lock的接口给业务方

222
00:11:41,495 --> 00:11:46,800
那么，业务方需要修改他们的业务逻辑，去轮询的watch锁的一些通知，然后

223
00:11:46,805 --> 00:11:50,550
根据锁的一些通知来进行相应的一些规则的判断

224
00:11:50,580 --> 00:11:54,030
通过锁超时的机制来处理锁的一些异常

225
00:11:54,870 --> 00:11:57,570
这是一种非常简单且高效的处理思路

226
00:11:57,630 --> 00:12:01,710
我们看一下这个客户来处理这个场景的一些特点

227
00:12:02,070 --> 00:12:04,320
这个场景的，首先他没有

228
00:12:04,800 --> 00:12:10,110
当前读的一些需求也没有用到for update，更多的是为了减少事物

229
00:12:10,440 --> 00:12:11,670
冲突的重试

230
00:12:11,940 --> 00:12:14,370
因为重试的成本还是比较高的

231
00:12:15,510 --> 00:12:19,140
而且它是非常细粒度的锁，类似商品订单

232
00:12:19,200 --> 00:12:22,230
会出现竞争者，竞争者的数量是有限的

233
00:12:22,560 --> 00:12:24,120
对于单行来说

234
00:12:24,210 --> 00:12:25,500
触发修改的

235
00:12:25,530 --> 00:12:27,150
行为其实就三个

236
00:12:27,180 --> 00:12:32,490
所以说死锁的力度也非常短，而且锁得行为发生在下单的瞬间或修改的瞬间

237
00:12:33,690 --> 00:12:39,000
正是因为力度较小，所以异常的情况的超时解锁是可以接受的


238
00:12:40,200 --> 00:12:43,650
最后一点呢，就是没有嵌套加锁的场景

239
00:12:43,740 --> 00:12:45,540
所以当遇到类似

240
00:12:45,840 --> 00:12:48,960
秒杀或者计数加锁的时候可以思考一下

241
00:12:48,965 --> 00:12:53,100
是不是可以通过数据库之外的一些角度或者方式方法来进行处理？

242
00:12:53,280 --> 00:12:56,760
尽量能够低成本或者低风险的来去解决这个问题

243
00:13:00,630 --> 00:13:03,780
下面我们来看一个乐观说改造的一个案例

244
00:13:03,900 --> 00:13:07,470
这个案例是上面例子的一个延伸，也是真实发生的

245
00:13:07,560 --> 00:13:11,010
当然，它可以结合分布式锁的方案来解决

246
00:13:11,070 --> 00:13:16,380
单独把这块代码拿出来让大家看一下，从数据库开发的角度来加深一下印象

247
00:13:17,190 --> 00:13:17,970


248
00:13:18,180 --> 00:13:21,570
这个场景呢？是保险公司业务

249
00:13:21,600 --> 00:13:26,910
需要对抢购人员进行编号的配方，每个人的编号是唯一的

250
00:13:27,270 --> 00:13:29,700
按照逻辑，我们出现了一张

251
00:13:30,810 --> 00:13:32,310
两个字段的一个表

252
00:13:32,400 --> 00:13:36,960
包括name和money两个字段，我们初始化插入了一条数据

253
00:13:37,140 --> 00:13:41,040
这个地方用money那其实不太合适，其实用weath更好

254
00:13:41,045 --> 00:13:42,420
不过，三简单的理解

255
00:13:43,020 --> 00:13:45,960
整个取号的业务逻辑可以简单地抽象为

256
00:13:46,710 --> 00:13:51,000
事务开启，然后对该行加for update的锁

257
00:13:51,005 --> 00:13:54,480
锁定该行，然后去执行money加一的操作

258
00:13:54,510 --> 00:13:58,650
如果money加一更新成功，则定义为编号配发成功

259
00:14:03,360 --> 00:14:03,960


260
00:14:04,800 --> 00:14:07,260
我们先来看一下mysql里面的行为

261
00:14:07,500 --> 00:14:11,760
假设是10并发执行update 

262
00:14:11,790 --> 00:14:13,290
并发更新同一行

263
00:14:13,380 --> 00:14:18,690
悲观锁的场景依赖于事物之间的锁定，可以做到串行执行，所以

264
00:14:18,695 --> 00:14:21,330
悲观锁判断成功的依据也非常明显

265
00:14:21,360 --> 00:14:24,840
应用只需要判断 affect rows 大于零


266
00:14:24,845 --> 00:14:27,180
即可释放上游 redis 对应的锁

267
00:14:27,360 --> 00:14:32,670
那么Mysql的结果也非常明显，最终的结果会是一个成功，九个返回失败

268
00:14:33,270 --> 00:14:36,090
这个代码其实和上面一样的，这个地方我

269
00:14:36,300 --> 00:14:37,710
其实没有什么好说的

270
00:14:39,990 --> 00:14:43,020
我们再来看一下，乐观所里面的预期行为

271
00:14:43,320 --> 00:14:46,080
因为造成冲突的那些SQL，其实

272
00:14:46,290 --> 00:14:48,240
都会执行update的语句

273
00:14:48,360 --> 00:14:51,540
也可能都会返回，影响到一条

274
00:14:51,720 --> 00:14:53,370
此时还没有commit

275
00:14:53,490 --> 00:14:55,080
为什么是可能呢？

276
00:14:55,110 --> 00:14:57,570
假设四个线程起了冲突

277
00:14:57,690 --> 00:15:00,240
程序中看到的四个线程

278
00:15:00,330 --> 00:15:02,070
返回是影响了一行

279
00:15:02,100 --> 00:15:03,810
其他没有冲突的SQL

280
00:15:03,960 --> 00:15:05,520
到时候，因为没有

281
00:15:05,640 --> 00:15:10,950
money唯一的字段了，所以剩余的六个线程返回了

282
00:15:11,070 --> 00:15:12,240
影响的0行

283
00:15:12,300 --> 00:15:13,830
这是需要特别注意的

284
00:15:15,300 --> 00:15:18,150
另外，十个并发实际只会

285
00:15:18,155 --> 00:15:21,900
有一个结果，真正的执行commit的，且commit成功

286
00:15:22,050 --> 00:15:27,360
而且乐观锁内部重试的affect row的值是拿不到的

287
00:15:27,930 --> 00:15:28,680
所以

288
00:15:28,740 --> 00:15:30,210
乐观锁在这个

289
00:15:30,390 --> 00:15:33,330
场景里面正确的事物的判断逻辑

290
00:15:33,420 --> 00:15:35,610
需要依赖返回的行数

291
00:15:35,670 --> 00:15:40,800
和事物成功失败两个判断条件来确定更新是否成功

292
00:15:40,860 --> 00:15:43,470
这一点需要我们开发者特别注意

293
00:15:46,050 --> 00:15:51,360
说了这么多，我们来看一下应用开发结合，乐观所集中改造的方式

294
00:15:51,780 --> 00:15:52,560
第一种

295
00:15:52,620 --> 00:15:54,510
其实也大概明确了

296
00:15:54,630 --> 00:15:57,780
通过显示声明事物的方式进行改造

297
00:15:57,900 --> 00:16:01,560
关键的点是，首先要捕获commit的成功和失败

298
00:16:01,620 --> 00:16:04,980
如果的commit失败，只代表事物的失败

299
00:16:05,250 --> 00:16:07,290
属于数据库提交异常

300
00:16:07,470 --> 00:16:11,550
如果commit成功，还需要判断返回行数

301
00:16:11,640 --> 00:16:14,550
是否大于零，也就是affect row

302
00:16:14,640 --> 00:16:15,570
如果

303
00:16:15,600 --> 00:16:18,900
大于零，这才是符合预期的编号

304
00:16:19,350 --> 00:16:24,660
其他返回行数，这是没有抢锁成功的现象，需要应用继续处理

305
00:16:24,665 --> 00:16:26,040
触发专业的重试逻辑

306
00:16:29,760 --> 00:16:35,070
那么这一块的话，然后我们是不是还有一些其他的优化思路或者优化手段的？

307
00:16:35,310 --> 00:16:38,490
上面的这个案例呢？我们需要深度的思考一下

308
00:16:38,610 --> 00:16:43,680
TIDB开启一个start_ts开始，然后到commit_ts结束

309
00:16:43,830 --> 00:16:46,890
因为到commit，其实本身就是CAS

310
00:16:47,220 --> 00:16:52,530
如果我们直接通过使来for update来做判断，然后通过业务代码来检测

311
00:16:52,535 --> 00:16:53,310


312
00:16:53,790 --> 00:16:55,050
是不锁定目标行

313
00:16:55,200 --> 00:16:56,550
最后根据affrect row

314
00:16:56,580 --> 00:16:58,440


315
00:16:58,445 --> 00:17:02,010
是不是可行的呢？那么我们来看看下面的这一段代码

316
00:17:05,700 --> 00:17:09,900
首先，我们通过声明注解事物的方式，先声明事物

317
00:17:10,140 --> 00:17:12,270
然后定义update table

318
00:17:12,390 --> 00:17:13,770
这个方法

319
00:17:13,800 --> 00:17:15,990
这个方法需要去

320
00:17:16,110 --> 00:17:18,030


321
00:17:18,270 --> 00:17:20,220
设置一个异常的捕获逻辑

322
00:17:20,370 --> 00:17:22,020
那么第三步呢，就是

323
00:17:22,260 --> 00:17:25,890
就要加一个select for update的满足条件行的锁


324
00:17:26,400 --> 00:17:31,710
然后第四部呢，就是要结合业务的具体情况来判断 select for update 的行，


325
00:17:31,715 --> 00:17:34,980
是否满足整个的业务逻辑？

326
00:17:35,070 --> 00:17:36,210
最后就是

327
00:17:37,320 --> 00:17:42,630
如果满足有逻辑的话，然后就去执行最后的update，然后也就是相当于

328
00:17:42,635 --> 00:17:45,360
这个update money的这个结果加一

329
00:17:46,350 --> 00:17:48,240
这是整个的方法

330
00:17:48,270 --> 00:17:53,010
那么，通过调用上面的这个update的这个方法可以直接捕获这个异常

331
00:17:53,070 --> 00:17:58,380
这种方式的好处就是不需要显示的去声明事务而依赖与框架本身的事物的

332
00:17:58,385 --> 00:17:59,220
处理机制

333
00:17:59,225 --> 00:18:03,570
所以说，这种方法的话，然后也建议大家在实际场景中

334
00:18:03,575 --> 00:18:05,340
推荐使用该方法

335
00:18:10,050 --> 00:18:10,650


336
00:18:13,170 --> 00:18:18,480
上面修改方式的代码呢？其实比较多，如果喜欢较少

337
00:18:18,485 --> 00:18:21,780
代码的话，可以考虑spring retry的这个模块


338
00:18:22,050 --> 00:18:25,740
依靠框架自己的从事机制来处理事务的冲突

339
00:18:25,980 --> 00:18:28,830
这个注解呢，大家可以看一下


340
00:18:28,860 --> 00:18:34,170
其实实际调用的时候会会帮助我们自动捕获sql的exception

341
00:18:34,680 --> 00:18:36,060
并且自动重试

342
00:18:36,180 --> 00:18:38,190
我们来看一下它的声明的方式

343
00:18:38,370 --> 00:18:43,680
然后通过这声明了这个有retrable，然后指定了这个value的这个方法

344
00:18:43,890 --> 00:18:49,200
这个方法的话，只有抛出指定异常的时候才会进行重试大家需要注意一下

345
00:18:49,350 --> 00:18:50,520


346
00:18:50,550 --> 00:18:55,680
max其实是从事的次数，然后这个地方是从事设置为两次

347
00:18:55,830 --> 00:18:58,500
backoff是重试等待的策略

348
00:18:58,505 --> 00:19:02,070
这个地方的话是5000毫秒

349
00:19:03,030 --> 00:19:08,340
然后有兴趣的同学可以去查一下是不是spring retry这个模块？

350
00:19:08,430 --> 00:19:10,860
然后网上其实有比较多的一些案例

351
00:19:11,190 --> 00:19:14,190
然后那个不仅仅是在乐观锁里面

352
00:19:14,195 --> 00:19:18,360
悲观事务里面也有很多的一些案例，为了提高性能

353
00:19:18,365 --> 00:19:19,950
然后来采用这个模块

354
00:19:21,510 --> 00:19:25,170
OK，我们看一下第一章的一些关键知识点

355
00:19:25,560 --> 00:19:27,660
TIDB默认的锁是什么锁？

356
00:19:27,840 --> 00:19:30,480
然后乐观锁和悲观锁的区别

357
00:19:30,485 --> 00:19:31,680
需要了解一下

358
00:19:31,740 --> 00:19:36,120
然后开发人员需要重点关注TIDB事物成功与否的判断逻辑

359
00:19:36,390 --> 00:19:39,960
尤其是结合Spring开发框架上面需要做的一些调整


360
00:19:40,050 --> 00:19:45,360
当然，我们也期望上开发的同事一点都不用更改，我们也一直在做这方面的努力

361
00:19:45,840 --> 00:19:47,610
然后应用直接适配即可

362
00:19:48,480 --> 00:19:51,990
但是到那一步呢，其实还是需要有一个过程

363
00:19:54,870 --> 00:20:00,180
OK，我们再回顾一下第一章的一个学习目标，看大家是不是已经完全的掌握了？

364
00:20:00,185 --> 00:20:01,050
我还理解

365
00:20:01,290 --> 00:20:06,600
然后第一点呢，就是现在是不是已经清楚地了解到这个乐观的和悲观锁的区别？

366
00:20:07,020 --> 00:20:08,040
然后第二点

367
00:20:08,160 --> 00:20:12,270
是不是已经了解了为什么TIDB原来锁的设计为乐观锁

368
00:20:12,420 --> 00:20:15,330
然后3.0里面为什么要实现悲观锁？

369
00:20:15,540 --> 00:20:20,760
现在有兴趣的同学呢？其实可以来进行3.0版本的

370
00:20:20,850 --> 00:20:22,770
悲观锁的一个poc


371
00:20:22,860 --> 00:20:27,780
然后我们现在其实某些行为的话，其实和Mysql还是有一些差别

372
00:20:27,960 --> 00:20:32,040
包括异常的一些报错，我们在4.0 ga里面

373
00:20:32,100 --> 00:20:34,080
尽量兼容MYSQl一些

374
00:20:34,170 --> 00:20:37,350
报错和场景

375
00:20:37,950 --> 00:20:42,090
然后第三点呢，其实是学习针对乐观锁，正确事物的

376
00:20:42,450 --> 00:20:43,770
判断方式

377
00:20:43,830 --> 00:20:49,140
上面也是通过了一些事例来告诉大家，整个事物的一些判断，判断的一些方法

378
00:20:49,145 --> 00:20:49,800


379
00:20:49,950 --> 00:20:54,510
然后第四点是了解TIDB在技术性秒杀场景的一些处理思路

380
00:20:54,780 --> 00:20:59,760
这一块的话，也是需要结合我们常见的一些分布式锁的一些机制

381
00:20:59,790 --> 00:21:04,140
比如说，利用于redis，ETCD等等的一些方式，可以百度一下

382
00:21:04,350 --> 00:21:07,680
然后第五点呢，就是熟悉tidb在spring

383
00:21:07,740 --> 00:21:12,180
框架下的的乐观锁的一些改造方式

384
00:21:13,170 --> 00:21:14,400
大概就这么五点

385
00:21:14,550 --> 00:21:19,860
第一章的内容还是比较重要，如果有什么意外疑问的话，还是希望大家

386
00:21:19,865 --> 00:21:21,510
一块总结和讨论一下

387
00:21:24,900 --> 00:21:27,450
我们开始第二章内容

388
00:21:27,660 --> 00:21:28,530
benchmack

389
00:21:28,980 --> 00:21:31,770
benchmack其实是一个非常笼统的概念

390
00:21:31,920 --> 00:21:34,530
我们做压测，基于什么样的一个背景？

391
00:21:34,650 --> 00:21:37,740
压制的目的是什么？测试有几种场景

392
00:21:37,860 --> 00:21:42,480
设施预期是什么？等等，这些方法论其实还是很重要

393
00:21:42,600 --> 00:21:46,080
所以第一部分我会简单地聊一下压测的一些方法论

394
00:21:46,320 --> 00:21:50,160
那么第二部分呢是在TIDB上要做一些测试

395
00:21:50,220 --> 00:21:52,980
需要满足一些硬性的指标和要求

396
00:21:53,130 --> 00:21:54,000
否则

397
00:21:54,300 --> 00:21:57,390
即便测试完成，某些数据也是没有意义的

398
00:21:57,750 --> 00:22:01,050
那么第三部分呢？针对常见的性能测试和工具

399
00:22:01,590 --> 00:22:06,630
做一个简单的说明后续大家的测试可以按照我提供的这个标准

400
00:22:07,890 --> 00:22:10,770
第四部分呢，其实是为扩展性测试

401
00:22:10,800 --> 00:22:13,500
扩展性其实是TIDB的一个强项

402
00:22:13,560 --> 00:22:16,710
里面要去平滑的测试，整个集群的一个扩展性

403
00:22:17,460 --> 00:22:18,150


404
00:22:18,180 --> 00:22:20,550
那么感兴趣的同学可以重点关注一下

405
00:22:20,610 --> 00:22:23,040
第五部分呢，实际上是业务压测

406
00:22:23,190 --> 00:22:27,450
业务压测的话，然后我们需要管关注哪些业务指标？

407
00:22:27,810 --> 00:22:28,950


408
00:22:29,010 --> 00:22:32,370
五个纬度来开始我们第二章的一个课程

409
00:22:35,040 --> 00:22:40,350
我们看一下我们第二章的一个学习目标，首先我们要需要了解

410
00:22:40,355 --> 00:22:41,550
benchmark一个作用

411
00:22:41,730 --> 00:22:47,040
然后跟根benchmark的这个作用呢？然后去了解一下benchmark

412
00:22:47,045 --> 00:22:49,170
整个基本测试的一个流程

413
00:22:49,470 --> 00:22:51,630
之后就是掌握基于

414
00:22:51,900 --> 00:22:54,570
TIDB的基准性能的测试要求

415
00:22:54,960 --> 00:22:59,370
结合要求和流程，学习常用的，benchmark的知识工具和方法

416
00:22:59,700 --> 00:23:02,850
最后就是了解业务压制的注意事项

417
00:23:04,230 --> 00:23:06,780
这些呢就是我们第二章

418
00:23:06,870 --> 00:23:08,640
的一个学习目标

419
00:23:09,150 --> 00:23:09,840
OK

420
00:23:11,100 --> 00:23:14,220
我们先看一下benchmark的概念定位

421
00:23:15,030 --> 00:23:20,280
benchmark就是这种测试，其实实际上是针对数据库系统设计的一种压力测试

422
00:23:20,430 --> 00:23:23,160
通常目标是为了掌握系统的行为

423
00:23:23,400 --> 00:23:28,230
简单的说，它是一种评估服务器和数据库资源能力的一种手段

424
00:23:28,470 --> 00:23:30,690
针对数据库我们今天测试

425
00:23:30,930 --> 00:23:32,820
定义为两个层面

426
00:23:33,000 --> 00:23:35,850
一个是基准测试，一个是压力测试

427
00:23:36,210 --> 00:23:40,050
基准测试可以理解为针对系统的一种压力测试

428
00:23:43,290 --> 00:23:48,600
基准测试，更多的是不关心又逻辑更加简单直接

429
00:23:48,605 --> 00:23:49,440
与测试

430
00:23:49,650 --> 00:23:52,050
提供的是基准的数据参考

431
00:23:52,200 --> 00:23:57,120
而压力测试一般是考虑业务的逻辑，面向的是真实的数据

432
00:23:58,020 --> 00:24:00,450
所以说，

433
00:24:00,630 --> 00:24:03,630
从整个测试的策略的角度上来看的

434
00:24:03,780 --> 00:24:04,650


435
00:24:04,860 --> 00:24:06,150
有这么两个方向

436
00:24:06,390 --> 00:24:08,850
第一个方向呢，就是立足于数据库产品

437
00:24:08,940 --> 00:24:12,420
一种是数据库产品呢？我们去进行单独的一些测试

438
00:24:12,690 --> 00:24:16,440
一个数据库产品的话，我们单独的测试一般会

439
00:24:16,560 --> 00:24:17,370
经历为

440
00:24:17,550 --> 00:24:18,840
功能测试

441
00:24:18,870 --> 00:24:24,180
然后那个基准性能测试，包括其他的周边的一些工具或者行为测试等等

442
00:24:24,510 --> 00:24:29,820
那么第二个层面还是应用的整体测试，应用的整体测试的话那么就面临的是？

443
00:24:29,825 --> 00:24:31,770
运用的一个兼容性测试和压力测试

444
00:24:33,600 --> 00:24:36,660
那么，整个测试的主要关注指标的有四个

445
00:24:36,840 --> 00:24:38,670
第一个呢，就是吞吐量

446
00:24:38,675 --> 00:24:43,320
吞吐量通常我们通过QPS或TPS来进行评估

447
00:24:43,410 --> 00:24:48,720
QPS和TPS其实就比较明确，就单位时间内处理的一些事务数

448
00:24:50,490 --> 00:24:54,720
这个指标呢？一直是经典数据库吞吐的一个判断的一个标准

449
00:24:54,960 --> 00:24:58,500
那第二个指标呢，实际上是响应时间或延迟

450
00:24:59,790 --> 00:25:03,450
响应时间或延迟，实际上是在我们在压测里面

451
00:25:03,720 --> 00:25:07,560
任务所需要整体时间和趋势的一个重要参考

452
00:25:07,710 --> 00:25:08,340


453
00:25:08,460 --> 00:25:12,150
这个这个这个指标呢？实际上在时延

454
00:25:12,155 --> 00:25:14,190
敏感性的业务上需要重点关注

455
00:25:14,700 --> 00:25:20,010
那么并发性呢？并发性其实按我理解的话，它是一种测试的一种属性

456
00:25:20,700 --> 00:25:24,300
分布式系统里面，其实与集群的资源有非常大的关系

457
00:25:24,480 --> 00:25:29,730
同时并发能力也会依赖于前两个指标吞吐量和响应时间

458
00:25:29,760 --> 00:25:31,350
比如说

459
00:25:31,470 --> 00:25:36,750
并发的加大可能会带来吞吐量的一个上升和响应时间的一个增高

460
00:25:36,810 --> 00:25:37,410
等等

461
00:25:38,100 --> 00:25:40,350
那么最后一点呢，实际上是扩展性

462
00:25:40,440 --> 00:25:43,020
扩展性实际上是TIDB的一个强项


463
00:25:43,025 --> 00:25:48,330
我们可以通过固定计算资源或者存储资源来验证TIDB群的整个扩展是不是线性的

464
00:25:51,150 --> 00:25:55,140
了解到测试的关键指标，我们要做的一项benchmark

465
00:25:55,200 --> 00:25:57,420
基本流程可以分为四个阶段

466
00:25:57,540 --> 00:26:02,850
我们从原厂和用户的角度来复习一下，需要在每个阶段关注的内容有哪些？

467
00:26:03,540 --> 00:26:04,470
首先

468
00:26:04,650 --> 00:26:07,710
做测试之前要明确我们的测试目标

469
00:26:07,800 --> 00:26:09,540
我们的测试需求是什么？

470
00:26:09,690 --> 00:26:11,160
要做哪些方向？

471
00:26:11,190 --> 00:26:12,750
哪些维度的测试？

472
00:26:12,930 --> 00:26:14,250
这是的预期是什么？

473
00:26:14,490 --> 00:26:19,620
这是周期有多长都是我们作为一个项目初始需要考虑的东西

474
00:26:19,890 --> 00:26:21,780
从而形成我们的是什么目标？

475
00:26:22,020 --> 00:26:27,330
作为原厂，我们更多的是参与评估整个测试需求是不是TIDB适合的场景？

476
00:26:27,690 --> 00:26:29,280
能否达到预期

477
00:26:29,520 --> 00:26:30,720
请问你的场景

478
00:26:30,870 --> 00:26:32,520
其他客户是怎么测试的？

479
00:26:32,700 --> 00:26:35,010
我们更多的是提供信息和意见

480
00:26:35,100 --> 00:26:37,770
丰富和优化一个你的整个测试方案

481
00:26:39,030 --> 00:26:40,020
那有了

482
00:26:40,290 --> 00:26:42,480
确定测试目标之后呢？

483
00:26:42,510 --> 00:26:44,550
需要考虑我们的测试资源

484
00:26:44,730 --> 00:26:47,130
现有的硬件是否满足这个要求？

485
00:26:47,340 --> 00:26:48,810
测试周期有多长？

486
00:26:48,870 --> 00:26:50,790
这是用力细化等等

487
00:26:51,240 --> 00:26:54,180
我方配合提供测试相关的一些文档

488
00:26:54,240 --> 00:26:57,750
评估你所申请的这个硬件资源

489
00:26:57,900 --> 00:27:00,930
是否满足你当前的所有的测试用力？

490
00:27:02,700 --> 00:27:07,290
确定测试目标和用力之后，那么测试过程就变得非常固定

491
00:27:07,650 --> 00:27:11,430
一般情况下，数据库产品会经过功能测试

492
00:27:11,490 --> 00:27:12,780
基准性能测试

493
00:27:12,870 --> 00:27:14,520
附加功能测试等等

494
00:27:14,850 --> 00:27:18,000
这一块大多数用户都有自己的测试方案和思路

495
00:27:18,540 --> 00:27:21,060
我方更多的是参与整个测试过程

496
00:27:21,510 --> 00:27:24,960
协助优化和分析整个集群的性能行经

497
00:27:25,200 --> 00:27:27,180
处理测试过程中的各种异常

498
00:27:27,900 --> 00:27:31,170
因为TIDB作为一个全新的数据库，分布式产品

499
00:27:31,440 --> 00:27:35,880
读取和写入流程，如果在你不了解整个产品原理的情况下

500
00:27:36,000 --> 00:27:39,480
直观地去获取一个测试结果其实是没有价值的

501
00:27:39,900 --> 00:27:44,460
如果测试不理想的情况下还是建议各位同学联系一下我们

502
00:27:44,580 --> 00:27:45,840
看一下整个

503
00:27:45,900 --> 00:27:48,060
测试是不是最优的一个结果？

504
00:27:49,560 --> 00:27:51,540
最后呢，其实是测试总结

505
00:27:51,780 --> 00:27:55,620
结合我们之前的测试来形成这个整个汇报方案

506
00:27:55,830 --> 00:28:01,140
我们更多的是确保您的整个方案是可预期的，您的每个

507
00:28:01,145 --> 00:28:02,910
测试用力都是有理有据

508
00:28:07,110 --> 00:28:09,300
TIDB作为一个分布式集群

509
00:28:09,330 --> 00:28:12,300
在进行benchmark有一些最基本的一些要求

510
00:28:12,450 --> 00:28:15,690
在之前的课程里，相信其他的讲师也是涉及到的

511
00:28:16,080 --> 00:28:17,970
首先是对测试系统的要求

512
00:28:18,030 --> 00:28:20,550
我们只支持redthat兼容的内核

513
00:28:20,670 --> 00:28:22,830
推荐7.3以上的一些版本

514
00:28:22,835 --> 00:28:24,420
其实有多方面的原因

515
00:28:24,990 --> 00:28:28,410
重要的一点就是我们在现有的生产环境中的集群

516
00:28:28,740 --> 00:28:32,160
其实全部都是基于7.3以上的版本进行安装部署的

517
00:28:32,490 --> 00:28:35,610
也是经过大量社区和商业客户的生产验证

518
00:28:36,090 --> 00:28:36,780
而且

519
00:28:36,900 --> 00:28:41,010
之前我们在7.3以下的版本上测试出很多的内核的bug

520
00:28:41,490 --> 00:28:46,380
并且有很多新的一些特性都是依赖于7.3以下的版本的系统内核

521
00:28:46,710 --> 00:28:49,560
所以说，无论是测试环境还是生产环节

522
00:28:49,740 --> 00:28:51,090
都建议大家

523
00:28:51,390 --> 00:28:53,310
是安装操作系统

524
00:28:53,490 --> 00:28:55,530
按照官方的要求来进行部署

525
00:28:55,710 --> 00:28:57,240
尽可能的去规避掉

526
00:28:57,330 --> 00:28:59,370
没有必要的一些风险

527
00:29:01,770 --> 00:29:04,890
那么第二个重要部分呢？就是对测试硬件的要求

528
00:29:05,460 --> 00:29:10,410
刚开始我们提到一项benchmark首先要明确测试目标和资源

529
00:29:10,590 --> 00:29:12,930
如果只做简单的功能性测试

530
00:29:13,050 --> 00:29:14,100
可以按照

531
00:29:14,220 --> 00:29:16,110
四节点的集群来进行部署

532
00:29:16,410 --> 00:29:17,160
具体的

533
00:29:17,165 --> 00:29:18,180
配置可以

534
00:29:18,360 --> 00:29:21,120
参考上面的这个测试环境的一个表格

535
00:29:21,540 --> 00:29:23,910
如果需要做复杂的性能测试

536
00:29:24,000 --> 00:29:26,310
那么有两项最基本的要求

537
00:29:26,640 --> 00:29:28,440
一下子就是ssd

538
00:29:28,680 --> 00:29:31,620
可以生产环境为pcre SSD

539
00:29:31,710 --> 00:29:32,970
为什么会选择pcre SSD？

540
00:29:33,780 --> 00:29:39,090
实际上是因为TIDB本身底层TIKV lm tree的

541
00:29:39,095 --> 00:29:41,010
这种架构所决定

542
00:29:41,190 --> 00:29:45,720
当数据量大时带compact的开销实际上是非常大的

543
00:29:46,650 --> 00:29:49,830
那么第二个点呢？这里的要求就是万兆网卡

544
00:29:50,340 --> 00:29:55,320
为什么需要万兆网卡？其实大家可以设想一下，如果是千兆网卡的话

545
00:29:55,350 --> 00:29:57,330
那么这个时候我们

546
00:29:57,450 --> 00:30:02,760
整个集群是底层是以region为单位来进行组合的，那么一个region的大小是96mb

547
00:30:02,765 --> 00:30:08,070
那么按照千兆环境的这个现有的网络同步一个

548
00:30:08,075 --> 00:30:10,800
region的话，就基本上把网络给打满了

549
00:30:10,950 --> 00:30:12,570
那么，整个集群怎么来？

550
00:30:13,200 --> 00:30:14,700
进行后续的测试呢？

551
00:30:16,020 --> 00:30:19,830
也是在那个社区中有非常多的客户的测试

552
00:30:20,070 --> 00:30:23,670
遇到了一些瓶颈，经过我们的排查，其实都是于

553
00:30:23,880 --> 00:30:26,790
没有满足这两项基本要求是有关系的

554
00:30:28,410 --> 00:30:33,720
一般我们做性能测试，建议线上的集群最小规模是

555
00:30:33,870 --> 00:30:36,690
九台，当然了从成本的

556
00:30:36,930 --> 00:30:40,890
考虑的话，TIDB PD某些情况下是可以混部的

557
00:30:41,400 --> 00:30:42,180
但是

558
00:30:42,270 --> 00:30:44,880
pd也是要求SSD

559
00:30:49,350 --> 00:30:54,660
功能测试这一块儿，我就不做过多的解说，因为作为一个标准的数据库产品

560
00:30:56,010 --> 00:31:01,320
官网确实有着非常详细的这个文档，大家可以参考设计中我们提供的一些测试用例

561
00:31:01,680 --> 00:31:02,670
来进行测试

562
00:31:02,970 --> 00:31:04,740
那么重点说一下性能测试

563
00:31:04,745 --> 00:31:06,210


564
00:31:06,750 --> 00:31:09,300
性能测试在TIDB上来讲的话一般


565
00:31:09,305 --> 00:31:10,950
可以分为四个大块

566
00:31:11,130 --> 00:31:13,020
那么第一块呢，就数据的导入

567
00:31:13,110 --> 00:31:15,450
第二个会呢，就是oltp的测试

568
00:31:15,510 --> 00:31:17,880
那么第三个呢就是olap

569
00:31:18,000 --> 00:31:20,010
第四块内容呢，就是扩展性测试

570
00:31:21,510 --> 00:31:23,700
那么我们就一块一块的内容看一下

571
00:31:24,480 --> 00:31:29,790
啊，首先是数据的导入的测试呢？一般情况下TIDB导入的都是

572
00:31:30,120 --> 00:31:32,370
mydumper的文件或者csv的文件

573
00:31:32,820 --> 00:31:35,460
然后我们有很多的导入的方式

574
00:31:35,580 --> 00:31:39,630
那么实际上最快的导致方式呢？是通过我们的物理导致工具来从

575
00:31:39,720 --> 00:31:41,400
底层直接进行导入

576
00:31:41,730 --> 00:31:43,260
这块需要注意的是

577
00:31:43,265 --> 00:31:46,410
物理导入的工具需要申请单独的物理机

578
00:31:46,980 --> 00:31:52,290
那么导入的速度呢？其实还是比较好量化的，那么也就提供多少G的文件

579
00:31:52,295 --> 00:31:56,970
然后导入的一个时间，通过这个指标来去判断导入的一个速度

580
00:31:58,320 --> 00:32:01,470
然后第二块内容呢？就是就是OLtp的测试

581
00:32:01,710 --> 00:32:04,830
OLtp的测试其实业内有两个测试标准

582
00:32:04,920 --> 00:32:06,210
一个是sysbench

583
00:32:06,270 --> 00:32:07,440
一个是tpcc

584
00:32:07,590 --> 00:32:09,570
sysbench的大家都比较熟悉

585
00:32:09,750 --> 00:32:12,390
测试的场景呢，也是比较简单

586
00:32:12,600 --> 00:32:13,830
我们也了解到

587
00:32:13,890 --> 00:32:16,470
sysbench其实涉及到表结构也是比较简单

588
00:32:16,980 --> 00:32:19,740
他是没有完整的一些处理事物

589
00:32:19,890 --> 00:32:21,210
事物处理的一些验证

590
00:32:21,390 --> 00:32:24,060
而这选择，其实tpcc正好具备

591
00:32:24,150 --> 00:32:26,010
所以说呢，在tpcc中

592
00:32:26,040 --> 00:32:27,480
我们还是能够

593
00:32:27,485 --> 00:32:32,790
通过他的一系列的测试能够体现出数据库所支持的一些数据的规模和事物的一个能力

594
00:32:34,980 --> 00:32:37,350
我们现在看第一部分sysbench

595
00:32:37,830 --> 00:32:38,730
那么

596
00:32:38,760 --> 00:32:44,070
sysbench对TIDB来讲的话，我们官方的建议是测试32张表

597
00:32:44,850 --> 00:32:46,500
1000万的一个数据

598
00:32:46,770 --> 00:32:50,730
当然数据量可以按照我们的测试可以更大

599
00:32:50,910 --> 00:32:53,700
越大越友好

600
00:32:53,850 --> 00:32:59,160
为什么呢？因为数据量越大，就意味着你的region数越多，因为region数越多呢，就是数据分布越均衡

601
00:32:59,165 --> 00:33:00,240


602
00:33:01,740 --> 00:33:04,410
sysbench测试的内容包括而

603
00:33:04,440 --> 00:33:05,490


604
00:33:05,580 --> 00:33:06,450


605
00:33:06,630 --> 00:33:08,880
五类属性 五类操作吧！

606
00:33:09,000 --> 00:33:11,670
point_select、read_only、update_index、read_write、write_only


607
00:33:11,760 --> 00:33:15,240

608
00:33:15,450 --> 00:33:19,590
那么，我们考核的指标呢，就是通常通过QPS TPS啊？

609
00:33:19,620 --> 00:33:21,360
平均延迟最大延迟

610
00:33:21,540 --> 00:33:22,380
点 99 等


611
00:33:22,740 --> 00:33:24,990
那么，这个地方需要注意的就是

612
00:33:25,050 --> 00:33:27,300
我们在sysbench时候

613
00:33:27,360 --> 00:33:30,900
整个集群会部署多台开的TIDB

614
00:33:31,020 --> 00:33:32,040
这个时候呢？

615
00:33:32,580 --> 00:33:37,890
多台TIDB需要同步启用多个sysbench起来进行数据的压测，而不是一个

616
00:33:38,490 --> 00:33:39,810
这个地方需要大家主意

617
00:33:39,870 --> 00:33:43,980
或者需要提供一个负载均衡的代理来对接所有的TIDB

618
00:33:44,310 --> 00:33:48,480
一般的代理工具会有百分之10到20%的一个性能损耗

619
00:33:49,710 --> 00:33:51,810
这块儿需要注意一下

620
00:33:52,380 --> 00:33:57,690
那么，单个TIDB的压测并发数呢？一般会设置为64，128

621
00:33:57,810 --> 00:33:59,490
256 512

622
00:33:59,520 --> 00:34:00,330


623
00:34:00,360 --> 00:34:01,650


624
00:34:01,770 --> 00:34:03,360
四个维度来进行测试

625
00:34:03,480 --> 00:34:07,410
一般默认配置的最优的结果是512个线程

626
00:34:08,040 --> 00:34:11,400
那么，1000并发的话，大家持续也可以测试一下

627
00:34:11,790 --> 00:34:17,100
然后根据我们的经验，其实1000并单个TIDB的吞吐

628
00:34:17,105 --> 00:34:20,670
实际是上升的，但是延迟会有明显的升高

629
00:34:20,700 --> 00:34:24,120
一块大家也可以在实际测试的过程当中观察一下

630
00:34:24,690 --> 00:34:30,000
sysbench其实我们每一次的这个大的版本官方

631
00:34:30,005 --> 00:34:34,050
都会披露一些sysbench的一些最佳的测试案例

632
00:34:34,140 --> 00:34:38,040
包括我们的官方也有sysbench的一个最佳测试标准

633
00:34:39,750 --> 00:34:42,450
另外一个测试的各种工具就是tpcc

634
00:34:42,570 --> 00:34:45,780
对tpcc不熟悉的小伙伴也可以自行百度一下

635
00:34:46,080 --> 00:34:47,040


636
00:34:47,310 --> 00:34:49,170
我们在tpcc

637
00:34:49,230 --> 00:34:53,280
里面官方推荐的一个测试的工具呢？其实就是benchmarkSQL 5.0

638
00:34:53,520 --> 00:34:57,570
我们初始化了，大概是5500个warehouse

639
00:34:57,780 --> 00:35:01,320
tpcc需要关注的指标其实就是tpmc

640
00:35:01,325 --> 00:35:04,110
就是每分钟处理的一个事务数

641
00:35:04,350 --> 00:35:07,560
那么其他的一些指标呢？其他和sysbench都是一样的

642
00:35:07,740 --> 00:35:11,820
就是平均延迟  99，然后最大延迟等等

643
00:35:11,970 --> 00:35:15,990
那么并发的其实可以和sysbench

644
00:35:16,050 --> 00:35:16,980
保持一致

645
00:35:19,290 --> 00:35:21,180
这是

646
00:35:21,240 --> 00:35:23,340
我们针对OLtp的一些测试

647
00:35:23,400 --> 00:35:28,110
那么，这个AP测试呢，实际上是引入大数据分析的一个测试的

648
00:35:28,590 --> 00:35:30,690
框架就是tpch框架

649
00:35:30,810 --> 00:35:34,920
tpch其实从TIDB工具链路里面有三种形式

650
00:35:35,400 --> 00:35:37,950
第一种呢，就是走TIDB SQL的路线

651
00:35:38,160 --> 00:35:40,380
然后第二种呢，可以走TiSpark的路线

652
00:35:40,620 --> 00:35:44,310
第三种呢，可以走我们未来的TiFlash列存储引擎

653
00:35:44,940 --> 00:35:50,070
不同的SQl在不同的引擎下三种不同的表现，那么测试的结果也是不同样的

654
00:35:51,540 --> 00:35:56,850
我们官方的一个测试的一个标准呢，一般会在500g的一个数据量的情况下来

655
00:35:57,450 --> 00:35:58,290


656
00:35:59,550 --> 00:36:01,560
来测试tpch框架

657
00:36:02,790 --> 00:36:06,120
整个结果来看呢，其实是

658
00:36:08,580 --> 00:36:12,420
各个行为都是不一样的，比如说TIDb有些SQL

659
00:36:12,425 --> 00:36:13,950
其实还是

660
00:36:13,980 --> 00:36:16,110
快与TISpark的

661
00:36:16,260 --> 00:36:20,430
但是其实总体评估下来TIFlash是最快的，因为走的是列存储

662
00:36:20,880 --> 00:36:23,460
这部分内容的话，其实也是大家

663
00:36:23,610 --> 00:36:26,370
可以参考一下我们的官方发布的一些文档

664
00:36:27,570 --> 00:36:30,900
就是今天描述的这些AP的这个场景

665
00:36:30,930 --> 00:36:32,790
并不是说

666
00:36:33,270 --> 00:36:35,400
并不是告诉大家哪个做法是最好的？

667
00:36:35,520 --> 00:36:40,140
还是要看具体的一个业务场景来选择合适的引擎和测试方法

668
00:36:41,250 --> 00:36:44,370
那么最后一块的测试呢，其实就是扩展性测试

669
00:36:44,820 --> 00:36:46,890
扩展性测试呢，是比较简单的

670
00:36:47,010 --> 00:36:50,160
也是以sysbench模型为基准来进行压测？

671
00:36:50,340 --> 00:36:54,510
那分别测试计算节点与数据点扩展前后的性能差异

672
00:36:54,930 --> 00:36:58,080
我们可以通过固定单个TIDB并发数

673
00:36:58,170 --> 00:37:00,810
为256，然后通过验证

674
00:37:00,930 --> 00:37:04,230
一台 两台 四台 六台TIDB server

675
00:37:04,235 --> 00:37:06,720


676
00:37:07,440 --> 00:37:10,470
不同的并发的情况下的一个指标的波动情况

677
00:37:10,680 --> 00:37:15,390
那么同理呢？TIKV也可以采取同样的方式来进行验证即可

678
00:37:16,800 --> 00:37:21,540
这个地方需要告诉大家，就是整个扩展性的，其实是TIDB的一个强项

679
00:37:21,720 --> 00:37:24,210
无论是TIDB server 还是TIKV server

680
00:37:24,215 --> 00:37:25,230


681
00:37:25,740 --> 00:37:27,660
扩展性测试的这个过程是

682
00:37:27,930 --> 00:37:29,400
可以完全在线的

683
00:37:29,550 --> 00:37:32,850
所以说大家在做这项测试的时候，可以重点关注一下

684
00:37:33,090 --> 00:37:38,220
整个业务的连续性，也就是在sysbench打压的整个过程当中

685
00:37:38,225 --> 00:37:41,820
看一下整个指标的一个波动情况和一个报错的一个情况

686
00:37:45,990 --> 00:37:50,580
那么最后一块呢？其实也是我认为非常重要的一块

687
00:37:50,850 --> 00:37:52,530
我们前面

688
00:37:52,680 --> 00:37:57,990
所讲的这些内容，就是sysbench是为了验证数据库，是不是可用了？

689
00:37:58,710 --> 00:38:04,020
然后能够为我们后续的业务测试提供一套性能基准的参考注意

690
00:38:04,770 --> 00:38:06,900
虽然基准测试讲了这么多

691
00:38:06,905 --> 00:38:09,660
其实这个地方不太推荐大家

692
00:38:09,690 --> 00:38:14,550
通过上面的一系列的逻辑和方法来进行基准性能的一些测试

693
00:38:15,120 --> 00:38:16,290
因为TIDB

694
00:38:16,295 --> 00:38:16,920
是开业

695
00:38:16,980 --> 00:38:18,720
这个一个产品

696
00:38:18,780 --> 00:38:22,740
在开源生态里面已经超过了几百家的一个PUC的

697
00:38:22,770 --> 00:38:23,700
测试验证

698
00:38:24,090 --> 00:38:29,160
基准测试数据仅仅是大家做作为业务上线

699
00:38:29,460 --> 00:38:31,110
技术选型的一个参考

700
00:38:31,320 --> 00:38:33,150
那么实际上能否满足业务需要？

701
00:38:33,330 --> 00:38:37,080
还需要结合业务场景来进行测试

702
00:38:37,230 --> 00:38:39,330
所以说更高效一点的做法是

703
00:38:39,360 --> 00:38:43,680
根据客户的需求，我们可以提供官方的一些测试数据

704
00:38:43,980 --> 00:38:48,810
或者说，对标大家的一些硬件，我们可以提供客户的一些测试案例

705
00:38:48,840 --> 00:38:50,970
或者测试平台的一些数据来

706
00:38:50,975 --> 00:38:52,740
大家提供一些参考

707
00:38:53,340 --> 00:38:57,090
还是希望大家更多的是聚焦业务场景的一些测试

708
00:38:57,450 --> 00:39:00,360
业务场景的测试更有说服力嘛，更精准，对不？

709
00:39:01,830 --> 00:39:06,090
那么在做业务测试之前呢？我们需要了解

710
00:39:06,720 --> 00:39:08,850
谁来负责整个业务测试？

711
00:39:09,000 --> 00:39:10,500
需要用什么样的

712
00:39:11,100 --> 00:39:12,990
数据来进行这个测试

713
00:39:12,995 --> 00:39:15,210
生产数据呢，还是构造

714
00:39:15,270 --> 00:39:16,590
样例测试数据等等

715
00:39:17,910 --> 00:39:18,540


716
00:39:19,530 --> 00:39:22,980
而且我们在做整个测试的时候，要做哪些

717
00:39:23,130 --> 00:39:28,440
内容呢，也就是我们的测试的这个用力，我们是要把整个业务测试的框架

718
00:39:28,560 --> 00:39:33,870
全部测试一遍，还是说把典型的测试场景抽象出来去做，去模拟一下

719
00:39:33,875 --> 00:39:35,430
这个框架

720
00:39:35,460 --> 00:39:36,390
来进行

721
00:39:36,420 --> 00:39:38,040
普通SQL的一些压制

722
00:39:39,960 --> 00:39:45,030
通常我们压测的常规的方式呢，是首先需要我们有一个业务的测试人员

723
00:39:45,035 --> 00:39:47,010
那个这个人员的需要

724
00:39:47,015 --> 00:39:49,710
熟悉业务的整个数据的一些构造

725
00:39:49,800 --> 00:39:50,940
可能我们

726
00:39:50,945 --> 00:39:53,190
第一件事情呢，就是造数据

727
00:39:53,250 --> 00:39:58,560
那么，要么就是拿生产环境中实际的数据来进行测试，那么数据量不够的话

728
00:39:58,565 --> 00:39:59,820
那我们可能

729
00:39:59,850 --> 00:40:04,020
会按照现有的这个数据来进行复制几倍的数据

730
00:40:04,590 --> 00:40:05,760


731
00:40:06,660 --> 00:40:11,970
那么这个这个地方呢，还是做业务压制的话，还是希望大家

732
00:40:12,240 --> 00:40:14,700
尽量的使用线上的数据来进行测试

733
00:40:16,470 --> 00:40:17,610
那么第二点呢？

734
00:40:17,615 --> 00:40:21,180
需要结合业务的需求来制定压制的计划和用力

735
00:40:21,330 --> 00:40:23,790
尽可能模拟现实的生产环境

736
00:40:23,940 --> 00:40:29,250
这个地方模拟现场生产环境的话呢？我们包括这个一些

737
00:40:29,255 --> 00:40:32,070
压制的一些并发量

738
00:40:32,100 --> 00:40:33,600
用户的行为

739
00:40:33,605 --> 00:40:36,270
数据库以及工具链硬件

740
00:40:36,750 --> 00:40:41,640
系统配置项都需要大家考这些这方面的因素

741
00:40:41,730 --> 00:40:42,390


742
00:40:42,930 --> 00:40:44,190
大家综合的进行考虑

743
00:40:45,720 --> 00:40:49,920
那么说起来呢，就是整个业务的测试过程是比较简单

744
00:40:50,070 --> 00:40:53,580
但是在实际业务测试过程中，还是遇到不少的问题

745
00:40:53,910 --> 00:40:55,560
下面就结合TIDB

746
00:40:55,590 --> 00:40:59,550
某业务测试的一些典型场景，我们一块探讨一下

747
00:40:59,580 --> 00:41:02,850
就作为原厂，我们重点关注的指标大概有哪些？

748
00:41:04,650 --> 00:41:07,980
从总体分析下来呢，大概有七项啊！

749
00:41:08,010 --> 00:41:12,210
那么第一项呢？其实我们就要关注典型的业务场景

750
00:41:12,360 --> 00:41:15,510
以及这个场景所涉及到的表结构数据量

751
00:41:15,570 --> 00:41:17,280
涉及压测得SQL语句

752
00:41:18,720 --> 00:41:21,330
我们要清楚地知道你的整个业务场景

753
00:41:21,390 --> 00:41:26,700
属于读多写少啊，还是写多读少呀，你的整个数据存量增量

754
00:41:27,150 --> 00:41:29,130
数据整个生命周期是什么样的一个情况？

755
00:41:29,610 --> 00:41:31,590
来方便我们来评估

756
00:41:31,595 --> 00:41:33,060
你未来

757
00:41:33,630 --> 00:41:38,940
3到5年内的一个数据的一个规模，这个时候的话，我们通过你的数据规模来评估出

758
00:41:38,945 --> 00:41:39,750
你们

759
00:41:40,050 --> 00:41:42,720
整个业务的并发量和你的整个

760
00:41:42,810 --> 00:41:43,590
资源

761
00:41:43,595 --> 00:41:45,240
的一个情况

762
00:41:45,990 --> 00:41:47,130
那么第二点呢？

763
00:41:47,160 --> 00:41:50,070
其实就是业务的测试目标测试预期

764
00:41:50,130 --> 00:41:52,440
需要达到的TPS是和QPS

765
00:41:53,670 --> 00:41:54,720
在大家

766
00:41:54,810 --> 00:42:00,120
迁移到TIDB之前，我们需要考虑一下，在现有的生产环境中，我们的tps

767
00:42:00,390 --> 00:42:02,070
QPS的峰值有多少？

768
00:42:02,075 --> 00:42:05,730
未来1到2年内，我们的业务增量大概是多少？

769
00:42:06,420 --> 00:42:11,070
结合我们的业务增量呢，我们去构造我们的整个测试的一个场景

770
00:42:13,140 --> 00:42:18,450
包括我们在测试之前，需要了解清楚整个业务的测试目标和测试预期大概是什么样的？

771
00:42:19,020 --> 00:42:21,420
这些也都是我们非常关注的

772
00:42:21,780 --> 00:42:24,690
那么第三点呢，其实就是压制的并发数

773
00:42:25,110 --> 00:42:30,150
并发数之外呢，我们还需要重点关注你的整个业务的一个读写比

774
00:42:32,550 --> 00:42:37,410
因为压测的并发症与整个集群的硬件是强相关的

775
00:42:37,415 --> 00:42:42,270
我们可以看一下当前测试环境中的瓶颈点到底在哪？

776
00:42:42,360 --> 00:42:44,190
我们可以把并发打满

777
00:42:44,195 --> 00:42:46,980
看一下是TIDB的瓶颈还是TIKV的瓶颈

778
00:42:47,580 --> 00:42:49,440
那么这个时候的话，我们能

779
00:42:49,740 --> 00:42:54,270
能够算出来整个业务的一个并发量大概是什么样的一个情况？

780
00:42:54,420 --> 00:42:56,520
那么，结合我们业务的发展

781
00:42:57,480 --> 00:43:02,790
来设定更高的一个并发的一个翻倍或者测试量

782
00:43:02,795 --> 00:43:06,840
我们可以根据现有的一个硬件配置的情况

783
00:43:06,870 --> 00:43:10,140
是不是能够评估出来在未来的一个

784
00:43:12,030 --> 00:43:13,770
更好的一个硬件配置

785
00:43:16,320 --> 00:43:20,280
那么第四点呢，实际上是业务开发语言框架

786
00:43:20,310 --> 00:43:22,470
是不是还有事物的封装？

787
00:43:22,475 --> 00:43:23,820
是否存在大事务

788
00:43:24,180 --> 00:43:25,470
这一块怎么理解呢？

789
00:43:26,550 --> 00:43:28,530
其实TIDB

790
00:43:28,860 --> 00:43:31,590
有一个特点，就这个特点其实是

791
00:43:31,680 --> 00:43:36,990
目前他就是不支持大事务的完美规划当中已经在做了

792
00:43:36,995 --> 00:43:42,300
不仅仅是不支持大事物，而且是最佳的写入实践是

793
00:43:42,630 --> 00:43:43,980
小batch 多并发

794
00:43:45,000 --> 00:43:49,500
还有一点就是，TIDB是乐观锁，锁就在我们第一章里面已经讲过了

795
00:43:49,530 --> 00:43:54,360
需要评估乐观锁和应用框架适配里面的一个改造的一个成本

796
00:43:56,100 --> 00:43:58,080
那么第五点呢是？

797
00:43:58,085 --> 00:43:59,190
要考虑

798
00:44:00,060 --> 00:44:03,720
需要考虑你的应用里面是不是有select for update？

799
00:44:04,170 --> 00:44:07,140
因为是哪select for update的行为实际上和MYSQL

800
00:44:07,410 --> 00:44:10,140
行为还是有一些差异的

801
00:44:10,440 --> 00:44:13,320
而且在某些常用的可能是非常低效的

802
00:44:13,410 --> 00:44:15,660
这一块的话，需要谨慎地去评估

803
00:44:16,110 --> 00:44:17,340
第六点呢？

804
00:44:17,430 --> 00:44:22,680
要考虑就是是否存在同时高并发操作，同一行记录的行为

805
00:44:22,920 --> 00:44:26,580
就是典型的一个对乐观锁不友好的一个场景

806
00:44:26,640 --> 00:44:30,330
如果存在该长一点的话，还需要分析一下

807
00:44:30,780 --> 00:44:32,880
那么是采用

808
00:44:32,970 --> 00:44:37,590
外部的一些分布式锁的一些处理机制还是结合数据库特性

809
00:44:38,190 --> 00:44:39,360
塑造一些

810
00:44:41,550 --> 00:44:43,080
其他的一些处理方式

811
00:44:43,085 --> 00:44:45,900
这种情况下，我们还是要具体情况具体分析

812
00:44:46,110 --> 00:44:49,110
那么第七点呢，其实是业务压力的工具

813
00:44:49,320 --> 00:44:54,540
因为我压制的工具的话，那在业界比较主流的可能就是这么jmeter loadruner？

814
00:44:55,140 --> 00:44:57,930
这两个工具呢，其实

815
00:44:57,990 --> 00:45:02,010
没有什么可说的，是一些通用的一些方案，但需要注意的是

816
00:45:02,040 --> 00:45:04,050
这两个工具在压测过程中

817
00:45:04,080 --> 00:45:06,270
我们发现大家，就是对

818
00:45:06,450 --> 00:45:07,500
这个

819
00:45:07,620 --> 00:45:10,980
自动提交这个属性，有时候不是特别关注

820
00:45:11,370 --> 00:45:12,540
因为自动提交

821
00:45:12,545 --> 00:45:13,860
这个属性

822
00:45:13,890 --> 00:45:18,930
如果说你的整个一个业务测试包含非常多的事物语句的话

823
00:45:18,990 --> 00:45:24,300
这个时候的他的行为是不一样的，所以这一块还是需要重点关注，因为之前我们

824
00:45:24,330 --> 00:45:29,460
很多客户就是默认把autocommit的这个行为设置为TRUE

825
00:45:29,760 --> 00:45:31,380
导致了一个事务
826
00:45:31,710 --> 00:45:33,360
里面包含十条

827
00:45:33,365 --> 00:45:37,140
insert的语句，然后拆分成了单独事务去执行

828
00:45:37,860 --> 00:45:38,580
所以说

829
00:45:38,640 --> 00:45:42,840
这个地方很多人遇到了这个坑，所以说大家需要重点关注

830
00:45:47,550 --> 00:45:48,420
OK

831
00:45:48,450 --> 00:45:52,620
其实，benchmark一项非常复杂的工程

832
00:45:52,710 --> 00:45:55,770
我们上面只介绍集群，正常情况下的benchmark

833
00:45:55,980 --> 00:45:58,980
直接更大的困难是集群出现故障时

834
00:45:59,010 --> 00:46:00,510
性能指标的评估

835
00:46:00,540 --> 00:46:03,660
所以我们内部也非常重视整个产品的benchmark

836
00:46:04,200 --> 00:46:09,150
而且我们的混沌测试呢，也是24小时不断的在我们的测试平台上跑

837
00:46:09,660 --> 00:46:12,150
也是希望大家一块去探索

838
00:46:12,480 --> 00:46:17,010
不同的业务场景在TIDB上一些性能的边界

839
00:46:17,850 --> 00:46:18,600
OK

840
00:46:18,750 --> 00:46:21,120
这是我们今天第二章的课程

841
00:46:21,330 --> 00:46:25,230
那么我们再来简单回顾一下第二章的一些关键知识点

842
00:46:26,550 --> 00:46:29,070
第二张的关键知识点呢？大概有四块

843
00:46:29,100 --> 00:46:32,310
第一块呢，就是benchmark一些测试策略有哪些？

844
00:46:32,315 --> 00:46:33,600
大家需要关注

845
00:46:34,320 --> 00:46:37,710
就是我们在数据库测试上的测试指标

846
00:46:37,980 --> 00:46:38,790
有哪些？

847
00:46:38,820 --> 00:46:44,130
然后第三点呢，其实就是常用的benchmark工具，然后需要考察的指标

848
00:46:44,370 --> 00:46:46,020
包含哪些？

849
00:46:46,320 --> 00:46:51,630
这一块儿，其实我们在后续的官方文档里面会把会尽量把这些内容进行标准化

850
00:46:51,930 --> 00:46:54,450
大家去重点关注业务的测试就好了

851
00:46:55,110 --> 00:46:56,700
最重要的第四点

852
00:46:56,730 --> 00:46:58,530
业务压制需要注意什么？

853
00:46:58,620 --> 00:47:01,500
这一块还是需要大家重点关注一下

854
00:47:04,650 --> 00:47:06,360
那么我们来回顾一下子

855
00:47:06,570 --> 00:47:08,160
第二章的学习目标

856
00:47:08,460 --> 00:47:09,240


857
00:47:09,330 --> 00:47:12,360
大家是不是现在已经了解了benchmark的作用？

858
00:47:12,570 --> 00:47:13,230


859
00:47:13,470 --> 00:47:18,180
然后是不是已经掌握了benchmark基准的测试流程？

860
00:47:18,510 --> 00:47:19,380
然后

861
00:47:19,530 --> 00:47:21,330
我们需要参与的东西

862
00:47:21,570 --> 00:47:25,530
然后你作为这个客户方需要参与的东西

863
00:47:25,535 --> 00:47:28,050
所以说，这两块是需要大家明确的

864
00:47:28,320 --> 00:47:33,630
那么第三个呢是大家是不是已经掌握了基于TIDB benchmark的性能的测试的一些基本

865
00:47:33,635 --> 00:47:34,230
要求

866
00:47:35,010 --> 00:47:39,090
只有满足了这些要求，我们的测试的结果和测试的数据

867
00:47:39,210 --> 00:47:39,930


868
00:47:40,650 --> 00:47:42,060
才是被认可的

869
00:47:43,860 --> 00:47:46,530
那么第四块呢，我们是不是已经

870
00:47:48,030 --> 00:47:52,140
学习了这个常见的benchmark的一些测试的工具和方法

871
00:47:53,190 --> 00:47:58,500
那么第五块呢，是不是已经了解了针对TIDB业务场景

872
00:47:58,505 --> 00:47:59,130


873
00:47:59,280 --> 00:48:01,560
在做压测的时候，我们需要

874
00:48:01,950 --> 00:48:03,270
关注哪些

875
00:48:03,510 --> 00:48:04,770
知识点

876
00:48:08,970 --> 00:48:11,790
OK，留给大家一个课程作业

877
00:48:12,030 --> 00:48:15,630
参考官方文档来进行实施sysbench的基本性能测试

878
00:48:16,440 --> 00:48:21,750
整个测试的话，后续我会发给大家一个链接，然后大家可以按照整个

879
00:48:21,755 --> 00:48:25,230
连接来进行进行详细的这个PUC

880
00:48:26,130 --> 00:48:26,820
OK

881
00:48:26,825 --> 00:48:28,620
今天的课程到此为止

882
00:48:28,680 --> 00:48:30,090
好，谢谢大家

883
00:48:34,800 --> 00:48:35,400


884
00:48:40,110 --> 00:48:40,710
