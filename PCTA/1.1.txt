1
00:00:00,240 --> 00:00:05,550
嗯嗯

2
00:00:05,555 --> 00:00:09,510


3
00:00:12,660 --> 00:00:17,970
PingCAP University的同学大家好，今天由我来给大家

4
00:00:17,975 --> 00:00:19,140
介绍一下

5
00:00:19,350 --> 00:00:23,880
数据库的发展简史吧

6
00:00:24,450 --> 00:00:25,500
然后

7
00:00:25,860 --> 00:00:31,170
首先，我先简单介绍一下我自己，我叫

8
00:00:31,175 --> 00:00:33,750
黄东旭, 是PingCAP的

9
00:00:34,140 --> 00:00:39,450
联合创始人跟CTO然后，其实也是做

10
00:00:39,455 --> 00:00:43,290
这个分布式系统做了很多年，然后

11
00:00:43,410 --> 00:00:47,460
这几年主要也是在做TiDB这个项目

12
00:00:47,760 --> 00:00:53,070
PingCAP University这一系列的课程

13
00:00:53,075 --> 00:00:54,450
然后和这个

14
00:00:54,540 --> 00:00:59,850
讲座吧，就是让大家对整个Database这个行业和

15
00:00:59,940 --> 00:01:05,250
TiDB的底层的一些技术架构，包括分布式据库该怎么做

16
00:01:05,255 --> 00:01:08,400
有一个全面的认识

17
00:01:08,405 --> 00:01:13,710
所以，今天我给大家带来一个

18
00:01:14,280 --> 00:01:19,590
类似于综述性质的一个talk，让大家对整个

19
00:01:19,595 --> 00:01:21,840
行业有一个比较感性的认识

20
00:01:23,460 --> 00:01:28,770
所以其实在去聊数据库

21
00:01:30,000 --> 00:01:35,310
的行业和历史之前，第一个问题就是

22
00:01:35,315 --> 00:01:36,690
对然后

23
00:01:36,720 --> 00:01:41,250
到底什么是数据库？其实我相信可能听众

24
00:01:41,520 --> 00:01:45,630
包括在座的学员

25
00:01:45,635 --> 00:01:50,940
有很多，其实天天都在使用着数据库，然后

26
00:01:51,600 --> 00:01:56,910
大家我不知道有没有真正去思考过这个数据库软件的一个

27
00:01:57,180 --> 00:01:58,080
定义

28
00:01:58,170 --> 00:02:03,480
这段是我从Wikipedia上摘抄

29
00:02:03,485 --> 00:02:08,790
下来的一个非常学术的，关于数据库软件

30
00:02:08,795 --> 00:02:14,100
这样的一个定义，其实归根结底，大家看到我这边

31
00:02:14,105 --> 00:02:18,750
标黑体的这几个字

32
00:02:18,840 --> 00:02:22,230
总结一下，主要是大概有几个，

33
00:02:22,470 --> 00:02:25,050
三个特别重要的概念

34
00:02:25,140 --> 00:02:27,150
一个是数据

35
00:02:27,155 --> 00:02:29,070
一个是数据的模型

36
00:02:29,220 --> 00:02:34,530
然后第三个就是Processing，基于这个模型上，你能够去

37
00:02:34,535 --> 00:02:39,840
做哪些处理，或者说怎么去操作

38
00:02:40,050 --> 00:02:41,220
操作这些数据

39
00:02:41,460 --> 00:02:42,420
所以其实

40
00:02:42,450 --> 00:02:47,760
第一个概念，Data本身是一个比较抽象的概念，所以这个

41
00:02:47,765 --> 00:02:53,070
世界万物，这个信息嘛，就是Data

42
00:02:53,460 --> 00:02:58,740
但是信息或者数据总是得有一个形式

43
00:02:58,770 --> 00:03:04,080
存储下来，比如说你到底是一个表的结构存储下来，还是这种

44
00:03:04,140 --> 00:03:05,880
文档的形式存储下来

45
00:03:05,940 --> 00:03:11,250
还是以任何的这种方式来组织这样的一个数据

46
00:03:11,255 --> 00:03:15,720
组织形式就是Data Model，然后

47
00:03:15,840 --> 00:03:21,150
Processing就是说你在基于Data Model之上

48
00:03:21,155 --> 00:03:26,460
能做哪些操作，能对这些数据做哪些处理

49
00:03:26,580 --> 00:03:31,890
一个数据库的软件，其实主要是由这

50
00:03:31,895 --> 00:03:37,200
三个特别重要的点，作为一个

51
00:03:37,205 --> 00:03:40,290
这个维度去考虑

52
00:03:41,640 --> 00:03:44,010
然后

53
00:03:44,490 --> 00:03:49,800
今天的这个课程的第一部分是，我会先讲一讲，整个

54
00:03:49,805 --> 00:03:55,110
历史，就是这个行业的八卦吧

55
00:03:58,110 --> 00:04:03,330
其实我个人认为当代数据库软件的开端

56
00:04:03,900 --> 00:04:09,210
是在1970年E.F Codd

57
00:04:09,215 --> 00:04:14,520
是IBM在硅谷的研究中心的

58
00:04:14,525 --> 00:04:18,780
这位研究员发表了一篇论文叫

59
00:04:18,870 --> 00:04:24,180
A Relational Model of Data for Large Shared Data Banks

60
00:04:26,340 --> 00:04:31,650
实际上就是在这篇

61
00:04:31,655 --> 00:04:36,960
论文里面他Literary就是做一个这种Transaction

62
00:04:36,965 --> 00:04:42,270
做事务，交易这样的一个含义，然后这篇

63
00:04:42,275 --> 00:04:44,250
论文

64
00:04:44,255 --> 00:04:45,750
比较

65
00:04:46,200 --> 00:04:51,510
其实在这篇论文发表之前，也有过或多或少的这种文件

66
00:04:51,515 --> 00:04:56,820
存储系统，然后数据其实是以这种

67
00:04:57,060 --> 00:04:59,580
就是或多或少有

68
00:04:59,910 --> 00:05:05,220
因为其实大家知道存储其实是这个计算机体系结构里面特别重要的

69
00:05:05,225 --> 00:05:10,530
组件，你总是得存点什么东西是吧，但是这篇论文

70
00:05:10,535 --> 00:05:15,840
是标志着我们现在去大规模去使用的

71
00:05:15,845 --> 00:05:21,150
数据库比如说像Oracle，DB2，SQL Server，MySQL，Postgres

72
00:05:21,155 --> 00:05:25,800
我认为所有的

73
00:05:25,805 --> 00:05:31,110
基于这种SQL或者说关系模型的数据库

74
00:05:31,115 --> 00:05:36,420
的开端，其实就是1970年的这篇论文

75
00:05:37,080 --> 00:05:39,330
然后

76
00:05:39,750 --> 00:05:42,030
基本上它是一个

77
00:05:42,420 --> 00:05:45,810
当时是Oracle的老板

78
00:05:45,815 --> 00:05:47,280
Larry

79
00:05:47,285 --> 00:05:52,590
他读到这篇论文了以后，一拍脑袋觉得，哇，这篇论文

80
00:05:52,595 --> 00:05:53,730
非常的棒，

81
00:05:54,180 --> 00:05:59,490
这个数据库应该就是得是这样的，所以他后来跑出去开了一个创业公司

82
00:05:59,495 --> 00:06:04,800
叫Oracle，到今天其实是已经是全全球最大的

83
00:06:04,805 --> 00:06:06,720
IT公司之一了

84
00:06:09,270 --> 00:06:14,580
所以其实在1970年的时候

85
00:06:14,585 --> 00:06:19,890
论文发表，1972年Oracle这个公司的

86
00:06:20,010 --> 00:06:25,320
成立，其实一直从上世纪70年代到

87
00:06:25,325 --> 00:06:30,630
90年代吧，整个数据库软件的市场一直都被

88
00:06:30,635 --> 00:06:32,310
这个

89
00:06:32,760 --> 00:06:38,070
这种传统的巨头像IBM像Oracle这样的

90
00:06:38,370 --> 00:06:40,200
公司给垄断着

91
00:06:40,470 --> 00:06:45,780
其实是一个比较小众的软件吧，因为大家能想象到

92
00:06:45,785 --> 00:06:46,530
这个

93
00:06:46,680 --> 00:06:51,990
70年代到80年代，90年代初，能需要

94
00:06:51,995 --> 00:06:57,300
数据库软件的场景和行业其实也

95
00:06:57,305 --> 00:07:02,610
就是一些特别大的这种金融机构，研究机构

96
00:07:02,790 --> 00:07:04,260
所以整体上来说

97
00:07:04,590 --> 00:07:09,900
在整个模型上，或者说整个商业模式上，其实并没有

98
00:07:09,905 --> 00:07:11,940
太大的变化就是

99
00:07:11,970 --> 00:07:16,710
过了大概到90年代中期

100
00:07:18,060 --> 00:07:22,020
90年代中期发生了什么事情呢，90年代中期

101
00:07:22,080 --> 00:07:27,390
大家知道在美国，互联网

102
00:07:27,395 --> 00:07:32,490
开始走进寻常百姓家

103
00:07:32,700 --> 00:07:38,010
然后整个互联网快速的发展，使得

104
00:07:38,015 --> 00:07:43,320
大家发现，哎，我开始要去做网站了，是吧，做网站我就

105
00:07:43,325 --> 00:07:48,630
得有个数据库，我要能够去存储我的数据，然后大家发现

106
00:07:48,635 --> 00:07:53,940
这种传统的商业的这个数据库又太贵了，比如说

107
00:07:54,330 --> 00:07:59,640
像Oracle，像IBM，比如说搭个小网站，你还要花好多钱去买这个

108
00:07:59,645 --> 00:08:04,950
软件其实不太好是吧

109
00:08:05,160 --> 00:08:07,530
就没那么多钱，怎么办？

110
00:08:08,130 --> 00:08:13,440
然后同一时代的话，就是开源运动

111
00:08:13,470 --> 00:08:18,780
开始兴起，所以开源社区

112
00:08:18,785 --> 00:08:24,090
里面就开始，因为这个需求一定是存在的，就是大家可能

113
00:08:24,095 --> 00:08:29,400
Oracle包括IBM DB2这些数据库

114
00:08:29,405 --> 00:08:34,710
在企业级市场已经开始

115
00:08:34,715 --> 00:08:35,580
啊？

116
00:08:35,640 --> 00:08:40,950
开始有这种统治级地位了，这种Relational Database，然后自然的到这个

117
00:08:40,955 --> 00:08:44,880
互联网这个时代，包括开源这个时代

118
00:08:45,030 --> 00:08:50,340
大家觉得这个数据库挺好用的，所以

119
00:08:50,345 --> 00:08:51,240
就

120
00:08:51,245 --> 00:08:56,550
当时其实也是很自然的，就出现了一些开源

121
00:08:56,555 --> 00:08:57,300
的

122
00:08:57,330 --> 00:08:58,740
这种关系型数据库

123
00:08:59,040 --> 00:09:04,350
比如说像MySQL，包括Postgres，这两个

124
00:09:04,355 --> 00:09:06,330
到现在为止是最著名的

125
00:09:06,335 --> 00:09:10,950
两个开源的关系数据库吧

126
00:09:11,070 --> 00:09:15,510
也是在那个时候诞生，95，96年，其实很近

127
00:09:16,020 --> 00:09:18,150
然后

128
00:09:18,780 --> 00:09:24,090
在这种开源的关系型数据库，在90年代中期出现了以后

129
00:09:24,095 --> 00:09:29,400
一直到20世纪初，在整个

130
00:09:29,405 --> 00:09:32,160
大家知道那时候正好也是互联网泡沫

131
00:09:32,165 --> 00:09:37,470
大量的网站，大量的

132
00:09:37,475 --> 00:09:39,660
互联网公司

133
00:09:39,720 --> 00:09:40,710
开始涌现

134
00:09:40,715 --> 00:09:46,020
然后当时也是MySQL跟Postgres蓬勃发展的

135
00:09:46,200 --> 00:09:48,660
这个年代

136
00:09:48,750 --> 00:09:54,060
然后一直到这个行业一直发展到

137
00:09:54,065 --> 00:09:59,370
21世纪初，发现整个互联网包括移动互联网

138
00:09:59,375 --> 00:10:04,680
开始出现，然后数据量的增长跟

139
00:10:04,685 --> 00:10:08,310
接入互联网的用户越来越多

140
00:10:08,730 --> 00:10:11,280
大家发现传统的这种单机的这种

141
00:10:11,285 --> 00:10:16,590
关系型数据库，就可能过去很多时候，我一个网站，我底下

142
00:10:16,595 --> 00:10:19,170
搭建一个数据库，可能就够了

143
00:10:19,560 --> 00:10:22,890
可能那个年代也没有多少

144
00:10:22,895 --> 00:10:25,260
并发，或者说这个数量不大

145
00:10:25,500 --> 00:10:30,780
是吧，然后一直到21世纪初吧

146
00:10:31,200 --> 00:10:34,590
大家发现

147
00:10:34,595 --> 00:10:35,910
这个数据量

148
00:10:35,970 --> 00:10:38,340
开始可能搞不定了，而且

149
00:10:38,670 --> 00:10:43,980
用户的需求越来越多，这个数据能不能快一点，

150
00:10:43,985 --> 00:10:46,260
这个

151
00:10:46,265 --> 00:10:51,570
大家发现整个行业的变化，业务的需求越来

152
00:10:51,575 --> 00:10:52,380
越

153
00:10:52,590 --> 00:10:54,300
极端吧

154
00:10:54,720 --> 00:10:57,300
所以开始去

155
00:10:57,390 --> 00:11:01,740
从数据库的技术里面衍生出一些分支

156
00:11:01,950 --> 00:11:07,260
比如说比较典型的一个标志性的项目是Memcached

157
00:11:07,265 --> 00:11:12,570
虽然现在大家都用的是Redis，但是在内存缓存这个领域里面

158
00:11:12,575 --> 00:11:17,880
我觉得第一个有这种大规模影响力的项目其实是Memcached

159
00:11:17,885 --> 00:11:23,190
Memcached其实是一个内存的缓存数据库，一个键值数据库

160
00:11:23,370 --> 00:11:28,680
它的特点就是都是用内存，就是做这种

161
00:11:28,685 --> 00:11:33,990
高速的缓存型的数据库，它是2003年

162
00:11:33,995 --> 00:11:39,300
第一个版本发布，然后大概在06年的时候

163
00:11:39,305 --> 00:11:40,260
然后

164
00:11:40,830 --> 00:11:46,140
有一个比较标志性的事件是，几个事件吧，0607年

165
00:11:46,740 --> 00:11:52,050
可是我觉得属于大数据跟

166
00:11:52,055 --> 00:11:52,890
NoSQL

167
00:11:52,920 --> 00:11:56,130
这个行业

168
00:11:56,820 --> 00:11:58,380
诞生的元年吧

169
00:11:58,770 --> 00:12:04,080
06年Google发表了一篇非常有划时代意义的

170
00:12:04,085 --> 00:12:06,240
论文，在分布式系统领域

171
00:12:06,870 --> 00:12:12,180
Bigtable，Google描述了一个

172
00:12:12,330 --> 00:12:17,460
可以在Google内部，因为大家知道谷歌是一个数据量特别

173
00:12:17,670 --> 00:12:22,980
特别大的一个公司，然后谷歌其实是希望能够去用这种

174
00:12:22,985 --> 00:12:28,290
分布式系统的理念来做到无限的

175
00:12:28,295 --> 00:12:33,600
水平扩展，他描述了一个新型的数据库，然后

176
00:12:33,605 --> 00:12:38,490
可以做到完全无缝的水平扩展，然后

177
00:12:38,730 --> 00:12:44,040
另外它是一个基于键值Key Value形式的一个

178
00:12:44,280 --> 00:12:49,590
键值对，它其实是一个Key加这种Columns，

179
00:12:49,595 --> 00:12:54,900
可以简单认为就是一个比较简单的价值对

180
00:12:54,905 --> 00:12:58,290
形式的一个系统吧，Bigtable

181
00:12:58,590 --> 00:13:01,020
非常有划时代的意义

182
00:13:01,080 --> 00:13:06,390
然后这篇论文其实也是影响了后续的一大堆

183
00:13:06,660 --> 00:13:09,750
的这种NoSQL系统

184
00:13:10,110 --> 00:13:14,850
第二篇论文是亚马逊在07年发表的

185
00:13:15,150 --> 00:13:20,460
他自己的这个Key Value键值对数据库

186
00:13:20,465 --> 00:13:25,770
叫Dynamo。Dynamo这篇论文其实非常棒

187
00:13:26,160 --> 00:13:29,940
它第一次引入了

188
00:13:30,330 --> 00:13:32,670
在NoSQL上的

189
00:13:32,700 --> 00:13:37,980
最终一致性，这样的一个概念，然后

190
00:13:38,010 --> 00:13:43,320
也融合了当时分布式系统领域里面非常前沿的一些

191
00:13:43,325 --> 00:13:44,220
技术

192
00:13:44,310 --> 00:13:45,840
比如说一致性哈希

193
00:13:45,845 --> 00:13:49,680
比如说WRN模型

194
00:13:49,685 --> 00:13:54,990
也是一个非常有代表性的系统，其实这两篇论文基本上

195
00:13:54,995 --> 00:14:00,300
就是后续出来的一大批NoSQL数据库

196
00:14:00,750 --> 00:14:06,060
的设计的鼻祖吧，然后还有一个比较重大的事情

197
00:14:06,065 --> 00:14:11,370
05年的时候这个Hadoop项目，因为其实大家知道

198
00:14:11,375 --> 00:14:16,680
谷歌大概从03年，04年，05年，06年这几年发表

199
00:14:16,685 --> 00:14:17,820
了几篇

200
00:14:17,910 --> 00:14:23,220
关于分布式系统、分布式文件系统、分布式计算，包括Bigtable

201
00:14:23,225 --> 00:14:28,530
这几篇论文，然后呢，Hadoop这个项目其实是

202
00:14:28,535 --> 00:14:30,150
最开始由雅虎

203
00:14:30,630 --> 00:14:35,880
这边牵头想做一个开源项目

204
00:14:36,150 --> 00:14:41,460
这个开源项目就是想去实现谷歌的那几篇论文，然后

205
00:14:41,465 --> 00:14:44,340
这是NoSQL的诞生

206
00:14:45,180 --> 00:14:49,950
然后大概在06年之后

207
00:14:50,010 --> 00:14:55,320
整个数据库行业在快速的

208
00:14:55,470 --> 00:14:57,210
发展和

209
00:14:57,480 --> 00:14:59,220
进入了一个快车道

210
00:14:59,370 --> 00:15:04,680
至于背后的原因，我个人觉得主要也是因为

211
00:15:04,770 --> 00:15:08,220
业务的需求，包括互联网，移动互联网

212
00:15:08,280 --> 00:15:13,590
就是这样的，这些新的用户的使用形态

213
00:15:13,595 --> 00:15:14,580
然后

214
00:15:14,760 --> 00:15:20,070
数据的增速越来越快，用传统的技术其实越来越

215
00:15:20,075 --> 00:15:21,960
难去解决这些

216
00:15:21,965 --> 00:15:23,160
新时代的问题

217
00:15:23,490 --> 00:15:25,230
所以

218
00:15:25,620 --> 00:15:29,880
经过差不多十年的时间，整个NoSQL这个技术

219
00:15:29,885 --> 00:15:35,100
迅速的发展，因为NoSQL的一个好处就是说，水平扩展能力特别好

220
00:15:35,160 --> 00:15:40,470
然后这个容量不够了加机器就好了，因为

221
00:15:40,475 --> 00:15:45,780
我觉得摩尔定律在某些程度上来说，应该已经说是失效了

222
00:15:45,785 --> 00:15:46,890
就这十年吧

223
00:15:47,490 --> 00:15:52,530
然后大概在2013年就是最近几年啊

224
00:15:54,690 --> 00:15:59,790
需求也一直在往前

225
00:16:00,060 --> 00:16:05,370
去驱动着技术的发展，然后大家发现有一些场景其实用

226
00:16:05,550 --> 00:16:08,010
这种比较简单的NoSQL

227
00:16:08,100 --> 00:16:13,410
或者说键值对这样的数据模型，其实很难去实现业务

228
00:16:13,415 --> 00:16:18,120
举个简单例子，比如说像这种金融

229
00:16:18,330 --> 00:16:20,280
交易、转账

230
00:16:20,460 --> 00:16:25,770
这样的要求，这种强事务，比如说你的钱不能丢的这种场景

231
00:16:26,040 --> 00:16:31,350
那你用这个NoSQL，很多NoSQL System其实并没有这种传统数据库的ACID

232
00:16:31,355 --> 00:16:32,550
这种事务支持

233
00:16:32,670 --> 00:16:34,650
所以你其实很难去

234
00:16:34,710 --> 00:16:40,020
在一个NoSQL系统上去做一个类似银行的核心交易系统这样的

235
00:16:40,110 --> 00:16:45,420
东西。第二方面就是大家发现NoSQL的

236
00:16:46,110 --> 00:16:47,280
数据的

237
00:16:47,340 --> 00:16:52,650
Data Model太简单，还记得刚才说的Data Model，很多NoSQL

238
00:16:52,655 --> 00:16:57,960
是文档，或者说Key Value键值对这样比较简单的，这种数据的

239
00:16:58,290 --> 00:17:03,600
表现形式，然后在Processing这一块的话其实

240
00:17:03,605 --> 00:17:05,340
它不像SQL

241
00:17:05,610 --> 00:17:10,920
这样的非常通用或者标准和非常

242
00:17:10,925 --> 00:17:13,230
强大的数据的

243
00:17:13,440 --> 00:17:17,040
操作数据的一种语言吧

244
00:17:17,100 --> 00:17:22,410
没有，所以有很多业务特别难写，还是Google

245
00:17:22,830 --> 00:17:28,140
谷歌在大概2012年发表了一篇论文

246
00:17:28,145 --> 00:17:33,450
这篇论文其实尝试着去结合传统关系型数据库

247
00:17:33,455 --> 00:17:36,660
的这些包括事务，包括SQL

248
00:17:36,665 --> 00:17:37,680
的这个能力

249
00:17:37,920 --> 00:17:42,180
跟NoSQL System融合在一起

250
00:17:42,540 --> 00:17:46,650
然后，这篇论文叫Spanner

251
00:17:46,830 --> 00:17:51,300
然后这篇论文其实是描述了谷歌的内部

252
00:17:51,330 --> 00:17:56,640
这个新一代的那个数据库系统吧。其实我觉得是Spanner这篇论文是

253
00:17:56,645 --> 00:18:01,650
是NewSQL这个行业的开端

254
00:18:01,740 --> 00:18:07,050
NewSQL就是新型的SQL，就是历史，大家可以看到这个历史其实是

255
00:18:07,770 --> 00:18:13,080
螺旋发展的一个历史。最早其实

256
00:18:13,085 --> 00:18:15,030
就是这个

257
00:18:15,240 --> 00:18:16,950
比如说像

258
00:18:17,310 --> 00:18:21,330
最早1970年的时候，他发明了这个关系模型

259
00:18:21,630 --> 00:18:23,640
然后

260
00:18:25,920 --> 00:18:31,230
MySQL、早期的数据库，全都是这种基于SQL或者说关系模型的数据库

261
00:18:31,530 --> 00:18:36,840
中间可能这个经过了十几20年

262
00:18:37,110 --> 00:18:38,730
NoSQL这个行业的发展

263
00:18:39,030 --> 00:18:44,340
然后大家觉得NoSQL, Not Only SQL是吧，抛弃掉了SQL模型，然后

264
00:18:44,760 --> 00:18:49,290
Key Value键值对支撑了很多这种互联网业务

265
00:18:49,380 --> 00:18:54,690
但最近这两年，大家又开始去回归SQL，因为整个业务的

266
00:18:54,695 --> 00:19:00,000
复杂度已经超过了Key Value，或者说一些NoSQL System能够去表达的

267
00:19:00,060 --> 00:19:02,040
这个极限，所以

268
00:19:03,750 --> 00:19:09,060
所以就诞生了NewSQL这个行业，所以包括像

269
00:19:09,065 --> 00:19:12,840
CockroachDB，包括像TiDB

270
00:19:13,260 --> 00:19:18,570
包括像亚马逊的Aurora，其实这几个最近这一两年

271
00:19:18,575 --> 00:19:23,880
在数据库行业里面特别流行的数据库，其实基本都是

272
00:19:23,885 --> 00:19:26,370
还是走这种关系模型的路线

273
00:19:28,290 --> 00:19:33,600
好，刚才说了这么多关系模型，然后

274
00:19:33,605 --> 00:19:38,910
这个不可避免的就是我们要去介绍一下

275
00:19:38,915 --> 00:19:42,270
这个Relational Database

276
00:19:44,700 --> 00:19:50,010
其实刚才说了这么多Relation Database, Relational到底指的啥?

277
00:19:50,015 --> 00:19:54,750
其实很简单，就是关系模型吧

278
00:19:54,810 --> 00:19:56,790
相信这个听众

279
00:19:57,090 --> 00:19:58,740
肯定天天都在用

280
00:19:58,770 --> 00:20:02,970
比如MySQL就是一个很标准的, 有这样一种表的结构

281
00:20:03,330 --> 00:20:06,750
表之间其实有这种互相关联的关系

282
00:20:07,620 --> 00:20:10,950
这个互相关联的关系呢，你需要这个

283
00:20:11,370 --> 00:20:16,680
这个数据库本身提供叫这种SQL，相信大家比较熟悉了

284
00:20:16,685 --> 00:20:21,990
的一个查询语言去做一些数据库的这些表和关系

285
00:20:21,995 --> 00:20:27,300
之间去做查询，做关联, 去做这个修改

286
00:20:27,750 --> 00:20:33,060
这样的一个数据库其实就叫Relational Database, 就是关系模型

287
00:20:33,065 --> 00:20:38,370
就是有表, 一行一行, 一列一列的, 就是简单来说就是类似的

288
00:20:38,375 --> 00:20:42,960
这种Excel电子表格

289
00:20:46,470 --> 00:20:51,780
然后这边介绍几个特别典型的Relational Database

290
00:20:51,785 --> 00:20:52,440


291
00:20:53,580 --> 00:20:58,890
首当其冲，那一定是Oracle，然后Oracle是

292
00:20:58,895 --> 00:21:02,490
我都不用介绍，大家可能都听过

293
00:21:02,670 --> 00:21:07,980
只要在这个行业的人或多或少提到数据库那自然就想到Oracle

294
00:21:08,040 --> 00:21:10,740
Oracle其实是这种

295
00:21:11,010 --> 00:21:16,320
传统的巨头吧，就是传统单机的关系数据库里面，我觉得基本上

296
00:21:16,325 --> 00:21:18,300
是无法超越的

297
00:21:18,480 --> 00:21:23,790
就是它实在是这个久经考验, 各种现在大家看到的

298
00:21:24,210 --> 00:21:25,860
场景

299
00:21:25,980 --> 00:21:30,540
比如说金融行业吧

300
00:21:30,545 --> 00:21:35,850
Oracle在这个行业里，已经变成了

301
00:21:35,855 --> 00:21:36,570
Somehow

302
00:21:36,750 --> 00:21:40,650
事实标准这样的一个

303
00:21:40,770 --> 00:21:46,080
东西，所以当年数据量不大的时候，然后同时又

304
00:21:46,085 --> 00:21:47,940


305
00:21:48,780 --> 00:21:52,860
又有钱，那用Oracle其实是一个

306
00:21:53,010 --> 00:21:55,020
特别特别好的一个选择

307
00:21:56,100 --> 00:21:57,390
它的唯一缺点就是贵

308
00:22:00,030 --> 00:22:05,340
对于这个互联网公司就是觉得我的

309
00:22:05,345 --> 00:22:10,650
数据量可能增长特别快，然后如果我都是

310
00:22:10,655 --> 00:22:13,380
小业务，每个业务有一个业务线

311
00:22:13,410 --> 00:22:18,720
每一个需求场景我都用Oracle的话，那肯定用不起

312
00:22:18,725 --> 00:22:23,370
在开源社区，有没有这个数据库呢

313
00:22:23,430 --> 00:22:28,740
那自然就是MySQL，其实有个网站

314
00:22:28,745 --> 00:22:30,390
叫DB Engines

315
00:22:30,420 --> 00:22:35,730
然后DB Engines是其实是一个相当于数据库的

316
00:22:36,030 --> 00:22:41,340
兵器谱兵器榜，全球流行的数据库

317
00:22:41,520 --> 00:22:46,830
排名第一，Oracle, 这刚才说过了，排名第二就是MySQL

318
00:22:47,070 --> 00:22:52,380
如果把他放到一个开源的数据库的领域里面，那么

319
00:22:52,385 --> 00:22:54,480
MySQL那其实是第一

320
00:22:54,570 --> 00:22:56,460
就是目前来说

321
00:22:56,465 --> 00:22:57,480
最流行

322
00:22:57,630 --> 00:23:02,940
广泛使用的开源的关系型数据库，其实MySQL这个发展历史很有

323
00:23:02,945 --> 00:23:03,570
意思

324
00:23:03,660 --> 00:23:08,970
他如果刚才其实回忆起那个History那块的话，大家就能

325
00:23:08,975 --> 00:23:14,280
看见MySQL其实是跟着互联网的诞生一起

326
00:23:14,285 --> 00:23:16,560
成长起来的，所以

327
00:23:16,740 --> 00:23:22,050
整个MySQL的这个开发迭代功能的

328
00:23:22,055 --> 00:23:24,660


329
00:23:24,810 --> 00:23:26,400
MySQL本身的发展

330
00:23:26,460 --> 00:23:31,770
就非常的意思, 就是他其实特别强调这个东西的易用性，开箱即用

331
00:23:31,775 --> 00:23:37,080
社区区非常活跃，实现了这些功能，什么都非常

332
00:23:37,085 --> 00:23:40,290
接地气，然后你想包括

333
00:23:40,410 --> 00:23:45,720
在MySQL 5.5之前, InnoDB引入之前，其实原来

334
00:23:45,725 --> 00:23:51,030
用的是这种MyISAM这样的，这种存储的

335
00:23:51,035 --> 00:23:54,060
存储引擎，根本没有ACID事务

336
00:23:54,150 --> 00:23:59,460
但是对于互联公司来说，那我的业务很多时候就是糟快猛

337
00:23:59,465 --> 00:24:01,230
你能帮我把这个业务搞定就好

338
00:24:01,320 --> 00:24:06,630
丢点数据我无所谓，或者说我可以通过业务层去取work around

339
00:24:06,635 --> 00:24:07,260


340
00:24:07,560 --> 00:24:12,870
但是你一定要给我开箱即用，然后很快的帮我把这个业务

341
00:24:12,875 --> 00:24:13,500
做出来

342
00:24:13,505 --> 00:24:18,810
所以其实MySQL就是在这样的一个这种

343
00:24:18,815 --> 00:24:24,120
背景下诞生的，而且他的成长离累Linux,

344
00:24:24,125 --> 00:24:29,430
PHP，大家可以看到有个缩写LAMP

345
00:24:29,435 --> 00:24:30,030


346
00:24:30,330 --> 00:24:31,650
LAMP其实就是

347
00:24:31,770 --> 00:24:37,080
可能上岁数的人还知道, 年轻的同学可能

348
00:24:37,290 --> 00:24:38,220
已经不太知道了

349
00:24:38,580 --> 00:24:43,410
LAMP就是当年开发这个

350
00:24:43,470 --> 00:24:48,780
互联网站的一个非常流行的技术栈，它是四个单词的缩写

351
00:24:49,410 --> 00:24:50,970
L是Linux

352
00:24:51,210 --> 00:24:52,710
A是Apache

353
00:24:52,770 --> 00:24:58,080
就是Apache Web Server, 然后M是MySQL

354
00:24:58,530 --> 00:24:59,730
P是PHP

355
00:24:59,880 --> 00:25:05,190
这几个全都是Open Source, 都是开源，你可以通过这几个东西，这条技术栈

356
00:25:05,195 --> 00:25:09,780
用纯开源的技术，搭建一个

357
00:25:09,960 --> 00:25:11,490


358
00:25:11,520 --> 00:25:16,560
搭建一个网站，当年是非常流行的一个技术栈

359
00:25:17,010 --> 00:25:20,130
然后

360
00:25:20,160 --> 00:25:22,860
其实说到MySQL，大概在它

361
00:25:23,640 --> 00:25:28,950
5.6以后，差不多十年前

362
00:25:28,955 --> 00:25:33,690
MySQL其实间接被这个Oracle收购了

363
00:25:33,900 --> 00:25:39,210
为什么说间接，因为MySQL原来是被Sun收购了，然后后来Oracle

364
00:25:39,215 --> 00:25:44,280
把Sun给收购掉，然后MySQL

365
00:25:44,310 --> 00:25:47,070
就相当于被Oracle收购掉了

366
00:25:47,640 --> 00:25:52,440
其实在我看来，MySQL被Oracle收购掉以后

367
00:25:52,530 --> 00:25:53,610


368
00:25:54,840 --> 00:25:59,520
虽然有很多社区的小伙伴觉得

369
00:25:59,790 --> 00:26:05,100
MySQL被老大哥给

370
00:26:05,250 --> 00:26:06,480


371
00:26:06,660 --> 00:26:11,970
给消灭掉了，但其实在我看来

372
00:26:11,975 --> 00:26:14,310
就可能有些这种商业化的这个

373
00:26:14,520 --> 00:26:18,120
色彩在里面，不像原来这么

374
00:26:18,150 --> 00:26:23,460
Open Source, 这么自由了，但是其实在我看来Oracle

375
00:26:23,465 --> 00:26:28,770
介入使得MySQL这个项目的

376
00:26:28,775 --> 00:26:34,080
活力和生命力越来越强，包括5.6, 5.7

377
00:26:34,085 --> 00:26:35,550


378
00:26:35,700 --> 00:26:41,010
包括现在的MySQL 8.0，每一个大版本，它的进步都非常的大

379
00:26:41,580 --> 00:26:46,890
毕竟是有这种专业的做数据库的团队Oracle的底蕴摆在那

380
00:26:46,895 --> 00:26:52,200
然后另外一个方向是这个MariaDB

381
00:26:52,590 --> 00:26:57,150
就是MariaDB是在MySQL被收购了以后

382
00:26:57,360 --> 00:26:59,640
然后

383
00:26:59,670 --> 00:27:04,980
原来MySQL团队的一些人，包括Monty就是

384
00:27:04,985 --> 00:27:07,440
MySQL的创始人

385
00:27:07,620 --> 00:27:11,640
出来单独搞了MySQL的一个分支

386
00:27:11,645 --> 00:27:13,590
然后继续保持着这种

387
00:27:13,710 --> 00:27:19,020
完全中立，独立，MariaDB其实是背后有个基金会，Maria DB Foundation

388
00:27:19,800 --> 00:27:25,110
然后保持这个自由软件的

389
00:27:26,760 --> 00:27:27,390


390
00:27:27,720 --> 00:27:28,680
的姿态吧

391
00:27:31,560 --> 00:27:36,870
说完这个MySQL，第二个比较重要的就是Postgres

392
00:27:37,050 --> 00:27:38,190


393
00:27:38,400 --> 00:27:43,710
其实听到Postgres的话，大家可能第一反应就是，这是一个从

394
00:27:43,715 --> 00:27:49,020
学术圈儿出来了，这个数据库，没错，Postgres

395
00:27:49,025 --> 00:27:54,330
归根结底吧，就是梳理一下它的

396
00:27:54,335 --> 00:27:59,640
这个创始人创神的师傅什么其实能梳理到Michael Stonebraker

397
00:27:59,645 --> 00:28:04,950
Michael Stonebraker，大家如果是做数据库

398
00:28:04,955 --> 00:28:07,170
学术研究的同学

399
00:28:07,290 --> 00:28:12,600
这肯定是如雷贯耳的一个名字啊，这个基本上是数据库的

400
00:28:12,660 --> 00:28:17,970
SQL数据库这块奠基人，这个技术的奠基人之一，然后

401
00:28:17,975 --> 00:28:20,670
以后以前前几年我不记得哪一年了

402
00:28:20,700 --> 00:28:23,220
也是刚拿了这个图灵奖

403
00:28:23,250 --> 00:28:25,530
这属于计算机

404
00:28:25,680 --> 00:28:28,410
领域里面最高的学术成就了

405
00:28:28,980 --> 00:28:34,110
PG的话，它的一个特点就是

406
00:28:34,320 --> 00:28:38,160
一是它把很多

407
00:28:38,165 --> 00:28:43,470
学术界的一些想法，其实就直接实现在数据库里

408
00:28:43,590 --> 00:28:48,750
比如说相比MySQL来说，它的隔离级别

409
00:28:48,840 --> 00:28:51,810
它的SQL优化器

410
00:28:51,990 --> 00:28:57,300
在有些场景下，其实做得会更好，包括它的代码其实是一个更加

411
00:28:57,305 --> 00:28:58,200


412
00:28:58,290 --> 00:29:03,600
模块化结构化的Code Base，然后

413
00:29:03,605 --> 00:29:07,890
它其实也比MySQL支持更强大的这种

414
00:29:08,040 --> 00:29:13,350
可编程SQL，就是PL/SQL

415
00:29:13,355 --> 00:29:18,660
在PG里面叫PG SQL，其实有点像Oracle的

416
00:29:18,665 --> 00:29:23,970
PL/SQL的支持，所以其实大家有很多的时候

417
00:29:23,975 --> 00:29:29,280
如果你的业务重度依赖Oracle的

418
00:29:29,285 --> 00:29:31,410
存储过程，这样的这些

419
00:29:31,590 --> 00:29:36,900
可编程SQL的话，虽然现在

420
00:29:36,905 --> 00:29:42,210
整个大的趋势就是说存储过程基本都要放在业务层去做重新的改写

421
00:29:42,215 --> 00:29:44,730
但是如果有一些确实

422
00:29:44,880 --> 00:29:50,190
比较难以改写的话，有很多数据库有很多用户其实

423
00:29:50,195 --> 00:29:55,500
倾向于通过Postgres去替换掉原来的Oracle的这种存储过程

424
00:29:56,490 --> 00:30:01,800
而且Postgres更早的支持了很多新的功能

425
00:30:02,430 --> 00:30:04,560
比如说像JSON

426
00:30:05,130 --> 00:30:07,320
可以去操作这种

427
00:30:07,530 --> 00:30:12,840
JSON这样的数据格式的行

428
00:30:13,110 --> 00:30:18,420
然后包括Postgres其实很早就支持地理信息这种

429
00:30:18,870 --> 00:30:20,820
比如说

430
00:30:20,970 --> 00:30:26,280
Geo Hash，比如说坐标

431
00:30:26,285 --> 00:30:31,590
然后你要去求一个范围这种请求

432
00:30:31,595 --> 00:30:33,390
就是GIS

433
00:30:33,900 --> 00:30:34,710


434
00:30:34,950 --> 00:30:40,260
但是其实Postgres，从过去来看吧，因为

435
00:30:40,265 --> 00:30:45,570
它的系统比较复杂，而且社区其实并没有MySQL这么活跃

436
00:30:46,080 --> 00:30:47,040
过去

437
00:30:47,130 --> 00:30:51,150
包括现在其实也是，从绝对数量来说

438
00:30:51,210 --> 00:30:55,530
整个MySQL的社区和用户还是更多

439
00:30:55,890 --> 00:31:01,200
但是其实Postgres的增速其实比较快，特别是这几年

440
00:31:01,530 --> 00:31:05,250
在美国在欧洲其实有很多

441
00:31:05,340 --> 00:31:10,650
开发者吧慢慢地在开始

442
00:31:10,655 --> 00:31:15,960
喜欢这个Postgres，有几个好处吧，就是Postgres这个License

443
00:31:16,470 --> 00:31:21,630
更加的友好，相比MySQL来说

444
00:31:24,270 --> 00:31:29,460
但是刚才说那几个数据库都是单机型的数据库

445
00:31:29,820 --> 00:31:35,130
其实我刚刚也提到了，就是摩尔定律在某些程度上已经

446
00:31:35,135 --> 00:31:37,200
这几年已经失效了

447
00:31:37,380 --> 00:31:42,630
所以，无论你的单机型的数据库做得再好

448
00:31:42,810 --> 00:31:48,120
通过增强单机的计算能力去拓展你的业务这条路肯定

449
00:31:48,125 --> 00:31:53,430
走不通了，所以无论如何总是要去探索出一条

450
00:31:53,435 --> 00:31:56,490
分布式的解决方案

451
00:31:57,000 --> 00:32:00,210
而且说现在这个业务发展越来越复杂

452
00:32:00,390 --> 00:32:02,340


453
00:32:02,460 --> 00:32:07,770
一个分布系统里边你很难去保证你的单点不会

454
00:32:07,775 --> 00:32:09,150


455
00:32:09,240 --> 00:32:14,550
挂掉，比如说你的数据库挂了，你整个网站起不来了，其实影响挺大的

456
00:32:14,760 --> 00:32:17,220
就是说只有分布式系统能去

457
00:32:17,400 --> 00:32:22,710
做到这种几乎100%的SLA或者说

458
00:32:22,860 --> 00:32:27,180
100%的Online时间

459
00:32:29,460 --> 00:32:30,300


460
00:32:30,690 --> 00:32:36,000
说完数据库，Relational Database

461
00:32:36,005 --> 00:32:41,280
开始展开其他的这种数据库的分支之前我想去

462
00:32:41,670 --> 00:32:43,800
聊些特别基础的东西

463
00:32:44,040 --> 00:32:49,350
就是说，我们还看到了数据库的一个产品形态，然后

464
00:32:49,980 --> 00:32:53,400
呃，它到底底层是通过什么样的东西

465
00:32:53,850 --> 00:32:54,870
构成的

466
00:32:54,900 --> 00:32:56,010
或者说

467
00:32:56,700 --> 00:33:01,020
到底数据是怎么存储在

468
00:33:01,025 --> 00:33:02,550
计算机上

469
00:33:04,800 --> 00:33:07,260
这块我觉得非常重要

470
00:33:07,410 --> 00:33:09,270
存储引擎

471
00:33:11,190 --> 00:33:16,500
存储引擎，其实一句话来说，它就是Database中的

472
00:33:16,505 --> 00:33:17,280
Database

473
00:33:17,850 --> 00:33:23,160
大家其实都上过大学计算机有门课叫

474
00:33:23,165 --> 00:33:28,470
数据结构是吧，就是数据结构里面大家可能还会记得各种树

475
00:33:28,800 --> 00:33:29,730


476
00:33:29,760 --> 00:33:34,680
什么二叉树，B树

477
00:33:34,685 --> 00:33:35,280


478
00:33:36,150 --> 00:33:41,460
大学的课程应该没有介绍，没有介绍过LSM-Tree

479
00:33:42,060 --> 00:33:43,350
一会儿他讲一下

480
00:33:44,070 --> 00:33:45,690
其实

481
00:33:45,810 --> 00:33:51,120
你可以认为这个数据库的软件只是

482
00:33:51,125 --> 00:33:55,200
一个在底层存储引擎上的一个包装

483
00:33:55,590 --> 00:34:00,900
就是上面去构建SQL，这个SQL去解析用户的查询

484
00:34:01,590 --> 00:34:06,660
插入，修改，然后将这些数据的变更

485
00:34:06,780 --> 00:34:08,790
转移到

486
00:34:09,180 --> 00:34:12,900
存储引擎上面，然后存储引擎把它写到磁盘上

487
00:34:14,310 --> 00:34:18,210
然后我今天主要会介绍两种

488
00:34:18,270 --> 00:34:23,580
比较著名的，或者说特别常用的

489
00:34:24,030 --> 00:34:25,110
数据结构

490
00:34:25,830 --> 00:34:28,470
一个B-Tree，一个叫LSM-Tree

491
00:34:30,510 --> 00:34:35,820
其实B+树在整个行业内部

492
00:34:35,825 --> 00:34:37,680
其实过去

493
00:34:37,830 --> 00:34:41,700
然后现在其实也有很多数据库在使用

494
00:34:41,850 --> 00:34:46,140
比如说最有名的B树的实现就是InnoDB了

495
00:34:46,200 --> 00:34:49,080
InnoDB其实是MySQL

496
00:34:49,380 --> 00:34:54,690
从5.5以后，官方默认的存储引擎

497
00:34:54,990 --> 00:34:57,330
然后

498
00:34:57,660 --> 00:34:59,700
其实B+树的话

499
00:34:59,730 --> 00:35:05,040
它的原理也很简单，它是一个多叉树，每一个

500
00:35:05,045 --> 00:35:05,880
这个

501
00:35:05,910 --> 00:35:11,220
叶子，其实是一个叫做Page的这个

502
00:35:11,520 --> 00:35:16,830
数据结构，它其实核心的思想就是大家知道数据库

503
00:35:16,835 --> 00:35:19,680
经常会有这种随机的访问

504
00:35:19,685 --> 00:35:21,240
IO的访问

505
00:35:22,200 --> 00:35:27,510
B-Tree诞生的年代，我们还没有固态硬盘，这么一个

506
00:35:27,515 --> 00:35:28,260
说法

507
00:35:28,440 --> 00:35:29,280
所以

508
00:35:29,310 --> 00:35:34,620
大家知道过去的磁盘都是有磁头磁盘，是HDD这样的

509
00:35:34,920 --> 00:35:38,100
这种设备，磁头的移动其实是很慢的

510
00:35:38,640 --> 00:35:39,390
所以

511
00:35:39,630 --> 00:35:44,940
就是尽可能的，你每一次IO每一次读或者写都是

512
00:35:44,945 --> 00:35:47,940
尽可能是读一批或者写一批

513
00:35:47,945 --> 00:35:52,290
然后比如说对于读请求来说，我的这个

514
00:35:52,560 --> 00:35:57,870
大概率我这一次读，我的下一次读，如果就在下一个

515
00:35:57,875 --> 00:36:00,090
离得比较近的话

516
00:36:00,630 --> 00:36:05,940
全都来这么读写这样的，把这个相近的数据都读

517
00:36:05,945 --> 00:36:06,660
出来

518
00:36:06,665 --> 00:36:10,140
这个效率和性能其实是比较好的

519
00:36:10,145 --> 00:36:15,450
就避免了很多随机的，无谓的

520
00:36:15,455 --> 00:36:16,830
磁头的移动

521
00:36:16,920 --> 00:36:19,440
整个性能会好一些

522
00:36:19,860 --> 00:36:20,550
对

523
00:36:22,290 --> 00:36:24,810
然后

524
00:36:25,380 --> 00:36:30,690
对，那是B-Tree，然后B-Tree我也不展开讲了，就是说它对于这种

525
00:36:30,695 --> 00:36:35,670
传统数据库来说，基本上

526
00:36:36,600 --> 00:36:41,910
算是唯一的一个选择吧，或多或少都跟这个B-Tree

527
00:36:42,450 --> 00:36:43,350
会比较像

528
00:36:43,680 --> 00:36:44,580
然后

529
00:36:47,010 --> 00:36:52,170
但最近几年其实有一个新的数据结构

530
00:36:52,230 --> 00:36:57,540
特别流行，就包括其实现在新一代的数据库基本都是以

531
00:36:57,630 --> 00:37:01,170
这个结构来设计的

532
00:37:01,470 --> 00:37:03,900
这个数据就叫LSM-Tree

533
00:37:04,410 --> 00:37:09,720
其实最有名的第一个LSM-Tree

534
00:37:10,200 --> 00:37:12,960
把LSM-Tree带入大家

535
00:37:13,140 --> 00:37:14,640


536
00:37:14,645 --> 00:37:15,960
视野里边

537
00:37:16,350 --> 00:37:18,060
的项目

538
00:37:18,090 --> 00:37:19,320
或者说公司吧

539
00:37:19,380 --> 00:37:21,210
就是谷歌，还是谷歌

540
00:37:21,215 --> 00:37:24,690
Google在实现他们的BigTable

541
00:37:24,900 --> 00:37:30,210
我刚提到的那个NoSQL的那个系统的时候

542
00:37:30,215 --> 00:37:34,350
其实在底层的存储的数据构就是LSM-Tree

543
00:37:34,440 --> 00:37:35,610
然后

544
00:37:35,730 --> 00:37:40,620
同时，谷歌也开源了一个很有趣的开源项目叫

545
00:37:40,710 --> 00:37:41,910
LevelDB

546
00:37:41,970 --> 00:37:42,930


547
00:37:43,140 --> 00:37:46,770
就是一个非常经典的LSM-Tree的一个开源实现

548
00:37:47,250 --> 00:37:52,560
因为今天不是一个计算机的理论课程

549
00:37:52,565 --> 00:37:54,450
所以

550
00:37:55,200 --> 00:38:00,510
我就简单的用一个比较感性的说法来解解一下LSM-Tree

551
00:38:00,810 --> 00:38:02,910
我们其实提到就磁盘

552
00:38:03,180 --> 00:38:08,220
那个随机的读写其实开销是特别大的

553
00:38:08,310 --> 00:38:10,680
那我能不能

554
00:38:11,340 --> 00:38:14,850
把所有的写全都变成顺序写

555
00:38:15,750 --> 00:38:21,060
然后

556
00:38:21,065 --> 00:38:24,150
在我的这个数据结构里边，然后

557
00:38:25,980 --> 00:38:31,290
因为大家知道，数据库里有个操作叫更新，更新的话

558
00:38:31,295 --> 00:38:33,840
你需要去找到那一个

559
00:38:33,845 --> 00:38:36,960
老的位置，然后去把它修改成一个新的值

560
00:38:37,860 --> 00:38:42,480
但是，在LSM-Tree里面并不是这样的，它每一个

561
00:38:42,485 --> 00:38:46,560
修改或者写入，不管是UPDATE，还是INSERT

562
00:38:46,650 --> 00:38:48,840
都是对应的一条

563
00:38:49,170 --> 00:38:51,300
Append Only

564
00:38:51,330 --> 00:38:56,640
就是追加的日志，然后它是在后期不停地

565
00:38:56,645 --> 00:38:58,110
去做这个

566
00:38:58,170 --> 00:38:59,940


567
00:39:00,030 --> 00:39:00,960
Compaction

568
00:39:01,170 --> 00:39:06,480
相当于把一个随机IO变成了

569
00:39:06,485 --> 00:39:07,200


570
00:39:07,410 --> 00:39:08,460
所有

571
00:39:09,000 --> 00:39:14,310
全都变成了顺序IO，但是它不可避免地会引起要多写很多

572
00:39:14,520 --> 00:39:19,830
很多遍，有些数据可能要多写很多遍，但是它的好处就是说把随机IO

573
00:39:19,835 --> 00:39:21,150
变成了顺序IO

574
00:39:21,270 --> 00:39:26,580
代价就是他可能对这个，比如你的写入会有

575
00:39:26,585 --> 00:39:29,340
写入放大，因为同一块数据，它可能在

576
00:39:29,370 --> 00:39:32,970
就是不停的去做每一次Compaction都得重新写一次

577
00:39:33,030 --> 00:39:37,110
然后另外一点就是对于热数据

578
00:39:37,350 --> 00:39:40,020
它不像

579
00:39:40,170 --> 00:39:45,480
B-Tree，通过一个内存中的索引，找到相应的Page，把它读出来

580
00:39:45,485 --> 00:39:50,790
LSM-Tree其实在内存中是

581
00:39:50,795 --> 00:39:52,290
会去

582
00:39:52,320 --> 00:39:57,630
比如说它的越热的数据会在这个树上的，越靠前的Level

583
00:39:57,960 --> 00:40:03,270
同时，在一些实现里面会有类似Block Cache这种内存缓存

584
00:40:04,260 --> 00:40:09,570
所以本质来说，它的两个数据，一个在磁盘上

585
00:40:09,575 --> 00:40:14,880
一个在内存里面

586
00:40:14,885 --> 00:40:17,160


587
00:40:17,760 --> 00:40:23,070
就是你的热数据，其实都会在内存里，所以你的这个机器的内存越大，对于这个

588
00:40:23,075 --> 00:40:28,350
LSM-Tree来说，性能就越好，另外一个

589
00:40:28,800 --> 00:40:33,480
特别大的一个优点，对于LSM-Tree来说，相比B-Tree

590
00:40:33,690 --> 00:40:38,430
它的实现的难度其实是比B-Tree要小很多

591
00:40:38,730 --> 00:40:39,930
就是其实

592
00:40:39,960 --> 00:40:45,270
你去看来LevelDB的代码，因为他的整个这个算法，实现其实

593
00:40:45,510 --> 00:40:46,410
比较简单

594
00:40:46,440 --> 00:40:51,300
相比如果要去实现一个非常

595
00:40:51,690 --> 00:40:53,790
稳定或高效的B-Tree

596
00:40:53,820 --> 00:40:58,620
的话，LSM-Tree其实是一个比较简单的一个数据结构

597
00:40:59,940 --> 00:41:05,250
所以新一代的，而且特别像现在LevelDB, RocksDB这些比较流行的开源的

598
00:41:05,255 --> 00:41:06,930
LSM-Tree的实现

599
00:41:07,110 --> 00:41:11,730
基本上让这些新一代的数据库厂商

600
00:41:11,940 --> 00:41:13,200
开箱即用吧

601
00:41:14,940 --> 00:41:20,250
但是除了刚才说的这个LSM-Tree, B-Tree，其实整个学术界也好，工业界也好

602
00:41:20,255 --> 00:41:21,510
还是有一些

603
00:41:21,690 --> 00:41:27,000
其他的这种存储引擎，比如说，比如说BW-Tree是这个

604
00:41:27,900 --> 00:41:32,460
微软的前几年吧，发表的一篇

605
00:41:32,465 --> 00:41:34,560
发明的一个新的数据结构

606
00:41:34,710 --> 00:41:36,960
然后它是针对这种

607
00:41:37,050 --> 00:41:42,360
这个高性能的SSD设计的一种，结合了

608
00:41:43,140 --> 00:41:47,550
B-Tree跟LSM-Tree优点的数据结构

609
00:41:47,970 --> 00:41:53,280
然后包括TokuDB是一个压缩比

610
00:41:53,285 --> 00:41:58,590
特别好的数据库，然后他用了一个算法叫分形树

611
00:41:59,490 --> 00:42:02,580


612
00:42:02,760 --> 00:42:07,290
然后它可以获得一个非常非常好的压缩比

613
00:42:07,410 --> 00:42:11,550
然后在不牺牲特别多的读写性能的

614
00:42:11,610 --> 00:42:13,770
前提下，压缩比特别高

615
00:42:14,250 --> 00:42:19,560
WiscKey是在LSM-Tree上去减少，刚才我说，LSM-Tree一个特别大

616
00:42:19,565 --> 00:42:20,760
问题是写放大

617
00:42:21,150 --> 00:42:26,460
但是用来去解决这个写放大的

618
00:42:26,465 --> 00:42:28,320
LSM-Tree上的优化

619
00:42:31,290 --> 00:42:35,790
好，说完了存储引擎，下一个部分是

620
00:42:36,240 --> 00:42:41,550
其实我一开始就提到最近几年一个特别重要的事情是这个NoSQL运动

621
00:42:41,555 --> 00:42:42,210


622
00:42:42,480 --> 00:42:43,590
就是NoSQL

623
00:42:43,740 --> 00:42:46,920
NoSQL并不是

624
00:42:47,190 --> 00:42:52,500
不要SQL的意思，就是刚刚我也说的，这是Not Only SQL

625
00:42:52,505 --> 00:42:53,940
就是不仅仅有SQL

626
00:42:54,150 --> 00:42:56,220
的意思就是这个

627
00:42:56,340 --> 00:43:01,320
其实这个词也是很多互联公司提出来的

628
00:43:01,530 --> 00:43:03,300
数据量越来越大

629
00:43:03,360 --> 00:43:06,660
大家发现这种单机的传统的数据库搞不定了

630
00:43:06,990 --> 00:43:07,680


631
00:43:07,920 --> 00:43:13,230
就只好自己去做一些新的这个模型或者新的数据库来去

632
00:43:13,235 --> 00:43:15,480
解决这个问题

633
00:43:17,190 --> 00:43:17,790
对

634
00:43:19,440 --> 00:43:24,690
然后其实Not Only SQL

635
00:43:24,780 --> 00:43:27,540
NoSQL，其实有很多数据库

636
00:43:27,930 --> 00:43:30,270
放弃掉了这个

637
00:43:30,275 --> 00:43:33,000
对于一个数据库来说最重要的东西

638
00:43:33,030 --> 00:43:33,960
就是

639
00:43:34,710 --> 00:43:36,330
一致性

640
00:43:38,220 --> 00:43:43,530
比如说这个是一个Notice

641
00:43:43,535 --> 00:43:44,400
CouchDB

642
00:43:44,910 --> 00:43:47,640


643
00:43:47,730 --> 00:43:53,040
CouchDB它在1.0.1的发布

644
00:43:53,160 --> 00:43:56,280
里面的一个Release里写

645
00:43:56,700 --> 00:44:01,710
1.0，还有一个特别Critical的Bug，which can lead to data loss

646
00:44:01,920 --> 00:44:06,270
就是会造成数据丢失的严重Bug

647
00:44:06,810 --> 00:44:09,930
写了个relax，然后

648
00:44:10,530 --> 00:44:15,450
你想，这个数据库会丢数据，

649
00:44:15,870 --> 00:44:21,180
一个数据库会丢数据，结果还有很多人还在去用

650
00:44:21,300 --> 00:44:22,620


651
00:44:23,340 --> 00:44:27,300
其实对于NoSQL来说，我觉得在

652
00:44:27,630 --> 00:44:32,940
这个一致性上面其实做了一些妥协，因为其实也有道理，对于很多业务场景来说

653
00:44:32,945 --> 00:44:33,960


654
00:44:34,080 --> 00:44:37,650
你的数据写下去，读不出来或者数据丢了

655
00:44:37,680 --> 00:44:39,510
可能问题并没有这么大

656
00:44:39,900 --> 00:44:42,180
比如说这个，举个例子

657
00:44:42,240 --> 00:44:43,410


658
00:44:43,920 --> 00:44:47,100
大家其实平时用什么微博之类的是吧

659
00:44:48,300 --> 00:44:52,890
你少看一条微博，或者比如说别人发一条微博，你没看见

660
00:44:53,010 --> 00:44:54,300
这个也不会

661
00:44:54,660 --> 00:44:57,480
引起什么世界末日之类

662
00:44:57,720 --> 00:45:00,000
也不会像丢了钱这样敏感

663
00:45:00,450 --> 00:45:03,060
不会，就是少看一条微博是吧

664
00:45:03,600 --> 00:45:06,900
或者说没有这么及时能够看得到

665
00:45:07,110 --> 00:45:07,920
也没事

666
00:45:08,160 --> 00:45:13,470
所以很多这种互联网的业务的这个特点就使得整个NoSQL

667
00:45:13,475 --> 00:45:17,430
其实在互联网行业里面发展的最快最好的

668
00:45:18,930 --> 00:45:20,580
因为SQL其实

669
00:45:22,740 --> 00:45:28,050
它为了去支持这些比较复杂的这些事务的模型，包括SQL的

670
00:45:28,055 --> 00:45:32,310
这些模型，它在扩展性上其实是比较难做的

671
00:45:32,520 --> 00:45:37,830
另外一点就是，对于一些比较极端的场景，如果去做这种事务的

672
00:45:37,835 --> 00:45:39,630
操作的话

673
00:45:39,635 --> 00:45:42,390
可能会带来额外的性能损失

674
00:45:44,310 --> 00:45:46,200


675
00:45:46,230 --> 00:45:51,540
其实刚才我也提到，在整个NoSQL的这个行业里,最重要的

676
00:45:51,870 --> 00:45:57,180
两个公司或者说奠基的公司吧，就是Google和这个Amazon

677
00:45:57,420 --> 00:45:58,950


678
00:45:59,490 --> 00:46:04,800
GFS就Google的文件系统，MapReduce, BigTable加上

679
00:46:04,805 --> 00:46:07,980
这个亚马逊的这边这个Dynamo的论文

680
00:46:08,280 --> 00:46:13,590
这四篇论文基本上是整个我个人认为是NoSQL

681
00:46:13,595 --> 00:46:17,790
这个运动包括大数据运动的开端

682
00:46:21,420 --> 00:46:26,730
所以就是说到NoSQL就不得不介绍BigTable

683
00:46:27,990 --> 00:46:29,610
BigTable

684
00:46:30,300 --> 00:46:35,610
其实这是BigTable的简单的一个介绍，就是大家知道

685
00:46:35,615 --> 00:46:40,920
Gooble内部的数据特别大特别是它去爬取这些

686
00:46:41,370 --> 00:46:46,020
网站啊，还有这些页面的时候还要去做这种倒排索引

687
00:46:46,350 --> 00:46:47,520
所以的

688
00:46:47,610 --> 00:46:49,680
然后它数据量其实是

689
00:46:49,950 --> 00:46:52,590
远大于一个单机数据库能承载的量

690
00:46:52,800 --> 00:46:56,160
所以它相当于要去设计一个这种纯分布式的

691
00:46:56,370 --> 00:46:57,600
存储系统

692
00:46:57,630 --> 00:47:02,940
然后去存储几乎无穷大的数据

693
00:47:02,945 --> 00:47:08,250
然后可能整个系统由上千台服务器来构成

694
00:47:08,730 --> 00:47:10,920
然后在业务层看来就是一个数据库

695
00:47:11,010 --> 00:47:13,800
但它的底下是一个纯分布式的系统

696
00:47:14,790 --> 00:47:18,960
然后它在数据模型上，其实也是放弃掉了这种传统的关系模型

697
00:47:19,230 --> 00:47:24,540
他其实是一个Key，然后加上Value这样的这种形式

698
00:47:24,545 --> 00:47:28,590
是一个映射表的模型

699
00:47:31,680 --> 00:47:36,990
这个是BigTable的基础架构，这边我其实也

700
00:47:37,260 --> 00:47:38,100
不想

701
00:47:38,580 --> 00:47:41,040
去展开去说，然后

702
00:47:43,710 --> 00:47:48,960
其实核心来说就是它把数据拆成了一个一个

703
00:47:49,050 --> 00:47:53,070
叫这种Tablet的逻辑单元，每一个Tablet就是

704
00:47:53,280 --> 00:47:58,590
一小块数据，他其实整体来说Share Nothing

705
00:47:58,620 --> 00:47:59,970
就把数据

706
00:48:00,150 --> 00:48:05,460
把它切成这个无数个小块，然后每一小块一台服务去负责

707
00:48:05,465 --> 00:48:07,320
这样的一个架构

708
00:48:11,190 --> 00:48:15,240
第二个比较重要的系统是这个Dynamo

709
00:48:15,840 --> 00:48:21,150
Dynamo的设计理念非常非常有意思

710
00:48:23,310 --> 00:48:27,090
如果要是说

711
00:48:27,120 --> 00:48:32,430
传统数据库是把一致性，然后数据的

712
00:48:32,760 --> 00:48:36,660
事务，SQL，可用性

713
00:48:36,665 --> 00:48:41,640
把灵活性放到第一位的话

714
00:48:41,730 --> 00:48:46,500
Dynamo它的设计理念就是把可用性放在第一位

715
00:48:46,860 --> 00:48:52,170
Always Writable，大家知道亚马逊当时是一个

716
00:48:53,040 --> 00:48:58,350
做电商的公司就是电商，有一些场景就是

717
00:48:58,355 --> 00:49:01,320
我的下订单，或者说订单状态

718
00:49:01,560 --> 00:49:06,870
如果你的服务不可用了，那损失的就是真金白银

719
00:49:06,875 --> 00:49:09,240
所以呢，他对于

720
00:49:09,360 --> 00:49:13,620
亚马逊对于它的数据库的SLA的要求是非常非常高的

721
00:49:14,280 --> 00:49:15,720
就是

722
00:49:17,820 --> 00:49:19,050


723
00:49:19,560 --> 00:49:22,350
这个数据其实是它的这个

724
00:49:23,880 --> 00:49:29,190
一个典型的峰值的要求的

725
00:49:29,195 --> 00:49:31,440
数据吧，就是说他需要对

726
00:49:31,770 --> 00:49:37,080
比如99.9%的查询都需要在300毫秒以内有返回

727
00:49:37,140 --> 00:49:42,450
然后峰值

728
00:49:42,570 --> 00:49:46,410
至少达到500 TPS

729
00:49:46,860 --> 00:49:52,170
但其实这篇论文是大概07年发表的，这个性能和可用性

730
00:49:52,175 --> 00:49:53,370
在今天看来

731
00:49:53,430 --> 00:49:56,100
还是比较简单的，但放在当年还是比较

732
00:49:56,460 --> 00:50:00,150
可能是比较重要的一个（指标）

733
00:50:00,390 --> 00:50:01,020


734
00:50:04,770 --> 00:50:07,590
然后

735
00:50:07,680 --> 00:50:12,990
我会再反过来说Dynamo那么多，因为Dynamo一直都没有开源

736
00:50:12,995 --> 00:50:14,370
所以

737
00:50:14,490 --> 00:50:16,320
包括BigTable也没有开源

738
00:50:16,530 --> 00:50:21,840
所以其实有几个开源界的系统

739
00:50:21,845 --> 00:50:27,150
去实现刚才我说那两个东西，一个BigTable，一个Dynamo

740
00:50:27,155 --> 00:50:31,230
第一个是Hadoop，Hadoop其实我刚才给他说了，是这个由雅虎

741
00:50:31,590 --> 00:50:36,900
牵头开始做，然后现在基本成为大数据处理平台的

742
00:50:36,905 --> 00:50:38,820
事实标准

743
00:50:39,210 --> 00:50:44,520
其实刚才说的BigTable在Google内部也是基于

744
00:50:44,525 --> 00:50:49,830
Google的分布式文件系统，这个GFS去构建的，然后它并不是

745
00:50:49,835 --> 00:50:54,300
一个简简单单的独立的数据库，而是一整套

746
00:50:54,450 --> 00:50:55,860
技术平台

747
00:50:55,980 --> 00:51:01,290
所以Hadoop其实是一个整体的，也是一个技术平台，它有像比如说HDFS

748
00:51:01,950 --> 00:51:05,820
比如像MapReduce组件，比如说ZooKeeper

749
00:51:05,825 --> 00:51:07,530
这个Coordinator

750
00:51:07,710 --> 00:51:12,630
HBase其实是它的结构化数据存储的这一块

751
00:51:12,690 --> 00:51:15,750
它其实是整个这个大的Hadoop中的一部分

752
00:51:17,790 --> 00:51:23,100
然后HBase的设计其实基本就跟BigTable

753
00:51:23,250 --> 00:51:28,560
是一脉相承的，也是把数据拆分成很多

754
00:51:28,650 --> 00:51:32,040
Data Chunk，然后

755
00:51:32,100 --> 00:51:37,320
然后去存储在底下的HDFS这个分布式系统上面

756
00:51:40,350 --> 00:51:42,240
然后Cassandra

757
00:51:44,220 --> 00:51:46,980
Cassandra这个项目

758
00:51:47,670 --> 00:51:51,180
现在是Apache项目吧，最早其实是Facebook

759
00:51:51,510 --> 00:51:52,620
根据

760
00:51:52,890 --> 00:51:58,200
Amazon那篇Dynamo的论文来实现的一个开源的

761
00:51:58,650 --> 00:52:00,000
数据库

762
00:52:00,360 --> 00:52:01,290


763
00:52:01,740 --> 00:52:04,140


764
00:52:04,380 --> 00:52:09,690
Cassandra到现在其实都是一个特别流行的数据库

765
00:52:09,930 --> 00:52:12,390
它有一点好处，就是

766
00:52:12,660 --> 00:52:17,970
它特别创新的一个地方，就是它引入了一个新的一致性的模型

767
00:52:17,975 --> 00:52:19,680
WRN

768
00:52:20,310 --> 00:52:24,840
WRN的话，其实是几个单词的缩写

769
00:52:25,290 --> 00:52:27,060
W是这个

770
00:52:27,600 --> 00:52:31,410
Number of Writer，就是写入

771
00:52:31,590 --> 00:52:32,610
Writers

772
00:52:32,820 --> 00:52:34,230
R是Readers

773
00:52:34,560 --> 00:52:35,460


774
00:52:36,000 --> 00:52:37,710
N是这个

775
00:52:37,715 --> 00:52:39,450
Total Number

776
00:52:39,840 --> 00:52:41,010
什么意思呢

777
00:52:42,810 --> 00:52:45,780
我举个例子，比如说一块数据

778
00:52:45,870 --> 00:52:47,880
有三个副本

779
00:52:48,000 --> 00:52:49,530
比如，假设有三个副本

780
00:52:50,070 --> 00:52:53,700
如果我要保证强一致性

781
00:52:54,210 --> 00:52:59,520
我任何一个节点上都能读到一定是最新的数据的话

782
00:52:59,525 --> 00:53:01,860
我一定要保证，保证什么呢

783
00:53:02,010 --> 00:53:03,060
就是我的

784
00:53:03,540 --> 00:53:08,850
读的副本数加上写的副本数

785
00:53:08,855 --> 00:53:10,470
一定要大于N

786
00:53:10,890 --> 00:53:11,640


787
00:53:11,970 --> 00:53:13,140


788
00:53:13,230 --> 00:53:13,980


789
00:53:14,700 --> 00:53:15,960
大于N没有等于N

790
00:53:15,965 --> 00:53:18,660
因为无论如何，你比如说

791
00:53:18,750 --> 00:53:24,060
我每一次同步写两份才返回给客户端成功

792
00:53:24,065 --> 00:53:24,870


793
00:53:24,900 --> 00:53:25,920
异步写一份

794
00:53:26,250 --> 00:53:31,560
然后我每次读如果是读两份的话，就刚刚我说的W=2

795
00:53:31,590 --> 00:53:32,790
R=2

796
00:53:33,000 --> 00:53:35,790
Total Number等于3, 副本数等于三的时候

797
00:53:36,060 --> 00:53:38,730
2+2=4，4>3

798
00:53:39,060 --> 00:53:44,370
那它一定能够读到最新的数据，因为不可能会出现，我这边写入成功了

799
00:53:44,375 --> 00:53:49,680
然后我一去读读到那个副本，正好是他没有写同步写入的那个

800
00:53:49,685 --> 00:53:50,310
副本

801
00:53:50,700 --> 00:53:53,850
然后这个就可能读到旧的数据了

802
00:53:53,855 --> 00:53:54,450


803
00:53:54,455 --> 00:53:59,760
所以相当于通过去配置这个WRN关系，你可以去配置出

804
00:53:59,765 --> 00:54:01,110
不同的

805
00:54:01,115 --> 00:54:02,610
一致性的级别

806
00:54:02,910 --> 00:54:05,850
所以这也是Cassandra包括Dynamo

807
00:54:05,880 --> 00:54:07,740
比较创新的地方

808
00:54:10,140 --> 00:54:15,450
而且它的数据分布其实是通过一个叫类似于一致性哈希的算法

809
00:54:15,455 --> 00:54:18,990
这个算法我也不展开了

810
00:54:19,050 --> 00:54:21,360
它本质上来说

811
00:54:21,420 --> 00:54:26,730
也是一种让数据达到均匀分布的

812
00:54:26,735 --> 00:54:29,010
在多台机器之间达到均匀分布的一个算法

813
00:54:30,930 --> 00:54:36,240
然后说到NoSQL就不能不提到MongoDB

814
00:54:36,245 --> 00:54:41,550
MongoDB其实是一个非常

815
00:54:41,940 --> 00:54:45,210
神奇的数据库

816
00:54:45,540 --> 00:54:48,060
说它神奇，主要是因为

817
00:54:48,065 --> 00:54:48,960


818
00:54:50,070 --> 00:54:51,450
它其实

819
00:54:52,380 --> 00:54:53,220
并没有

820
00:54:53,225 --> 00:54:55,470
从学术上来说

821
00:54:55,650 --> 00:54:58,230
其实刚刚我们说的那几个系统

822
00:54:58,410 --> 00:55:03,720
都是背后有论文，有很多学术

823
00:55:03,725 --> 00:55:05,220
上的一些创新

824
00:55:05,250 --> 00:55:07,980
特别在分布式系统，或者说一些

825
00:55:08,040 --> 00:55:09,450
关系理论模型上

826
00:55:09,600 --> 00:55:14,910
但是MongoDB的话，其实它的创新主要是在于对开发者的友好或者

827
00:55:14,915 --> 00:55:15,930
易用性上

828
00:55:15,990 --> 00:55:19,740
MongoDB其实非常

829
00:55:20,010 --> 00:55:21,210


830
00:55:21,660 --> 00:55:26,970
有特点的，它把它的数据的存储格式做成了一种叫

831
00:55:26,975 --> 00:55:29,340
Document的存储形式

832
00:55:29,700 --> 00:55:33,570
它很像JSON，就是特别灵活，不需要去定义一个Schema

833
00:55:33,690 --> 00:55:37,620
同时它也不像这种Key-Value这么简单

834
00:55:37,770 --> 00:55:38,850
它就是一个文档

835
00:55:38,910 --> 00:55:39,840
就像

836
00:55:39,930 --> 00:55:42,450
每一个

837
00:55:42,455 --> 00:55:46,950
单位它是一个个这样的文档为单位，所以对于很多这种业务

838
00:55:47,040 --> 00:55:49,230
模型来说非常方便

839
00:55:49,500 --> 00:55:51,510
比如况对于一些小的网站

840
00:55:51,660 --> 00:55:52,680


841
00:55:53,400 --> 00:55:58,710
我一开始可能对Schema，这个表数据的存储的字段

842
00:55:58,715 --> 00:56:01,050
结构，一开始没考虑太清楚

843
00:56:01,650 --> 00:56:06,960
如果你使用关系模型的话，你可能就会涉及到不停的

844
00:56:06,965 --> 00:56:09,930
去调整或修改之类，但是MongoDB没关系

845
00:56:10,140 --> 00:56:15,450
你就开箱即用，每个人，每个用户

846
00:56:15,455 --> 00:56:16,890
每条记录就是一个文档

847
00:56:17,220 --> 00:56:19,350
每条文档可以跟别的文档长的不一样

848
00:56:19,380 --> 00:56:20,520
就是没有任何关系

849
00:56:21,780 --> 00:56:27,090
但其实在这种模型下，它有好处，有坏处，好处就是说确实在

850
00:56:27,095 --> 00:56:28,050
一开始一些

851
00:56:28,140 --> 00:56:33,450
PUC的场景，一些小的业务场景下，它用起来非常顺手

852
00:56:33,455 --> 00:56:38,760
开箱即用，但是坏处就是说一些比较大的，比较复杂的场景下

853
00:56:39,300 --> 00:56:40,860
MongoDB的

854
00:56:40,890 --> 00:56:44,940
它的灵活性带来了一个

855
00:56:44,945 --> 00:56:47,550
难以维护的问题

856
00:56:47,880 --> 00:56:50,820
所以这其实就是一个权衡

857
00:56:51,210 --> 00:56:53,100
但对于

858
00:56:53,160 --> 00:56:58,470
很多互联网业务来说，其实MongoDB还是非常流行

859
00:56:58,475 --> 00:56:59,190
的一个选择

860
00:57:00,720 --> 00:57:06,030
而其实整个数据库发展到现在吧，就是NoSQL

861
00:57:06,035 --> 00:57:11,340
为什么要把ElasticSearch项目也归类进来，严格来说，它其实是个搜索引擎

862
00:57:11,345 --> 00:57:12,060


863
00:57:12,630 --> 00:57:17,520
因为大家知道ElasticSearch前身是Lucence

864
00:57:17,525 --> 00:57:22,830
然后其实我在

865
00:57:22,835 --> 00:57:28,020
把这个搜索引擎放进来的

866
00:57:28,025 --> 00:57:30,570
想法是在于

867
00:57:30,960 --> 00:57:36,270
其实现在我越来越观察到整个数据库的使用形态，其实并不局限于

868
00:57:36,275 --> 00:57:37,320


869
00:57:37,380 --> 00:57:41,040
这种键值对也好

870
00:57:41,130 --> 00:57:42,960
表结构关系模型也好

871
00:57:43,260 --> 00:57:44,520
其实包括像

872
00:57:44,550 --> 00:57:46,470
搜索

873
00:57:46,710 --> 00:57:49,110
或者说这种模糊的匹配，模糊查询

874
00:57:49,230 --> 00:57:50,100
其实

875
00:57:50,160 --> 00:57:52,560
也是有很多的需求

876
00:57:52,950 --> 00:57:58,260
其实很多公司其实拿着ElasticSearch当数据库在用

877
00:57:58,265 --> 00:57:59,910


878
00:58:00,450 --> 00:58:05,760
而且ElasticSearch, Logstash, Kibana这三个组件组合在一起

879
00:58:06,240 --> 00:58:08,670
形成了一个非常

880
00:58:08,880 --> 00:58:12,570
非常厉害的技术栈，去解决了一整套

881
00:58:12,600 --> 00:58:17,910
日志检索的问题

882
00:58:17,915 --> 00:58:21,390
解决了特别大的痛点，所以特别流行

883
00:58:23,130 --> 00:58:26,550
然后在

884
00:58:26,790 --> 00:58:32,010
NoSQL领域里面还有一个特别大的分支，就是Cache System

885
00:58:32,490 --> 00:58:35,610
就是做分布式缓存的，做缓存

886
00:58:35,880 --> 00:58:41,190
刚刚我说到了，我们其实聊到这些数据库，其实都是这种持久化型的，这种数据库

887
00:58:41,460 --> 00:58:46,770
缓存型的数据库的话，其实对于某一些场景，比如说

888
00:58:47,010 --> 00:58:49,680
我就要求这个请求，一定要在

889
00:58:49,710 --> 00:58:51,720
一毫秒之内返回

890
00:58:52,050 --> 00:58:55,350
对数据库的请求来说，要在一毫秒之内返回

891
00:58:55,650 --> 00:58:56,670
但是你想

892
00:58:56,760 --> 00:59:01,920
很多关系型数据库，但凡你这个请求要落到磁盘上

893
00:59:02,010 --> 00:59:07,320
特别是在一些机械磁盘的场景，可能十毫秒就过去了

894
00:59:08,460 --> 00:59:11,880
当然对于这种比较极端的这种业务场景要求

895
00:59:11,940 --> 00:59:16,020
QPS特别高，性能要求特别好，特别快的场景的话

896
00:59:16,350 --> 00:59:19,350
那基本上只有把这个数据放到内存里面

897
00:59:19,410 --> 00:59:20,490
才行

898
00:59:20,790 --> 00:59:26,100
但是放到内存里面有两个问题，一个是内存，毕竟比磁盘小太多了

899
00:59:26,160 --> 00:59:31,110
你现在一个高配的服务器内存再大也就是

900
00:59:31,410 --> 00:59:33,960
几百G的内存算不错了

901
00:59:34,620 --> 00:59:39,930
但是磁盘的话，你可以轻松去挂个几T几十T的磁盘在一台机器上OK的

902
00:59:40,620 --> 00:59:42,120
另外一点就是说

903
00:59:42,150 --> 00:59:45,360
内存的这个价格其实

904
00:59:45,365 --> 00:59:49,770
算成单价的话，也会比磁盘贵很多，所以

905
00:59:49,830 --> 00:59:54,000
而且另外一个特别大的问题就是内存，它其实是会丢失的

906
00:59:54,330 --> 00:59:55,110


907
00:59:55,350 --> 00:59:58,470
重启一下服务器，内存就被清空了

908
00:59:58,860 --> 01:00:04,170
是易失的存储单位，当然它其实特别快

909
01:00:05,100 --> 01:00:07,230


910
01:00:08,040 --> 01:00:13,080
因为这样的特点，一定会有人去尝试，把数据库放在内存里面

911
01:00:13,200 --> 01:00:18,510
NoSQL领域里边比较典型的两个，一个是Memcached，一个是Redis

912
01:00:19,290 --> 01:00:24,450
其实这个也没什么好说的，就是把一个数据库放内存里，然后速度特别快

913
01:00:24,510 --> 01:00:29,820
但是你一定要能接受它可以丢失，所以一般像这些缓存系统都是配合着一个

914
01:00:29,825 --> 01:00:31,620
持久化的数据库再去使用

915
01:00:31,920 --> 01:00:34,860
所以一般底下都是挂一个MySQL

916
01:00:34,865 --> 01:00:36,360
或者说一个NoSQL

917
01:00:36,420 --> 01:00:41,520
上面在业务端把一些热数据放到这个Memcached或Redis里面

918
01:00:44,400 --> 01:00:49,710
然后刚刚我说过，Memcached跟Redis

919
01:00:49,715 --> 01:00:53,460
都是单机的系统就是一台机器

920
01:00:54,180 --> 01:00:55,770
一台机器的内存是有限的

921
01:00:56,190 --> 01:01:01,500
再比如说，我能不能去做一个分布式的

922
01:01:01,505 --> 01:01:03,750
缓存系统，是吧

923
01:01:04,200 --> 01:01:05,280
还真有

924
01:01:05,880 --> 01:01:06,900


925
01:01:07,680 --> 01:01:12,990
有两个比较流行的吧，开源的

926
01:01:13,110 --> 01:01:17,370
分布式缓存数据库

927
01:01:17,375 --> 01:01:18,510
一个叫Codis

928
01:01:18,515 --> 01:01:20,550


929
01:01:20,970 --> 01:01:25,770
我对Codis很有感情啊，因为我其实是Codis

930
01:01:25,860 --> 01:01:28,470
原始的作者，原创的作者之一

931
01:01:28,475 --> 01:01:29,370
然后

932
01:01:29,640 --> 01:01:34,770
他其实是一个非常流行的内存的

933
01:01:34,800 --> 01:01:37,950
分布式的缓存系统

934
01:01:38,400 --> 01:01:43,710
Codis其实走的是Redis的协议

935
01:01:44,280 --> 01:01:49,590
你可以把它当做一个单机Redis来使用，但是提升其实底下

936
01:01:49,595 --> 01:01:51,810
是由多个

937
01:01:52,020 --> 01:01:53,910
节点组成的

938
01:01:54,720 --> 01:01:57,480
第二个就是官方的

939
01:01:57,660 --> 01:02:02,970
原生的Redis Cluster，两个架构群有点不太一样，就是官方的

940
01:02:02,975 --> 01:02:08,280
是一个基于纯P2P的一个架构，Codis其实是一个分层

941
01:02:08,285 --> 01:02:10,410
分的比较好

942
01:02:10,415 --> 01:02:14,580
是一个Proxy Based的系统

943
01:02:18,690 --> 01:02:24,000
然后下一个部分是OLAP跟数据仓库

944
01:02:25,380 --> 01:02:29,730
其实，数据库发展到到现在吧

945
01:02:31,200 --> 01:02:31,830


946
01:02:31,980 --> 01:02:35,550
大家其实可以看到1970年那篇论文，讲这种

947
01:02:35,555 --> 01:02:40,860
类似在线交易的系统，但这个

948
01:02:42,240 --> 01:02:46,680
大家会发现，随着业务发展越来越多

949
01:02:46,740 --> 01:02:52,050
很多时候数据库是用来做一些分析，或者说

950
01:02:52,055 --> 01:02:55,320
报表这样的场景

951
01:02:55,620 --> 01:03:00,930
而且另外一点就是很多数据其实你把它放到数据库里是不划算了，你可能放到这种

952
01:03:01,350 --> 01:03:02,880
比较便宜的那种

953
01:03:03,270 --> 01:03:08,580
分布式存储，或者说数据仓库里面去做一些数据挖掘

954
01:03:08,820 --> 01:03:09,750
可能会更加划算

955
01:03:11,010 --> 01:03:16,320
所以OLAP在这十几20年吧也是一个非常非常

956
01:03:16,500 --> 01:03:18,600
热或者非常大的一个市场

957
01:03:19,920 --> 01:03:25,230
所以我这边也是讲了几个比较流行的

958
01:03:25,380 --> 01:03:27,090
OLAP数据库

959
01:03:27,120 --> 01:03:28,950
一个是Hive

960
01:03:29,310 --> 01:03:31,500
Hive其实刚才

961
01:03:31,560 --> 01:03:36,870
大家可能也看到Hadoop这个平台

962
01:03:36,875 --> 01:03:42,180
Hadoop平台上面的这个数据的数据仓库的实现就叫Hive

963
01:03:42,450 --> 01:03:44,880
然后数据其实存在还是存在HDFS上面的

964
01:03:45,180 --> 01:03:50,490
你可以认为Hive其实是一个计算和分析引擎

965
01:03:50,820 --> 01:03:54,180
实际的Data其实是还是存储在HDFS上

966
01:03:54,360 --> 01:03:55,620


967
01:03:55,890 --> 01:04:01,200
Hive对外提供的还是一个比较标准的

968
01:04:01,205 --> 01:04:02,730
SQL接口

969
01:04:03,360 --> 01:04:08,670
但是其实Hive内部做的一个事情，就是说把用户写了这个查询的

970
01:04:08,675 --> 01:04:09,780
这个SQL

971
01:04:09,990 --> 01:04:15,300
因为大家知道，就比如说我有很大规模的数据存储在HDFS这个分布式文件系统上面

972
01:04:15,305 --> 01:04:20,310
我要去做一些分析这个分析怎么分析呢，我写SQL进行分析

973
01:04:20,640 --> 01:04:25,410
然后其实Hive做的就是把SQL解析成这个

974
01:04:26,490 --> 01:04:31,800
在Hadoop用的这个，这种MapReduce的这种批处理框架

975
01:04:31,950 --> 01:04:33,570
这种分布式计算的框架

976
01:04:33,690 --> 01:04:36,780
然后去再用这个

977
01:04:38,100 --> 01:04:43,290
底下这个集群的计算资源却去做一些计算，然后

978
01:04:44,100 --> 01:04:49,410
所以其实本质上来说，它其实是一个Batch Processing的系统，就是说我要去

979
01:04:49,415 --> 01:04:54,690
做这种批处理，或者说去做这种批量的分析

980
01:04:55,440 --> 01:04:59,850
批处理的一个好处是对于

981
01:05:00,000 --> 01:05:01,260
海量数据吧

982
01:05:01,620 --> 01:05:06,930
它一般来说不会，写过MapReduce的同学

983
01:05:06,935 --> 01:05:07,860
肯定知道

984
01:05:07,920 --> 01:05:13,230
就是整个MapReduce分阶段的，一个Stage一个Stage，每个Stage他要把这些

985
01:05:13,235 --> 01:05:16,680
中间结果给落盘，然后再进入下一个Stage

986
01:05:17,280 --> 01:05:20,010
它好处就是说你多大数据我都能搞

987
01:05:20,040 --> 01:05:22,800
但坏处也很明显，就是特别慢

988
01:05:22,950 --> 01:05:26,040
每次都要来回的落盘

989
01:05:26,070 --> 01:05:30,300
来回去把中间结果取出来，再去做下一个阶段计算，所以

990
01:05:30,330 --> 01:05:33,180
Hive其实

991
01:05:34,380 --> 01:05:36,480
也算是最早的一个

992
01:05:36,540 --> 01:05:40,950
比较老牌的一个分布式计算的方案

993
01:05:44,100 --> 01:05:48,600
因为刚才说的那些问题

994
01:05:48,750 --> 01:05:53,910
有另外一些项目就开始诞生了

995
01:05:54,120 --> 01:05:59,430
比如说Impala，Impala其实也是一个

996
01:05:59,435 --> 01:06:04,740
对外暴露SQL的一个查询引擎，它其实就是一个非常纯粹的分布式

997
01:06:04,745 --> 01:06:06,300
计算的一个框架

998
01:06:06,660 --> 01:06:11,970
然后他其实有一点设计的比较好，就是它跟底下的这个存储是

999
01:06:11,975 --> 01:06:17,280
几乎是剥离的，就是说你其实可以底下去对接不同的这种

1000
01:06:17,285 --> 01:06:21,540
存储单元，其实整个Impala是一个

1001
01:06:21,900 --> 01:06:24,390
分布式计算引擎

1002
01:06:24,570 --> 01:06:26,010
然后

1003
01:06:26,040 --> 01:06:27,870
同时它

1004
01:06:27,900 --> 01:06:30,150
用内存做了很多这些

1005
01:06:30,180 --> 01:06:35,490
这种Cache，整个性能其实是

1006
01:06:36,240 --> 01:06:39,390
在一些这种比较Adhoc

1007
01:06:39,660 --> 01:06:42,780
比较及时的这种查询上表现会更好

1008
01:06:44,220 --> 01:06:45,450


1009
01:06:45,480 --> 01:06:47,610
Kudu

1010
01:06:47,640 --> 01:06:52,950
第二个想说的是Kudu。Kudu其实是也是由Cloudera

1011
01:06:52,955 --> 01:06:55,230


1012
01:06:55,380 --> 01:06:56,880
这个公司开源的

1013
01:06:56,910 --> 01:06:57,750


1014
01:06:57,900 --> 01:07:00,720
其实他SQL引擎也是依赖Impala

1015
01:07:00,725 --> 01:07:03,900
是一个修改版本的Impala，Kudu是一个数据库了

1016
01:07:04,020 --> 01:07:08,820
Kudu是不仅仅包括计算引擎，同时他也自己去Build了一个

1017
01:07:09,060 --> 01:07:11,430
自己的存储引擎，想去支持

1018
01:07:11,520 --> 01:07:16,290
及时的写入，及时的分析的一个数据库

1019
01:07:16,620 --> 01:07:20,370
但其实这两个项目现在都不算太活跃，因为其实

1020
01:07:20,460 --> 01:07:21,660
这个

1021
01:07:21,900 --> 01:07:26,790
在OLAP领域里面，项目实在太多

1022
01:07:27,030 --> 01:07:29,730
所以其实这两个项目

1023
01:07:29,760 --> 01:07:31,620


1024
01:07:31,680 --> 01:07:34,650
也不能说太活跃了现在

1025
01:07:35,280 --> 01:07:35,940


1026
01:07:35,970 --> 01:07:39,870
包括这个Cloudera本身的投入其实也不算特别大

1027
01:07:41,940 --> 01:07:47,250
然后第二个比较流行的MPP数据库叫GreenPlum

1028
01:07:47,255 --> 01:07:48,810
GreenPlum其实是Pivotal这个公司开源的一个数据库

1029
01:07:49,080 --> 01:07:54,390


1030
01:07:55,020 --> 01:08:00,330
它的这个基础的代码其实是基于Postgres

1031
01:08:01,710 --> 01:08:04,200
非常模块化的一个

1032
01:08:04,410 --> 01:08:06,150
数据库

1033
01:08:06,360 --> 01:08:10,290
然后GreenPlum是把这个Postgres改造成了一个

1034
01:08:10,350 --> 01:08:12,930
这个多实例的一个MPP的数据库

1035
01:08:13,230 --> 01:08:16,680
它其实是这个相当于通过

1036
01:08:16,710 --> 01:08:20,760
因为它是有数据分片的这个概念

1037
01:08:20,910 --> 01:08:21,930
然后

1038
01:08:21,990 --> 01:08:22,950


1039
01:08:23,070 --> 01:08:27,720
它相当于又构建了一个分布式计算层

1040
01:08:27,990 --> 01:08:29,100
然后去

1041
01:08:29,160 --> 01:08:30,330


1042
01:08:30,480 --> 01:08:32,970
去做这个计算

1043
01:08:33,000 --> 01:08:35,430
而且另外一点就是GreenPlum有一个

1044
01:08:35,520 --> 01:08:36,420
非常

1045
01:08:36,660 --> 01:08:38,400
牛X的一个SQL优化器

1046
01:08:38,640 --> 01:08:42,570
叫Orca

1047
01:08:42,930 --> 01:08:48,240
Orca其实是GreenPlum这边自己基本

1048
01:08:49,200 --> 01:08:51,270
重写了

1049
01:08:51,510 --> 01:08:56,820
整个PG的优化器，用来去适合更加复杂，更加

1050
01:08:57,180 --> 01:09:00,120
大规模的SQL查询

1051
01:09:00,125 --> 01:09:02,730


1052
01:09:03,720 --> 01:09:09,030
但好处特快，就是GreenPlum，其实在很多场景下，其实跑的还挺快的，但是坏处

1053
01:09:09,035 --> 01:09:09,900
就是说

1054
01:09:10,500 --> 01:09:12,540
他没有办法去支持这种

1055
01:09:13,080 --> 01:09:18,390
随机的插入更新，增删改查，其实很困难，因为其实对于这个

1056
01:09:18,690 --> 01:09:23,160
OLAP数据库来说，它为了追求这种极致的访问性能

1057
01:09:23,280 --> 01:09:24,810
读取或者查询性能

1058
01:09:24,870 --> 01:09:29,280
其实是牺牲掉的一些像一种事务性这些东西

1059
01:09:29,880 --> 01:09:32,370
所以一般来说，像这种

1060
01:09:32,400 --> 01:09:34,020
OLAP数据库都是

1061
01:09:34,025 --> 01:09:35,250
批量的导入

1062
01:09:35,370 --> 01:09:36,480
然后做分析

1063
01:09:36,630 --> 01:09:39,300
然后再删除，再去导入下一批的数据

1064
01:09:42,000 --> 01:09:45,030
Kylin就是

1065
01:09:45,035 --> 01:09:48,510
Kylin创始人Look也是我很好的一个朋友

1066
01:09:48,660 --> 01:09:49,650


1067
01:09:49,800 --> 01:09:55,110
它是诞生于中国的一个项目，EBay China当时

1068
01:09:55,115 --> 01:10:00,390
Look还是EBay China时候主持的一个项目，他的这个模型就更加

1069
01:10:00,570 --> 01:10:03,690
比起像那些MPP就更加的

1070
01:10:05,970 --> 01:10:07,560
更加的Focus

1071
01:10:07,770 --> 01:10:09,900
它其实在某些场景下

1072
01:10:09,930 --> 01:10:15,240
他的模型是这种基于数据立方体，叫Data Qube

1073
01:10:15,245 --> 01:10:16,920
它会把一些

1074
01:10:17,820 --> 01:10:21,270
你要查询的东西

1075
01:10:21,390 --> 01:10:26,700
的结果给预计算，就比如说你做菜是吧，你每次都买原始的材料，从头开始做

1076
01:10:26,705 --> 01:10:29,670
其实是比较费时间的

1077
01:10:29,700 --> 01:10:30,750
但是如果你

1078
01:10:31,020 --> 01:10:36,330
提前的，比如说隔一天前一天晚上去把一些东西给做好了

1079
01:10:36,840 --> 01:10:42,150
第二天你可能简单的炒炒菜，或者说

1080
01:10:42,155 --> 01:10:46,980
东西都已经腌好了，或者说已经切的差不多了

1081
01:10:47,190 --> 01:10:48,330
最后

1082
01:10:48,450 --> 01:10:53,760
你再去真正做饭的时候会特别快，它原理也是一样，就相当于把原始的

1083
01:10:53,765 --> 01:10:54,540
数据

1084
01:10:55,050 --> 01:10:56,850
通过一些

1085
01:10:57,480 --> 01:11:00,750
预计算把这些中间结果保存下来

1086
01:11:01,020 --> 01:11:05,970
然后给上层的这个SQL查询层

1087
01:11:06,210 --> 01:11:11,520
来针对Data Qube上的这些预计算的数据来去组合

1088
01:11:11,525 --> 01:11:13,140


1089
01:11:13,590 --> 01:11:14,970
然后得到最终的结果

1090
01:11:15,300 --> 01:11:16,590
所以它在

1091
01:11:17,160 --> 01:11:18,780


1092
01:11:18,930 --> 01:11:22,890
实时报表这个场景，或者说你的这个查询相对

1093
01:11:23,190 --> 01:11:24,150
比较固定

1094
01:11:24,540 --> 01:11:29,730
的场景下，其实是能够去极大的加速整个查询的性能

1095
01:11:30,000 --> 01:11:32,400
但它的缺点比较明显，就是

1096
01:11:32,520 --> 01:11:33,840
它对于这种

1097
01:11:34,140 --> 01:11:35,970
Adhoc，就是

1098
01:11:36,480 --> 01:11:37,770
比较随便，比如说我

1099
01:11:37,950 --> 01:11:39,750
一拍脑袋，我就想要做这个

1100
01:11:40,080 --> 01:11:43,560
但是Data Qube没有预先构建起来的话

1101
01:11:43,650 --> 01:11:48,420
它的性能，或者说支持程度其实是不好的

1102
01:11:51,690 --> 01:11:56,790
下一个比较重要的一个系统是这个Spark

1103
01:11:57,390 --> 01:12:02,700
Spark这个项目其实很有意思，其实它野心非常大，就是

1104
01:12:02,705 --> 01:12:08,010
UC Berkerly这个学校

1105
01:12:08,015 --> 01:12:09,660
在09年

1106
01:12:09,900 --> 01:12:13,050
开启的一个新的

1107
01:12:13,500 --> 01:12:17,430
一个新的分布式计算的一个项目

1108
01:12:18,120 --> 01:12:19,050
然后

1109
01:12:19,380 --> 01:12:24,690
它一开始的目标是想去替换掉，因为刚才其实我说到MapReduce

1110
01:12:25,380 --> 01:12:30,600
MapRecue其实是分这个Stage，就特别慢，中间还要落盘什么的

1111
01:12:31,440 --> 01:12:34,620
Spark其实想去

1112
01:12:34,770 --> 01:12:40,080
创造一个新的系统，然后去用一种

1113
01:12:40,170 --> 01:12:43,740
他们内部叫RDD这个模型

1114
01:12:43,860 --> 01:12:45,030


1115
01:12:45,240 --> 01:12:50,550
实现更加及时，更加实时的一个

1116
01:12:50,610 --> 01:12:55,800
因为其实在Spark里面大量的使用了计算节点内存

1117
01:12:56,100 --> 01:13:01,410
而且其实它整个计算是一种基于有向无环图的

1118
01:13:01,415 --> 01:13:03,240
这种计算

1119
01:13:03,270 --> 01:13:08,580
然后所以在有些场景下，它的分布式计算的效率会

1120
01:13:08,760 --> 01:13:11,160
比传统的MapReduce模型要快的多

1121
01:13:11,760 --> 01:13:12,450


1122
01:13:13,110 --> 01:13:16,440
而且是Spark做的特别聪明的一点就是说

1123
01:13:16,560 --> 01:13:21,870
它一开始并没有去依赖像Hive这样去完全依赖到这个Hadoop

1124
01:13:21,875 --> 01:13:23,790
这个系统上

1125
01:13:23,880 --> 01:13:26,460
而是他把它的存储给抽象出来

1126
01:13:26,610 --> 01:13:28,590
所以，任何系统都可以去

1127
01:13:28,740 --> 01:13:33,630
对接Spark来Leverage

1128
01:13:36,750 --> 01:13:42,060
用它的能力去做一些迭代，计算，ETL这样一些事情

1129
01:13:42,810 --> 01:13:43,860
所以

1130
01:13:43,890 --> 01:13:48,030
所以这说的也没有错，Unified engine across data workloads and platforms

1131
01:13:48,240 --> 01:13:50,790
所以我其实非常喜欢Spark这个项目

1132
01:13:53,040 --> 01:13:58,350
终于说到我们这几年

1133
01:13:58,355 --> 01:13:59,610
在做的东西了

1134
01:13:59,700 --> 01:14:00,450
NewSQL

1135
01:14:01,200 --> 01:14:06,510
其实刚刚我简单也提了一下，就是NoSQL包括数据仓库发展这么多年

1136
01:14:06,810 --> 01:14:09,900
大家开始渐渐的发现这个

1137
01:14:10,140 --> 01:14:11,760
市面上数据库太多了

1138
01:14:12,150 --> 01:14:13,590


1139
01:14:13,830 --> 01:14:19,140
什么样的细分场景都跑出来一个数据库说，我就适合这个场景

1140
01:14:19,770 --> 01:14:20,580
但是

1141
01:14:20,790 --> 01:14:22,350
再看来看去呢

1142
01:14:23,070 --> 01:14:25,050
SQL，事务

1143
01:14:25,080 --> 01:14:30,390
这些上世纪70年代就有了

1144
01:14:30,395 --> 01:14:31,710
这些概念

1145
01:14:31,860 --> 01:14:33,750
到现在为止，其实还是

1146
01:14:34,230 --> 01:14:39,540
还真就是经久不衰，很多业务，其实你用SQL来写，一行SQL能顶

1147
01:14:39,960 --> 01:14:43,980
你去写100行200行代码

1148
01:14:44,340 --> 01:14:45,720
还包括事务

1149
01:14:46,020 --> 01:14:51,330
比如说转账存钱，这样的场景你肯定不想

1150
01:14:51,335 --> 01:14:56,640
说数据库这一层不帮你保证这些东西，你全都在业务上，自己去写代码去保证

1151
01:14:57,390 --> 01:14:58,290
那也是不对的

1152
01:14:58,800 --> 01:15:02,460
然后包括

1153
01:15:02,790 --> 01:15:07,680
分布式这个能力，其实这几年通过NoSQL发展

1154
01:15:08,070 --> 01:15:13,380
也或多或少的成为了这种大家整个工程师

1155
01:15:13,385 --> 01:15:17,100
整个系统上，整个行业里面积累了很多经验

1156
01:15:17,460 --> 01:15:18,870
所以就会

1157
01:15:19,140 --> 01:15:23,520
像我们这样的人就会想着，能不能去把NoSQL这边的一些

1158
01:15:23,580 --> 01:15:26,190
分布式，可扩展的

1159
01:15:26,195 --> 01:15:26,970
能力

1160
01:15:27,060 --> 01:15:28,830
跟传统的这些

1161
01:15:29,010 --> 01:15:34,320
SQL，事务这些东西结合在一起，然后做一种新形态

1162
01:15:35,130 --> 01:15:39,120
看起来像传统数据库，Oracle，MySQL

1163
01:15:39,300 --> 01:15:44,040
但是又像NoSQL这样可以完全水平扩展的一个数据库呢

1164
01:15:48,000 --> 01:15:50,340
其实

1165
01:15:51,240 --> 01:15:52,110
是可以的

1166
01:15:55,170 --> 01:15:59,040
这其实我就是再简单介绍刚才一下那些Feature

1167
01:15:59,130 --> 01:16:00,330
然后

1168
01:16:02,460 --> 01:16:05,910
因为时间关系吧，我直接跳到系统介绍

1169
01:16:07,590 --> 01:16:12,180
第一个要介绍的系统是Spanner

1170
01:16:12,300 --> 01:16:13,620


1171
01:16:13,625 --> 01:16:18,930
最早刚刚在聊History的时候，我也介绍了一下Spanner

1172
01:16:18,960 --> 01:16:22,410
Spanner

1173
01:16:23,010 --> 01:16:27,300
在我看来，它其实是BigTable

1174
01:16:27,420 --> 01:16:28,890
在Google内部的

1175
01:16:29,490 --> 01:16:31,110
BigTable的进化版

1176
01:16:31,200 --> 01:16:31,830
是吧！

1177
01:16:32,190 --> 01:16:37,500
然后这边写了一个F1，这个F1这个东西是什么呢，F1，其实是一个

1178
01:16:37,505 --> 01:16:39,960
独立的SQL层

1179
01:16:40,380 --> 01:16:45,570
构建在Spanner之上，提供SQL服务的一个组件

1180
01:16:46,080 --> 01:16:47,070


1181
01:16:47,250 --> 01:16:52,560
相当于这两个系统组合在一起在用户看来就是一个标准的关系型数据库

1182
01:16:52,565 --> 01:16:53,400


1183
01:16:54,660 --> 01:16:59,970
然后对于Spanner来说，它的读写其实都是可以几乎无限的水平扩展

1184
01:17:00,660 --> 01:17:01,620


1185
01:17:02,580 --> 01:17:03,240


1186
01:17:03,480 --> 01:17:08,790
在这个系统里创新的引入了一个原子钟这个硬件，原子钟加

1187
01:17:08,795 --> 01:17:11,010
GPS时钟硬件

1188
01:17:11,070 --> 01:17:12,450
他们命名为True Time

1189
01:17:12,660 --> 01:17:17,880
来去做这种长距离的，这个跨数据中心的强一致和高可用

1190
01:17:20,370 --> 01:17:25,680
对于Google Spanner这个系统其实在整个业界有两个比较

1191
01:17:25,950 --> 01:17:31,110
著名的实现吧，就目前来说，这个我比较认可的也就

1192
01:17:31,350 --> 01:17:35,730
这两个实现，其中第一个这个实现是叫CockroachDB

1193
01:17:36,180 --> 01:17:37,800
蟑螂数据库

1194
01:17:37,920 --> 01:17:39,060
小强数据库

1195
01:17:39,180 --> 01:17:41,610


1196
01:17:41,640 --> 01:17:45,270
小强数据库创始人，其实也是几个

1197
01:17:45,540 --> 01:17:48,840
在Google纽约团队的几个工程师出来

1198
01:17:49,320 --> 01:17:51,150
做了一个这

1199
01:17:51,155 --> 01:17:54,900
Open Source的Spanner实现

1200
01:17:57,780 --> 01:18:03,090
它的协议兼容是Postgres兼容

1201
01:18:04,500 --> 01:18:08,430
然后它的实现基本是用是用go来写

1202
01:18:09,060 --> 01:18:09,930


1203
01:18:10,050 --> 01:18:14,790
它的主要的设计主打的应用场景是

1204
01:18:14,880 --> 01:18:20,190
跟Spanner也有点接近，就是说去做这种跨数据中心长距离的OLTP业务

1205
01:18:20,730 --> 01:18:22,350
强一致，高可用

1206
01:18:22,380 --> 01:18:24,570
小强嘛，他的意思就是说

1207
01:18:24,690 --> 01:18:25,950
我这个

1208
01:18:26,220 --> 01:18:27,210


1209
01:18:27,300 --> 01:18:30,600
这是个打不死的数据库，任何一个节点坏了

1210
01:18:30,690 --> 01:18:34,080
没关系，这个系统还是正常的，能够

1211
01:18:34,290 --> 01:18:35,850
永远不挂

1212
01:18:37,050 --> 01:18:38,640
但是他的

1213
01:18:41,190 --> 01:18:42,600
坏处

1214
01:18:42,930 --> 01:18:45,210
其实我介绍一下TiDB这边吧

1215
01:18:45,930 --> 01:18:51,240
第二个系统就是这个我们在做的这个PingCAP

1216
01:18:51,245 --> 01:18:55,080
在做的数据库TiDB，其实TiDB在

1217
01:18:55,290 --> 01:19:00,600
整个行业里面也是一个非常流行的NewSQL数据库

1218
01:19:00,960 --> 01:19:04,860
对比CockroachDB

1219
01:19:05,850 --> 01:19:06,810
有几个优势

1220
01:19:07,320 --> 01:19:08,190
一是

1221
01:19:11,460 --> 01:19:16,770
整体上来说，TiDB的整个实现的性能和稳定性

1222
01:19:16,775 --> 01:19:19,230


1223
01:19:19,440 --> 01:19:22,050
我们其实在一些比较

1224
01:19:22,260 --> 01:19:27,570
标准的Benchmark，比如说像Sysbench, 比如说像TPCC，这样的传统的OLTP

1225
01:19:27,575 --> 01:19:28,980
这种workload下的

1226
01:19:29,130 --> 01:19:33,330
这种高并发，同样的机器配置

1227
01:19:33,540 --> 01:19:36,240
TiDB的性能其实是要

1228
01:19:36,450 --> 01:19:41,760
比CockroachDB至少在现在这个时间应该是2019年8月份

1229
01:19:41,765 --> 01:19:44,100
19年的八月份

1230
01:19:44,220 --> 01:19:46,830
是要强很多

1231
01:19:47,130 --> 01:19:48,360
然后

1232
01:19:48,390 --> 01:19:53,700
第二点就是TiDB的目标其实并不仅仅是想要去做一个OLTP Database

1233
01:19:53,705 --> 01:19:54,750


1234
01:19:55,050 --> 01:19:55,680
因为

1235
01:19:55,860 --> 01:20:01,170
这个我们其实说过OLAP，你的数据量大

1236
01:20:01,175 --> 01:20:06,480
那么第二个很自然的想法就是说我要去做分析，所以TiDB

1237
01:20:06,485 --> 01:20:11,790
花了很多精力再去做SQL

1238
01:20:11,795 --> 01:20:12,630


1239
01:20:12,690 --> 01:20:16,830
我们其实想去统一整个数据的

1240
01:20:16,860 --> 01:20:18,750
数据库和数据仓库

1241
01:20:18,930 --> 01:20:24,210
去抹平中间的界限就是你其实可以作为理想情况下，HTAP

1242
01:20:24,300 --> 01:20:27,720
就一边做这个交易型高并发的这种业务

1243
01:20:27,810 --> 01:20:33,120
一边在上面通过你的SQL去做分析的业务

1244
01:20:33,990 --> 01:20:34,890
然后

1245
01:20:34,950 --> 01:20:40,260
对于TiDB来说，TiDB兼容的是MySQL协议

1246
01:20:40,530 --> 01:20:43,770
这点上其实跟CockroachDB

1247
01:20:43,860 --> 01:20:45,570
不太一样

1248
01:20:45,660 --> 01:20:48,420
所以其实TiDB更加适合

1249
01:20:48,720 --> 01:20:51,120
原有MySQL的业务

1250
01:20:51,240 --> 01:20:54,960
迁移过来，其实TiDB在兼容性这块

1251
01:20:55,110 --> 01:20:56,760
做的更加好

1252
01:20:57,030 --> 01:21:01,590
举个例子，就是TiDB甚至可以直接作为MySQL的从库

1253
01:21:01,740 --> 01:21:05,640
去实时同步你的上游MySQL主库

1254
01:21:05,850 --> 01:21:06,960
所以像这些

1255
01:21:08,160 --> 01:21:11,340
对于用户来说提供了一个

1256
01:21:11,400 --> 01:21:15,450
跟MySQL使用非常接近

1257
01:21:15,690 --> 01:21:21,000
但是它是一个完全可以扩展的架构

1258
01:21:21,390 --> 01:21:26,100
所以其实解决了很多用户在这种单机关系数据库上的一些问题

1259
01:21:29,280 --> 01:21:34,590
然后NewSQL这两个系统就快速的介绍一下，因为整个

1260
01:21:34,595 --> 01:21:39,480
一类的课程我们都会在讲NewSQL

1261
01:21:39,570 --> 01:21:40,560
未来的时候

1262
01:21:41,010 --> 01:21:46,320
Cloud Native可能是我觉得是

1263
01:21:46,440 --> 01:21:47,580
很重要的一个方向

1264
01:21:49,440 --> 01:21:50,220


1265
01:21:50,400 --> 01:21:52,320
说到Cloud Native

1266
01:21:52,620 --> 01:21:57,930
可能最近这几年吧，一直都在都在听别人去聊Cloud

1267
01:21:57,935 --> 01:21:59,190


1268
01:21:59,400 --> 01:22:00,030
但是

1269
01:22:00,450 --> 01:22:01,230
为什么

1270
01:22:01,260 --> 01:22:06,240
或者到底什么叫Cloud Native, 为什么Cloud Native这几年火了起来

1271
01:22:06,840 --> 01:22:10,980
其实我觉得最本质的一个变化是

1272
01:22:11,880 --> 01:22:15,780
我们的硬件在这几年发生了翻天覆地的变化

1273
01:22:16,380 --> 01:22:21,690
比如说磁盘，现在最近其实可能都或多或少的，在用SSD

1274
01:22:22,590 --> 01:22:25,590
其实SSD比

1275
01:22:26,220 --> 01:22:30,990
传统的机械磁盘要快很多很多

1276
01:22:31,110 --> 01:22:36,420
延迟也低很多，然后包括甚至最近这一两年的

1277
01:22:36,425 --> 01:22:38,430
可能很快就要出来的这种

1278
01:22:38,790 --> 01:22:40,350
持久化的内存

1279
01:22:40,355 --> 01:22:44,550
这个内存有内存级别的内存，同样这个

1280
01:22:44,580 --> 01:22:47,310
这个性能的存储介质

1281
01:22:47,340 --> 01:22:50,610
然后非易失的存储介质也会出现

1282
01:22:51,180 --> 01:22:55,770
存储上的硬件进步很多，另外一块就是网络

1283
01:22:56,520 --> 01:23:01,680
比如说在过去，我记得百兆网卡，千兆网卡，这是行业的主流

1284
01:23:01,770 --> 01:23:03,690
但最近这几年

1285
01:23:03,695 --> 01:23:07,290
万兆网卡，甚至两万兆网卡

1286
01:23:07,295 --> 01:23:10,110
都不少见了

1287
01:23:10,260 --> 01:23:11,610
其实现在

1288
01:23:11,670 --> 01:23:15,960
基本上你再去数据中心里边，万兆网卡基本上标配

1289
01:23:16,860 --> 01:23:21,000
所以，相当于你的带宽足够，你的存储的速度足够

1290
01:23:21,150 --> 01:23:24,690
然后你的机器价格又不是太贵

1291
01:23:24,960 --> 01:23:30,270
所以分布式肯定是没得讲，然后另外一点就是说

1292
01:23:30,630 --> 01:23:32,070
你怎么能去

1293
01:23:32,400 --> 01:23:33,840
更好地去

1294
01:23:33,930 --> 01:23:39,240
利用好你整个集群的资源

1295
01:23:39,690 --> 01:23:42,930
就比如说我手上现在有1000台服务器

1296
01:23:43,530 --> 01:23:46,230
我怎么能够去更好的

1297
01:23:46,740 --> 01:23:51,540
提升这些集群里面机器的使用率

1298
01:23:52,260 --> 01:23:56,670
所以虚拟化技术就应运而生了

1299
01:23:57,030 --> 01:23:59,190
最早期的虚拟化技术

1300
01:23:59,340 --> 01:24:04,650
基本是以这种虚拟机（Virtual Machine，VM）为代表的

1301
01:24:04,655 --> 01:24:07,770


1302
01:24:07,775 --> 01:24:10,650
像KVM，像VMWare这样的技术

1303
01:24:11,070 --> 01:24:14,910
但现在大家发现VM这个技术

1304
01:24:15,300 --> 01:24:17,040
还是不够灵活，就是说

1305
01:24:17,070 --> 01:24:18,570


1306
01:24:18,660 --> 01:24:23,640
比如说你要启动一个VM，可能还需要十秒钟

1307
01:24:23,790 --> 01:24:25,830
还需要一点时间

1308
01:24:26,280 --> 01:24:27,030
然后

1309
01:24:27,150 --> 01:24:32,460
现在大家慢慢的把虚拟化

1310
01:24:32,465 --> 01:24:34,020
这个技术往

1311
01:24:34,140 --> 01:24:38,220
基于容器的方向，比如说企业容器，那就是100毫秒

1312
01:24:38,340 --> 01:24:40,470
这个级别的事情

1313
01:24:40,475 --> 01:24:41,550


1314
01:24:41,820 --> 01:24:46,170
甚至可能都不需要100毫秒，很快拉起一个Container计算完销毁

1315
01:24:46,260 --> 01:24:47,010
就是说

1316
01:24:47,160 --> 01:24:48,540
越来越轻量

1317
01:24:48,930 --> 01:24:52,890
你的系统的

1318
01:24:52,895 --> 01:24:55,950
调度资源的粒度越来越细

1319
01:24:56,220 --> 01:24:59,460
第二点就是整个业务的开发

1320
01:24:59,580 --> 01:25:04,890
会慢慢地从这种单体业务走向Micro-service

1321
01:25:05,100 --> 01:25:07,350
甚至你想现在

1322
01:25:07,530 --> 01:25:12,840
觉得Micro-service还不够灵活，开始去尝试Lambda或者Serverless

1323
01:25:13,080 --> 01:25:14,670
这样的

1324
01:25:14,880 --> 01:25:16,350
无服务器架构

1325
01:25:16,380 --> 01:25:18,540
这个其实也是

1326
01:25:18,810 --> 01:25:20,610


1327
01:25:20,730 --> 01:25:23,310
更加灵活的去使用底下的（硬件资源），因为

1328
01:25:23,430 --> 01:25:28,740
就是说你使用下Serverless或者Micro-service这种技术，底层的硬件对你来说几乎

1329
01:25:29,100 --> 01:25:30,360
已经是透明的

1330
01:25:30,570 --> 01:25:31,170


1331
01:25:31,230 --> 01:25:34,710
所以你其实可以在底下调度器上做很多文章

1332
01:25:34,800 --> 01:25:40,110
包括现在比较流行的数据库系统的设计上

1333
01:25:40,115 --> 01:25:41,700
比如说Aurora

1334
01:25:43,110 --> 01:25:45,990
它是采用这种Shared Storage这种架构

1335
01:25:46,050 --> 01:25:51,360
Shared Storage假设我底下的磁盘就是一个网络磁盘，我不区分到底是本地还是网络

1336
01:25:52,200 --> 01:25:55,830
我的磁盘上的存储在同一数据中心里就应该是共享的

1337
01:25:56,130 --> 01:26:01,320
它的假设就是说，我访问本地磁盘的吞吐，其实跟访问网络磁盘吞吐几乎是一样的

1338
01:26:01,950 --> 01:26:04,710
像这样的这些技术其实

1339
01:26:04,800 --> 01:26:05,700
都是

1340
01:26:06,120 --> 01:26:08,610
Cloud Native非常

1341
01:26:11,130 --> 01:26:13,470
重要的性质

1342
01:26:14,460 --> 01:26:16,770
这是要说的第一个系统就是Aurora

1343
01:26:16,980 --> 01:26:22,290
Aurora最近刚拿了SIGMOD今年的

1344
01:26:22,295 --> 01:26:23,760
最佳系统实现奖

1345
01:26:24,150 --> 01:26:25,200
然后

1346
01:26:25,620 --> 01:26:29,100
但是其实我觉得在学术上来说Aurora并没有太大创新

1347
01:26:29,250 --> 01:26:32,400
但是在它确实非常流行

1348
01:26:32,760 --> 01:26:35,520
为什么特别流行呢，一是它首先

1349
01:26:35,610 --> 01:26:37,410
100%的MySQL Compatible

1350
01:26:37,500 --> 01:26:42,810
他其实设计的非常取巧，就是它的计算层仍然还是使用了原生的MySQL

1351
01:26:43,080 --> 01:26:48,390
所以，它的SQL层就是一个MySQL，所以你不需要去做额外的事情，去保证它的Compatibility

1352
01:26:48,960 --> 01:26:50,130


1353
01:26:50,580 --> 01:26:52,290
但是他比较创新的就是说

1354
01:26:52,295 --> 01:26:55,470
它底下的存储这块

1355
01:26:55,475 --> 01:26:56,790
其实是使用

1356
01:26:57,150 --> 01:27:01,620
就没有使用单机的InnoDB，而是使用一个

1357
01:27:01,740 --> 01:27:02,910
共享存储

1358
01:27:03,690 --> 01:27:04,680
然后

1359
01:27:05,970 --> 01:27:06,780


1360
01:27:07,530 --> 01:27:12,300
去实现分布式的能力

1361
01:27:13,350 --> 01:27:18,660
比如说他其实是更高效的主从架构，因为你不需要像过去的

1362
01:27:18,665 --> 01:27:20,910
主从这样去复制Binlog

1363
01:27:21,120 --> 01:27:26,430
而是底下通过Redo Log这个级别

1364
01:27:26,435 --> 01:27:28,470
去做数据复制和同步的

1365
01:27:31,560 --> 01:27:36,870
对然后另外一个比较大的趋势就是做多租户

1366
01:27:36,875 --> 01:27:37,620


1367
01:27:37,860 --> 01:27:41,940
然后其实多租户这个概念也不是特别新

1368
01:27:43,530 --> 01:27:48,090
大家如果对Google的系统比较熟悉的话，肯定知道Google有一个系统叫Borg

1369
01:27:48,420 --> 01:27:51,000
Borg其实

1370
01:27:51,090 --> 01:27:52,020


1371
01:27:53,040 --> 01:27:58,350
其实你可以认为它是类似开源领域里面有这种

1372
01:27:58,410 --> 01:28:02,160
调度器的实现叫Kubernetes

1373
01:28:02,280 --> 01:28:04,860
Kubernetes它其实

1374
01:28:05,160 --> 01:28:08,790
其实也不是Borg的二代吧，但是

1375
01:28:08,820 --> 01:28:14,130
它也是谷歌出来做的一个基于

1376
01:28:14,910 --> 01:28:20,130
容器或者基于分布式存储的

1377
01:28:20,370 --> 01:28:23,520
一个调度器

1378
01:28:23,550 --> 01:28:25,110


1379
01:28:25,500 --> 01:28:29,040
Kubernetes或者Borg这样的系统去

1380
01:28:29,400 --> 01:28:31,500
决定你的这块

1381
01:28:31,505 --> 01:28:33,690
计算资源应该分配给哪些业务

1382
01:28:34,020 --> 01:28:36,540
然后它能够比人

1383
01:28:36,630 --> 01:28:40,830
更加高效的去做这个事情，因为

1384
01:28:41,820 --> 01:28:43,290
它是一个程序

1385
01:28:43,410 --> 01:28:46,020
就是它

1386
01:28:46,530 --> 01:28:47,670
太Trivial了是吧

1387
01:28:47,760 --> 01:28:48,420
就是

1388
01:28:48,690 --> 01:28:50,790
因为它其实它本质上来说

1389
01:28:51,630 --> 01:28:52,650


1390
01:28:53,760 --> 01:28:58,110
比如说你这个集群里面有那么

1391
01:28:58,230 --> 01:28:59,340
比如说N台机器

1392
01:28:59,730 --> 01:29:00,660


1393
01:29:00,990 --> 01:29:06,030
比如说业务上有

1394
01:29:06,180 --> 01:29:07,260


1395
01:29:07,320 --> 01:29:10,650
多条业务线，但是你只有十台机器

1396
01:29:10,950 --> 01:29:13,920
那我怎么能尽可能的把

1397
01:29:13,950 --> 01:29:15,330
多个业务

1398
01:29:15,360 --> 01:29:20,400
更好地利用这底下这十台机器的计算资源

1399
01:29:21,000 --> 01:29:25,950
如果你靠人去做手动的分配的话，比如这三台机器给你那三台机给他

1400
01:29:26,430 --> 01:29:27,750
那其实

1401
01:29:27,780 --> 01:29:28,530
万一

1402
01:29:28,535 --> 01:29:33,840
这个业务特别热，三台机器不够用，另外几台机器特别闲

1403
01:29:33,845 --> 01:29:35,190
然后

1404
01:29:35,430 --> 01:29:36,600


1405
01:29:37,080 --> 01:29:38,220
特别闲是吧

1406
01:29:38,280 --> 01:29:41,790
那其实整体来说，机器利用率是不太高的

1407
01:29:42,090 --> 01:29:45,540
所以Kubernetes充当了这么一个

1408
01:29:45,630 --> 01:29:49,470
Orchestrator的模式

1409
01:29:49,650 --> 01:29:50,520


1410
01:29:50,580 --> 01:29:55,890
它其实相当于把你的计算资源化成了无数个小容器，然后把你的业务

1411
01:29:55,895 --> 01:30:00,690
放到容器里，他把容器跟业务

1412
01:30:00,780 --> 01:30:01,740
管理起来

1413
01:30:01,770 --> 01:30:03,960
比如说你这个业务挂了

1414
01:30:04,110 --> 01:30:08,220
或者说这个容器挂了，它给你自动地Launch一个进来

1415
01:30:08,490 --> 01:30:11,280
然后因为其实在这层来看到全都是容器

1416
01:30:11,610 --> 01:30:16,680
然后他其实可以很好的去平衡不同机器的计算资源的使用

1417
01:30:16,740 --> 01:30:19,380
它内部是有一套调度算法

1418
01:30:21,030 --> 01:30:26,190
所以其实对于TiDB来说， 多说两句

1419
01:30:26,490 --> 01:30:29,010
我们其实也是

1420
01:30:29,220 --> 01:30:34,530
会依靠Kubernetes去做多租户和

1421
01:30:34,680 --> 01:30:36,630
资源的（调度）

1422
01:30:36,840 --> 01:30:37,800


1423
01:30:38,310 --> 01:30:42,150
比如说我一个业务线，我不可能只用一个TiDB集群

1424
01:30:42,390 --> 01:30:47,700
但是依托Kubernetes，我们就可以很好的利用底层的计算的

1425
01:30:47,705 --> 01:30:48,600
物理资源

1426
01:30:48,720 --> 01:30:49,770


1427
01:30:49,890 --> 01:30:55,200
来提高整个集群的利用率，同时我们把很多这些集群的

1428
01:30:55,205 --> 01:30:57,930
部署维护自动化的

1429
01:30:57,935 --> 01:31:00,360
逻辑放到了TiDB-Operator里

1430
01:31:00,540 --> 01:31:04,410
注入给Kubernetes

1431
01:31:04,950 --> 01:31:05,850
所以

1432
01:31:06,120 --> 01:31:08,850
一整套其实是

1433
01:31:09,510 --> 01:31:12,930
我其实一直认为Kubernetes会是未来的

1434
01:31:13,290 --> 01:31:15,810
基础的操作系统，这样概念的东西

1435
01:31:16,140 --> 01:31:17,010
然后

1436
01:31:17,370 --> 01:31:21,840
在这个新的操作系统上，需要新时代的数据库

1437
01:31:22,050 --> 01:31:27,360
然后TiDB就是为了这样的新时代的Cloud Native的架构

1438
01:31:27,365 --> 01:31:30,960
去设计的一个数据库

1439
01:31:32,610 --> 01:31:34,800
好，谢谢

1440
01:31:39,510 --> 01:31:40,110
今天就到这吧

