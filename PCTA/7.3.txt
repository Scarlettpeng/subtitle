1
00:00:00,030 --> 00:00:05,340


2
00:00:12,990 --> 00:00:15,390
PingCAP University 的同学们，大家好

3
00:00:15,450 --> 00:00:20,760
欢迎收看 PingCAP 官方培训视频，本期我们主讲的主题是 Tidb

4
00:00:20,765 --> 00:00:22,380
慢查询的处理

5
00:00:22,530 --> 00:00:23,910
以及优化思路

6
00:00:28,350 --> 00:00:32,820
本期的课程主要面对 TiDB 的开发人员以及维护人员

7
00:00:33,090 --> 00:00:36,030
需要对  SQL  和 TiDB 有一定的了解

8
00:00:36,210 --> 00:00:38,760
课程时间在一个课时

9
00:00:39,090 --> 00:00:42,090
在各位与各种数据库的接触生涯中

10
00:00:42,150 --> 00:00:44,790
慢查询是一个不能避开的话题

11
00:00:45,300 --> 00:00:47,970
当然慢查询也是一个相对的话题

12
00:00:48,420 --> 00:00:50,400
因为慢,

13
00:00:50,460 --> 00:00:52,200
肯定是跟快相对应的

14
00:00:52,380 --> 00:00:56,940
只要深入的解决慢查询问题，就是需要从原理出发

15
00:00:57,210 --> 00:00:59,670
了解其中可能存在的优化点

16
00:01:00,000 --> 00:01:01,770
知其然知其所以然

17
00:01:02,040 --> 00:01:05,430
所以在本期的课程中，我们将会从原理出发

18
00:01:05,760 --> 00:01:08,430
针对慢查询，提供一些优化思路

19
00:01:08,700 --> 00:01:10,170
本次课程后

20
00:01:10,175 --> 00:01:13,200
您将会了解 TiDB 读请求的执行流程

21
00:01:13,230 --> 00:01:16,710
了解 TiDB 在分析场景下的参数优化

22
00:01:17,130 --> 00:01:20,610
以及遇到疑难问题的最终求援方式

23
00:01:23,730 --> 00:01:28,920
本期课程的主要内容从具体来看，包括以下的学习内容

24
00:01:29,010 --> 00:01:31,110
就是 TiDB 读请求流程

25
00:01:31,115 --> 00:01:33,000
慢查询的获取渠道

26
00:01:33,300 --> 00:01:35,070
慢查询的排查技能

27
00:01:35,130 --> 00:01:38,700
以及如何使用 TiDB 的参数进行计算加速

28
00:01:39,090 --> 00:01:42,090
在问题实在无法解决的时候

29
00:01:42,540 --> 00:01:47,550
以及最终的求援方式，包括最终的实战演练

30
00:01:48,450 --> 00:01:50,850
整个内容会兼顾

31
00:01:51,690 --> 00:01:56,460
在我们学习之后，整个内容会有一个关键知识点的回顾学习

32
00:01:57,030 --> 00:02:00,210
好了，废话不多说，让我们直接进入正题

33
00:02:01,110 --> 00:02:02,220
首先

34
00:02:03,150 --> 00:02:03,750


35
00:02:04,500 --> 00:02:05,880
首先

36
00:02:06,000 --> 00:02:08,250
让我们从源头出发

37
00:02:11,280 --> 00:02:16,590
这里面主要也是学习目标，这个跟上一面的学习内容是相同的

38
00:02:16,710 --> 00:02:18,030
所以就暂时

39
00:02:18,420 --> 00:02:19,860
不做过多的

40
00:02:20,010 --> 00:02:20,730
说明

41
00:02:22,410 --> 00:02:25,620
废话不多说，让我们进入正题首先

42
00:02:25,860 --> 00:02:30,150
让我们从源头出发，从一个  SQL  的执行过程来看

43
00:02:30,360 --> 00:02:32,190
如何可能会有慢查询？

44
00:02:32,970 --> 00:02:35,790
相信大家在经过之前的学习之后

45
00:02:35,850 --> 00:02:38,580
已经非常明白 TiDB 的主要架构

46
00:02:39,330 --> 00:02:44,640
一个 SQL 的执行会经历建立连接，在网络上接收数据，MySQL 协议

47
00:02:44,645 --> 00:02:46,110
解析和转换

48
00:02:46,200 --> 00:02:50,100
这个语法的解析查询计划的制定与优化

49
00:02:50,250 --> 00:02:53,220
以及查询计划的执行，到最后的返回结果

50
00:02:54,150 --> 00:02:55,080
如图

51
00:02:55,230 --> 00:02:59,610
TiDB 与 TiKV 之间的交互，主要是通过 TiDB 上的 ti-client

52
00:03:00,030 --> 00:03:01,170
和 TiKV

53
00:03:01,290 --> 00:03:04,320
KV 和 DistSql 接口进行的

54
00:03:04,890 --> 00:03:10,200
这两个分别对应于 TiKV 的参数则是 Storage readpool 和 Coprocessor readpool

55
00:03:10,530 --> 00:03:11,730
这两个线程池

56
00:03:12,870 --> 00:03:16,560
理论情况下，KV 接口是可以完成所有操作的

57
00:03:16,890 --> 00:03:20,730
但是我们出于一些性能上的考虑，实现了下推计算

58
00:03:21,180 --> 00:03:24,510
下推计算，这一部分就是通过 Coprocessor 接口来完成的

59
00:03:25,620 --> 00:03:27,120
在这整个过程中

60
00:03:27,480 --> 00:03:30,240
到底是哪些问题可能造成慢查询的？

61
00:03:30,660 --> 00:03:33,360
让我们再来回顾一下刚刚讲的过程

62
00:03:33,630 --> 00:03:35,190
一步步地分析一下

63
00:03:36,150 --> 00:03:38,400
首先是链接到 TiDB

64
00:03:38,790 --> 00:03:44,100
这一步就涉及到网络、应用和 TiDB 之间的网络是否有问题

65
00:03:44,550 --> 00:03:45,780
这可能是

66
00:03:46,140 --> 00:03:46,980
导致

67
00:03:47,010 --> 00:03:50,940
你看到的执行时间变长的第一个问题

68
00:03:51,420 --> 00:03:53,370
我们有些时候可能会发现

69
00:03:53,460 --> 00:03:57,630
在应用上， SQL  执行很慢，但是在库内执行却很快

70
00:03:57,840 --> 00:03:59,610
可能就是这一个的原因

71
00:04:00,060 --> 00:04:05,370
这一部分可能从应用上捕捉的执行时间和 TiDB 日志里的执行时间来做对比

72
00:04:05,670 --> 00:04:06,570
得结果

73
00:04:07,260 --> 00:04:10,800
网络之后就是 TiDB 里面的协议转换的过程

74
00:04:11,430 --> 00:04:12,990
这里既然在 TiDB 上

75
00:04:13,320 --> 00:04:15,210
那么，TiDB 节点的压力

76
00:04:15,330 --> 00:04:17,100
就会成为影响因素

77
00:04:17,340 --> 00:04:19,230
而 TiDB 作为一个计算引擎

78
00:04:19,410 --> 00:04:21,600
CPU ，会成为比较关注的东西

79
00:04:22,230 --> 00:04:25,800
在解析之后，下面就是制定及执行计划

80
00:04:25,950 --> 00:04:27,660
如果执行计划不对

81
00:04:27,690 --> 00:04:31,470
该所索引的走到了全表扫描，就会严重影响性能

82
00:04:32,010 --> 00:04:34,890
在下面就是执行计划的执行

83
00:04:34,895 --> 00:04:36,570
执行涉及到两点

84
00:04:36,780 --> 00:04:38,910
一个是 TiKV 节点上的压力

85
00:04:39,300 --> 00:04:42,480
这个跟 TiDB 节点上的压力是类似的

86
00:04:42,900 --> 00:04:47,400
但它可 TiKV 为一个存储引擎，还需要额外关注到磁盘的压力

87
00:04:47,940 --> 00:04:51,930
在这里压力还有一个比较特殊的情况，就是压力不均

88
00:04:52,290 --> 00:04:53,670
做为一个集群

89
00:04:53,970 --> 00:04:59,280
肯定是压力均摊每个节点承担一部分的压力，可以带来更好的效果

90
00:05:00,090 --> 00:05:01,590
这就是热点问题

91
00:05:01,620 --> 00:05:03,270
另外一个就是重试

92
00:05:03,690 --> 00:05:07,650
如果发生了可重试的问题，TiDB 自动重试的话

93
00:05:08,040 --> 00:05:10,140
当然也会加上这些时间

94
00:05:10,650 --> 00:05:12,630
整个流程大概就是这样

95
00:05:12,750 --> 00:05:15,090
这里面还涉及到 TP 、AP 的考量

96
00:05:15,600 --> 00:05:19,860
从 TP 上来说，因为都是检查比较简单的查询搜索

97
00:05:20,160 --> 00:05:24,000
可能 300 毫秒以上就是我们在这默认的慢查询时间

98
00:05:24,120 --> 00:05:25,590
以上就是慢查询

99
00:05:25,740 --> 00:05:27,450
但是对于 AP 应用的话

100
00:05:27,870 --> 00:05:28,650
比较

101
00:05:29,010 --> 00:05:32,820
庞大的 SQL 执行时间可能会执行非常长

102
00:05:33,030 --> 00:05:36,570
所以说，有可能执行半天时间也是正常现象

103
00:05:41,280 --> 00:05:41,880


104
00:05:46,590 --> 00:05:50,820
了解完 SQL 可能出现了慢查询的情况之后

105
00:05:51,210 --> 00:05:54,030
下面将是对慢查询的实际处理思路

106
00:05:54,840 --> 00:05:58,500
说了这么多的慢查询，那么在哪里可以发现慢查询呢？

107
00:05:59,250 --> 00:06:03,330
最直观的肯定是我们自己在客户客户端上执行一个 SQL  

108
00:06:03,690 --> 00:06:06,420
然后半天没有出来，嗯，很慢

109
00:06:06,690 --> 00:06:09,240
这就是一个慢查询，那哪里是证据？

110
00:06:10,230 --> 00:06:12,510
首先是 TiDB 的监控

111
00:06:12,720 --> 00:06:15,390
如图就是一个慢查询的事例

112
00:06:16,170 --> 00:06:20,670
它会标出总体的查询时间，执行时间和等待时间

113
00:06:21,030 --> 00:06:24,000
其次就是 TiDB 和 TiKV 的日志

114
00:06:24,300 --> 00:06:28,800
TiDB 和 TiKV 的日志上都会比较慢的查询进行日志输出

115
00:06:29,820 --> 00:06:32,130
TiDB 关键字就是 slow-query

116
00:06:33,030 --> 00:06:38,340
最后就是我们在最新的版本上已经支持了，TiDB 的慢查询的内存表

117
00:06:38,760 --> 00:06:43,050
这个实际上也是解析的 TiDB 的日志，但是会极大

118
00:06:43,350 --> 00:06:46,950
的，方便我们的处理过程，因为你可以通过  SQL  接口

119
00:06:47,010 --> 00:06:52,320
去做一些简单的过滤，而不只能通过

120
00:06:52,590 --> 00:06:54,510
对日志的操作来完成

121
00:07:01,050 --> 00:07:02,520
讲完获取

122
00:07:02,640 --> 00:07:05,400
渠道之后，那就是我们已经知道了

123
00:07:05,430 --> 00:07:06,690
有慢查询

124
00:07:07,200 --> 00:07:09,030
那么，如何去处理呢？

125
00:07:09,510 --> 00:07:10,410
第一步

126
00:07:10,620 --> 00:07:14,730
当然是分析监控，因为我们最开始的也是从监控上去看的

127
00:07:15,450 --> 00:07:19,680
具体可能的原因在上上篇 PPT 上面已经讲过了

128
00:07:20,250 --> 00:07:23,970
下面就是从监控中得到，是不是这样的做？

129
00:07:24,120 --> 00:07:25,320
做佐证

130
00:07:26,220 --> 00:07:27,270
如图中

131
00:07:27,360 --> 00:07:29,520
我们的监控实在是太多了

132
00:07:29,910 --> 00:07:32,730
右下角会有一个优先级的介绍

133
00:07:32,880 --> 00:07:33,870
可以看到

134
00:07:34,980 --> 00:07:38,100
这里面首先最高优先级的是 Over-view

135
00:07:38,220 --> 00:07:39,630
以及 Trouble-shooting

136
00:07:39,900 --> 00:07:43,290
Over-view 的话，我们可以发现主机的压力情况

137
00:07:43,920 --> 00:07:44,730
从

138
00:07:44,735 --> 00:07:48,630
Trouble-shooting 上我们可以得到 TiKV 监控的具体信息

139
00:07:49,140 --> 00:07:53,760
另外，剩下的中等的是可能查看主机的实际情况

140
00:07:53,970 --> 00:07:56,190
最后的就是每个 TiKV 的情况

141
00:07:56,580 --> 00:08:01,890
当然，我们再发现具体的 TiKV 有问题的时候，也就是可以通过每个

142
00:08:01,895 --> 00:08:03,420
TiKV 具体的监控

143
00:08:03,425 --> 00:08:04,560
去发现问题

144
00:08:09,270 --> 00:08:12,240
下面一个就是我们可以去

145
00:08:12,420 --> 00:08:13,740
分析日志

146
00:08:14,220 --> 00:08:18,180
我们的慢查询日志，当前的格式已经跟 MySQL 兼容

147
00:08:18,480 --> 00:08:21,540
大家可以通过 MySQL 可兼容的 PT 工具

148
00:08:21,570 --> 00:08:23,730
直接对日志进行分析

149
00:08:24,270 --> 00:08:29,580
然后图中是一个具体的慢查询实例，我们来看一下这个日志的主要内容

150
00:08:30,570 --> 00:08:32,880
上面当然是比较简单的

151
00:08:32,885 --> 00:08:33,780
用户

152
00:08:33,870 --> 00:08:35,400
时间

153
00:08:35,430 --> 00:08:38,970
以及我们的事务 ID ，

154
00:08:39,270 --> 00:08:41,250
就是 Txn

155
00:08:41,520 --> 00:08:42,690
查询时间

156
00:08:42,840 --> 00:08:46,710
查询时间，下面一行则是我们需要注意的东西

157
00:08:47,910 --> 00:08:48,900
这个

158
00:08:48,960 --> 00:08:53,880
开头是下推，查询在 TiKV 上执行的时间总总和

159
00:08:54,270 --> 00:08:56,460
第二个是等待的时间综合

160
00:08:56,850 --> 00:09:02,160
从这两个参数的差异，我们可以判断是 SQL 本身的执行时间长，还是因为

161
00:09:02,165 --> 00:09:03,750
TiKV 的压力过大

162
00:09:03,870 --> 00:09:05,520
等待的时间较长

163
00:09:06,240 --> 00:09:08,220
后面是重试的

164
00:09:08,310 --> 00:09:11,310
等待的时间以及下推请求的个数

165
00:09:11,700 --> 00:09:16,410
在最后的两个分别是下推请求处理的 Key 数以及

166
00:09:17,280 --> 00:09:18,120


167
00:09:18,270 --> 00:09:19,860
实际执行的 KV

168
00:09:20,550 --> 00:09:23,460
Total 包含了 MVCC 的版本

169
00:09:23,580 --> 00:09:28,890
所以从这里我们可以看到，是不是因为 MVCC 版本太多而带来的问题？

170
00:09:29,790 --> 00:09:34,770
在下面看来就比较明显了，有库名是否使用，索引

171
00:09:34,860 --> 00:09:35,790
指纹

172
00:09:35,880 --> 00:09:38,820
统计信息情况以及内存使用情况

173
00:09:38,970 --> 00:09:40,980
以及我们 SQL 执行的语句

174
00:09:41,220 --> 00:09:45,360
是否使用索引，我们这里可以看到有索引 ID

175
00:09:45,600 --> 00:09:46,860
通过索引 ID

176
00:09:46,865 --> 00:09:51,480
我们就可以在 TiDB 的 http 接口上去获取到索引

177
00:09:51,630 --> 00:09:53,910
索引的名字等其他信息

178
00:09:54,840 --> 00:09:56,190
然后图中

179
00:09:56,310 --> 00:09:59,010
红色的代表的是 TiDB 的问题

180
00:09:59,040 --> 00:10:00,600
包括统计信息

181
00:10:00,660 --> 00:10:02,850
索引选择以及内存

182
00:10:03,120 --> 00:10:05,610
蓝色的则代表 TiKV 的问题

183
00:10:05,850 --> 00:10:08,580
包括是否是 TiKV 等待时间过长

184
00:10:08,760 --> 00:10:10,620
MVCC 版本数过多

185
00:10:10,710 --> 00:10:16,020
以及下推查询的最大值以及平均值，可以观察出是否有

186
00:10:16,800 --> 00:10:18,600
热点的 TiKV

187
00:10:22,830 --> 00:10:26,070
再下一个就是我们对应的 TiDB 的内存表

188
00:10:26,550 --> 00:10:29,880
实际上，内存表就是刚刚日志的解析表

189
00:10:30,600 --> 00:10:35,580
大家可以看到，这里的每一列，实际上都对应的刚刚日志里的信息

190
00:10:36,030 --> 00:10:41,340
但是他作为一个表就可以使我们在表上执行各种各样的 SQL 进行去过滤

191
00:10:41,550 --> 00:10:43,560
然后这里就不多介绍

192
00:10:43,860 --> 00:10:46,350
大家可以看一下这边的表结构信息

193
00:10:46,800 --> 00:10:48,540
在执行的时候

194
00:10:48,570 --> 00:10:52,560
可以作为过滤条件使用 SQL 得到想要的信息

195
00:10:56,580 --> 00:10:57,600
另外

196
00:10:57,840 --> 00:11:01,980
之前有提到 TiDB 日志上是有

197
00:11:02,520 --> 00:11:05,790
慢查询信息的那么 TiKV 日志上也有

198
00:11:06,330 --> 00:11:08,760
图上就是一个 TiKV 日志的实例

199
00:11:09,390 --> 00:11:13,230
这个一般应用于如果某个 TiKV 的压力过大

200
00:11:13,800 --> 00:11:14,850
需要从

201
00:11:14,910 --> 00:11:18,510
压力过大的 TiKV 上去，发现我们具体要执行的 SQL 

202
00:11:18,660 --> 00:11:19,380
这里

203
00:11:19,620 --> 00:11:22,380
从 TiKV 日志反查具有一样的

204
00:11:22,410 --> 00:11:23,700
效果

205
00:11:24,300 --> 00:11:26,280
如图，我们可以看到

206
00:11:26,520 --> 00:11:28,290
具体的 Region 信息

207
00:11:28,295 --> 00:11:30,420
Store id ，以及执行时间

208
00:11:30,690 --> 00:11:32,670
从 Store id ，我们就可以

209
00:11:33,270 --> 00:11:35,610
获取到还有 Table ID

210
00:11:36,840 --> 00:11:42,150
如图下的两个方式是可以通过 Table ID 获取到具体的表信息

211
00:11:42,990 --> 00:11:45,660
得到表信息之后，我们就可以与

212
00:11:45,750 --> 00:11:49,860
TiDB 的日志之中去找到对应的 SQL ，以及对应的慢查询

213
00:11:50,070 --> 00:11:53,160
这样我们就可以进行下一步的分析

214
00:11:57,870 --> 00:12:01,470
无论无论是刚刚上一步还是

215
00:12:01,475 --> 00:12:06,300
最上面 TiDB 的日志，我们最终只是拿到了慢查询的 SQL 

216
00:12:06,420 --> 00:12:09,300
得到 SQL 之后，我们可以做些什么呢？

217
00:12:09,330 --> 00:12:11,460
那肯定是分析一下 SQL 

218
00:12:11,580 --> 00:12:14,220
看一下它的执行计划是否有问题

219
00:12:14,730 --> 00:12:17,610
这里是一个简单的执行计划的事例

220
00:12:17,790 --> 00:12:19,530
如图，我们可以看到

221
00:12:19,680 --> 00:12:24,240
这两张表都是没有选择索引的它是

222
00:12:24,660 --> 00:12:26,250


223
00:12:26,970 --> 00:12:31,320
都是一个全表扫，然后把数据拿到 TiDB 上之后

224
00:12:31,470 --> 00:12:33,450
做了一个 hash join

225
00:12:35,790 --> 00:12:41,100
具体的执行计划，大家可以通过我们官方的文档去了解这里

226
00:12:41,105 --> 00:12:42,900
就大概讲一下

227
00:12:43,470 --> 00:12:46,770
然后从执行计划中，我们可以看到

228
00:12:47,010 --> 00:12:50,460
SQL 是否选取到索引的，索引关联算子

229
00:12:50,465 --> 00:12:52,650
聚合算法以及 join 的顺序

230
00:12:53,760 --> 00:12:56,370
对应的解决方法是

231
00:12:57,240 --> 00:12:58,200
如果

232
00:12:58,260 --> 00:13:03,030
索引没有选择对，我们需要观察统计信息是否有问题

233
00:13:03,150 --> 00:13:05,340
统计信息，这里就涉及到

234
00:13:05,345 --> 00:13:09,210
我们应该有一个定时收集统计信息的任务

235
00:13:09,870 --> 00:13:15,180
这个当然，在我们最新版本的 TiDB 上也是已经

236
00:13:15,185 --> 00:13:16,320
做到了

237
00:13:16,560 --> 00:13:18,510
可以自动收集统计信息

238
00:13:18,870 --> 00:13:24,180
但是有一个定时任务是是要比 TiDB 的自动收集

239
00:13:24,210 --> 00:13:27,030
自动收集统计信息效果要好的

240
00:13:28,470 --> 00:13:32,910
然后如果根据统计信息，无法选择合适的索引和关联算子

241
00:13:33,090 --> 00:13:34,260
都需要使用

242
00:13:34,350 --> 00:13:35,730
加 Hint 的方式

243
00:13:35,880 --> 00:13:38,850
或者是 3.0 版本的 SQL 执行计划绑定了

244
00:13:40,290 --> 00:13:44,760
当然有时候我们也会发现，单独只有一个 TiKV 的压力很大

245
00:13:44,970 --> 00:13:47,040
这个也会很影响执行的性能

246
00:13:47,310 --> 00:13:48,360
如图所示

247
00:13:48,540 --> 00:13:52,710
TiKV1 的下推计算执行压力明显要高于其他 5 个节点

248
00:13:53,730 --> 00:13:58,110
这时候我们就可以通过上面所提到的处理方式进行处理

249
00:13:58,680 --> 00:14:01,140
如从 TiKV 节点日志中

250
00:14:01,145 --> 00:14:04,350
我们可以获取到具体的 Region ID 和 Table ID

251
00:14:04,680 --> 00:14:08,610
通过 Table ID ，我们可以获取到具体的表名

252
00:14:08,910 --> 00:14:12,180
然后获取到表名之后，我们可以在 TiDB 的日志中

253
00:14:12,210 --> 00:14:17,520
获取到该表常用的操作，找到对应的 SQL 再去分析执行计划

254
00:14:18,210 --> 00:14:21,330
包括刚刚提到的是否走对索引

255
00:14:21,390 --> 00:14:23,160
以及 join 的算子

256
00:14:23,220 --> 00:14:24,660
是否选取正确

257
00:14:25,500 --> 00:14:26,280
当然

258
00:14:26,820 --> 00:14:32,130
SQL 的执行计划并不一定是有问题，因为有时候三个 TiKV 

259
00:14:32,135 --> 00:14:33,120
压力巨大

260
00:14:33,180 --> 00:14:37,500
可能涉及到我们每次的执行查询都是同一个 Region 

261
00:14:39,180 --> 00:14:42,840
这时候就只有通过手动 Split 去解决了

262
00:14:43,110 --> 00:14:46,440
手动 Split 可以通过 PD 的接口去完成

263
00:14:46,710 --> 00:14:49,590
另外，在最新的版本中我们也

264
00:14:49,890 --> 00:14:53,220
支持了在建表的时候，预先 Split

265
00:14:53,400 --> 00:14:55,980
这样可以保证，即使有很少的数据

266
00:14:56,160 --> 00:14:57,120
也可以

267
00:14:57,900 --> 00:15:01,350
在最开始的时候，有多个 Region 以分担压力

268
00:15:10,410 --> 00:15:13,380
提到了上面的都是可能

269
00:15:13,800 --> 00:15:18,300
慢查询的执行计划有问题，在最下面就不是了

270
00:15:18,570 --> 00:15:20,940
当你发现 SQL 的执行计划

271
00:15:20,970 --> 00:15:22,530
以及 TiKV 的压力

272
00:15:22,980 --> 00:15:28,290
都没有问题的时候，这时候就只能通过算子进行计算加速了

273
00:15:29,400 --> 00:15:32,670


274
00:15:34,650 --> 00:15:39,360
以上的描述都是 Sql 的执行计划以及 TiDB 和 TiKV 的

275
00:15:39,660 --> 00:15:43,140
压力有问题，当然这些也并不总是有问题的

276
00:15:43,650 --> 00:15:45,660


277
00:15:50,130 --> 00:15:51,330


278
00:15:51,510 --> 00:15:52,200


279
00:15:56,910 --> 00:15:57,510


280
00:15:59,640 --> 00:16:01,230
上面讲到的都是

281
00:16:01,350 --> 00:16:05,460
SQL 的执行计划或者 TiDB 和 TiKV 的压力有问题

282
00:16:05,790 --> 00:16:08,130
当然，这些也并不总是有问题的

283
00:16:09,210 --> 00:16:14,520
当我们发现 SQL 的执行计划也没有问题， TiDB 和 TiKV 的压力也比较小的时候

284
00:16:15,270 --> 00:16:17,700
这时候如果想提高 SQL 的执行

285
00:16:17,940 --> 00:16:22,350
效率就只能通过修改 TiDB 的参数来进行完成了

286
00:16:22,500 --> 00:16:24,690
这个通常应用于 AP 应用

287
00:16:25,800 --> 00:16:31,110
如图列举的则是 TiDB 加快执行并发度的

288
00:16:31,140 --> 00:16:32,820
的几个参数

289
00:16:33,840 --> 00:16:36,030
在上面的两个是

290
00:16:36,090 --> 00:16:40,530
是提高 Scan 操作的并发度这个通常受影响的是 TiKV 

291
00:16:40,710 --> 00:16:43,830
所以一般建议不超过 TiKV 的总核数

292
00:16:44,070 --> 00:16:48,900
而作为下面的 Join 、Hash Join 以及 Index lookup Join 算法

293
00:16:48,930 --> 00:16:50,460
所提高的并发度

294
00:16:50,790 --> 00:16:53,310
因为 Join 主要都发生在 TiDB 

295
00:16:53,400 --> 00:16:56,130
这里一般建议不超过 TiDB 的核数

296
00:16:58,020 --> 00:17:03,000
如果这些都搞不定，怎么办？那么 TiDB 的 SQL 团队将是您最终的后盾

297
00:17:03,060 --> 00:17:06,300
如果执行计划可以稳定的复线执行不准确

298
00:17:06,330 --> 00:17:11,220
那么可以将您的集群版本号表结构 、数据量、 执行计划以及统计信息

299
00:17:11,490 --> 00:17:14,850
提交给 TiDB 的团队，我们将为您分析

300
00:17:14,940 --> 00:17:17,580
另外的话，我们还提供了一些其他的

301
00:17:19,470 --> 00:17:21,900
收集工具包括一键采集工具

302
00:17:21,930 --> 00:17:27,240
当然，在 TiDB 或者 TiKV  CPU 或者内存使用比较繁忙的

303
00:17:27,245 --> 00:17:30,510
也可以进行火焰图或者 Profile 的导出

304
00:17:30,930 --> 00:17:34,080
另外，我们还提供了一些 API 的工具

305
00:17:34,170 --> 00:17:36,750
去帮助您进行分析

306
00:17:37,110 --> 00:17:40,260
包括 tidb-ctl 、 pd-ctl 、tikv-ctl ，还有一个

307
00:17:40,350 --> 00:17:42,660
table-regions 脚本

308
00:17:42,810 --> 00:17:46,110
脚本帮助您分析的 region 分布

309
00:17:48,450 --> 00:17:52,380
好，我们整个慢查询的介绍大概就到这里

310
00:17:53,250 --> 00:17:56,220
我们再来回顾一下关键的知识点

311
00:17:56,580 --> 00:17:58,410
主要有 slow-query

312
00:17:58,650 --> 00:17:59,850
慢查询

313
00:17:59,880 --> 00:18:02,820
导致的原因，从大的方向看，可能有哪些

314
00:18:03,000 --> 00:18:05,160
包括不限于我们刚刚提到的

315
00:18:07,020 --> 00:18:11,430
主机的压力以及网络还要执行计划以及

316
00:18:11,435 --> 00:18:12,750
重试等

317
00:18:13,230 --> 00:18:16,560
然后从哪个表里可以看到 slow-query 的执行情况 ?

318
00:18:16,770 --> 00:18:18,870
这个就是我们 TiDB 的内存表了

319
00:18:19,170 --> 00:18:22,290
通过什么接口可以根据表的 ID 查看表名 ?

320
00:18:22,560 --> 00:18:24,630
这个是 TiDB 的 http 接口

321
00:18:25,530 --> 00:18:29,640
SQL 语句有没有走索引? 在执行计划中通过什么关键词判断?

322
00:18:29,790 --> 00:18:34,140
这个我们如果使用索引的话，在执行计划中会有 index 关键词

323
00:18:34,170 --> 00:18:37,620
当然，在慢查询日志中会打出具体的索引 ID

324
00:18:38,490 --> 00:18:42,750
最后一个热点，region 可以通过什么工具进行手工拆分？

325
00:18:42,810 --> 00:18:47,970
这个是可以通过 pd-ctl 工具进行手动拆分，当然，在最新的版本中

326
00:18:48,030 --> 00:18:51,060
也支持在建表的时候进行预打散 region

327
00:18:53,220 --> 00:18:57,360
好在整个结束之后，我们可以回顾一下最开始的学习目标

328
00:18:57,600 --> 00:18:58,980
我们首先

329
00:18:59,010 --> 00:19:02,580
在原理上了解了 TiDB query 的整个执行过程

330
00:19:02,940 --> 00:19:05,910
以及介绍了慢查询的排查流程以及

331
00:19:06,150 --> 00:19:07,320
可能的原因

332
00:19:07,860 --> 00:19:09,930
还介绍了几个定位渠道

333
00:19:09,990 --> 00:19:11,520
以及最后的算子

334
00:19:11,525 --> 00:19:12,600
计算加速

335
00:19:14,670 --> 00:19:19,980
下面就是通过这个课程之后，你可以进行的实践操作来复习巩固

336
00:19:21,030 --> 00:19:26,340
主要的内容就有以下这些就是了，slow-query 内存表的使用与诊断

337
00:19:26,345 --> 00:19:27,330
的排查

338
00:19:27,390 --> 00:19:30,600
查看 slow-query 的执行计划统计信息的导入导出

339
00:19:31,080 --> 00:19:33,210
模拟读取热点并定位

340
00:19:33,750 --> 00:19:37,080
模拟读取热点的话，我们我们可以通过

341
00:19:37,170 --> 00:19:40,590
并发的去执行某个 SQL

342
00:19:41,790 --> 00:19:47,100
下面的话，我们就是一些您在课，课余之后可以进行巩固的操作

343
00:19:47,105 --> 00:19:47,730
操作

344
00:19:48,300 --> 00:19:49,020
比如

345
00:19:49,350 --> 00:19:53,850
slow-query 内存表的使用以及诊断排查，查看 slow-query 的执行计划

346
00:19:54,240 --> 00:19:55,980
统计信息的导出导入

347
00:19:56,220 --> 00:19:58,530
模拟读取信息的热点并定位

348
00:19:58,920 --> 00:20:00,780
获取热点表的 region  分布

349
00:20:01,020 --> 00:20:03,420
从热点 region 找到是哪一张表

350
00:20:03,810 --> 00:20:06,570
手动进行 region 的分裂和迁移

351
00:20:06,720 --> 00:20:09,060
掌握火焰图的采集方式

352
00:20:09,180 --> 00:20:13,320
以及熟悉 TiDB 的常用小工具，并了解其应用场景

353
00:20:15,660 --> 00:20:20,970
另外，如有疑问，可以登录 PingCAP 的官方网网校 University.PingCAP.com

354
00:20:21,300 --> 00:20:23,010
去查询

355
00:20:26,970 --> 00:20:29,790
这次的主要培训就到这里，谢谢大家

356
00:20:34,500 --> 00:20:35,100


