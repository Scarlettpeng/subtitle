1
00:00:13,020 --> 00:00:13,890
大家好

2
00:00:13,895 --> 00:00:17,970
本节课的内容是tidb sql优化与业务开发时间

3
00:00:18,780 --> 00:00:22,980
我是秦天爽，在pingcap平台负责华北地区的售后服务工作

4
00:00:23,850 --> 00:00:28,380
本节课主要分为两章，SQL优化与业务开发实践

5
00:00:30,570 --> 00:00:32,820
我们直接进入SQL优化的部分

6
00:00:32,825 --> 00:00:36,300
SQL优化实践的第一个案例叫做外连接简化

7
00:00:37,350 --> 00:00:42,270
在本节课中，我们需要用到，ssh终端连接到一个？

8
00:00:42,360 --> 00:00:43,590
Tidb的环境

9
00:00:46,260 --> 00:00:51,570
我目前使用的是一个自己的虚拟机环境，可以看到我的tidb集群的版本是？

10
00:00:51,575 --> 00:00:52,890
2.1.15

11
00:00:53,700 --> 00:00:55,080
就可以通过

12
00:00:55,230 --> 00:00:59,490
select tidb_version()，这样一个内置函数

13
00:00:59,760 --> 00:01:01,860
来确认，目前集群的版本

14
00:01:01,890 --> 00:01:03,360
这里面会包含

15
00:01:04,080 --> 00:01:06,720
打包的日期和具体的给git hash

16
00:01:09,270 --> 00:01:10,980
OK嗯

17
00:01:11,610 --> 00:01:14,550
我现在创建一个新的数据库

18
00:01:18,180 --> 00:01:20,160
然后我们进入这个数据库

19
00:01:24,510 --> 00:01:27,090
创建两张表t1，跟t2

20
00:01:31,800 --> 00:01:32,820
我不知道

21
00:01:36,300 --> 00:01:38,940
然后向表中写入一些数据

22
00:01:43,650 --> 00:01:44,250
我不知道

23
00:01:48,960 --> 00:01:54,270
我可以我想表二中写入一些数据，我们可以通过select语句来查询一下

24
00:01:54,750 --> 00:01:56,370
表2，目前的内容

25
00:01:58,170 --> 00:01:59,070
我知道

26
00:01:59,190 --> 00:02:02,280
呃，可以看到，在第一个阶段，a上面

27
00:02:02,430 --> 00:02:05,670
他有五个不同的值

28
00:02:07,710 --> 00:02:09,120
是空值

29
00:02:10,200 --> 00:02:12,420
其中b字段是唯一索引

30
00:02:12,480 --> 00:02:15,120
目前我输入的都是空值

31
00:02:19,830 --> 00:02:20,430
ok

32
00:02:20,580 --> 00:02:25,680
可以接下来我们使用了，analyze 语句来收集一下两张表的统计信息


33
00:02:28,980 --> 00:02:32,460
然后我们来看一下第一条语句的执行计划

34
00:02:32,490 --> 00:02:37,800
那这条语句是一个select *from t1表关联t2表使用的关联字段

35
00:02:37,805 --> 00:02:42,270
这其中的关联键是t1表的a字段跟ta表的a字段

36
00:02:43,740 --> 00:02:47,520
那我们来解读一下这个执行计划

37
00:02:48,450 --> 00:02:51,540
可以看到他使用的依然是左外连接

38
00:02:54,510 --> 00:02:57,510
然后关联字段是t1的a和t2的a

39
00:03:02,220 --> 00:03:06,060
那我们对这个语句做一些加工

40
00:03:08,040 --> 00:03:09,900
给他加上一个where条件

41
00:03:10,560 --> 00:03:14,580
where条件是t2的b字段要大于10

42
00:03:15,270 --> 00:03:19,530
那可以看目前的执行计划已经变成了一个内连接

43
00:03:20,970 --> 00:03:22,590
这是因为？

44
00:03:24,120 --> 00:03:29,430
这是因为tidb有一个外连接简化的这么一个

45
00:03:29,435 --> 00:03:30,240
性能优化

46
00:03:30,750 --> 00:03:31,830
那当

47
00:03:31,920 --> 00:03:33,930
一个外连接的语句

48
00:03:34,290 --> 00:03:37,230
他所使用的其中一张表的

49
00:03:37,470 --> 00:03:38,610
这段上面

50
00:03:38,910 --> 00:03:40,770
呃，加了一个

51
00:03:40,950 --> 00:03:42,840
关于长直的判断那

52
00:03:42,930 --> 00:03:46,200
这样在SQL语义上，它是会过滤掉所有空值的

53
00:03:46,440 --> 00:03:49,470
过过滤掉空值之后，实际上就是不允许

54
00:03:50,190 --> 00:03:51,990
左关联的

55
00:03:52,020 --> 00:03:54,510
右侧的那张表不准出现空值

56
00:03:54,780 --> 00:03:57,570
那这样实际上它就是一个内连接

57
00:03:59,820 --> 00:04:03,480
第二个SQL优化的实践案例是复合索引的实践

58
00:04:03,660 --> 00:04:06,840
在之前的理论课中，我们曾经了解到

59
00:04:07,080 --> 00:04:12,390
tidb目前还没有 index merge 功能，也就是说，在对一张表的一次查

60
00:04:12,395 --> 00:04:13,230
询中

61
00:04:13,590 --> 00:04:16,170
tidb目前还只能使用一个，索引

62
00:04:17,010 --> 00:04:19,770
那这就涉及到复合索引的设计

63
00:04:21,570 --> 00:04:22,620
呃

64
00:04:22,650 --> 00:04:25,380
我们先创建一张表三

65
00:04:27,450 --> 00:04:30,180
OK，可以看到它有这样几个字段

66
00:04:30,360 --> 00:04:34,080
ABCde，有不同的数据类型从整形

67
00:04:36,480 --> 00:04:38,040
decimal，然后

68
00:04:38,160 --> 00:04:40,020
varchar，double timestamp

69
00:04:47,100 --> 00:04:50,280
我们来看一下这样一条SQL的执行计划

70
00:04:50,430 --> 00:04:53,850
那他是查询了这张表的所有字段

71
00:04:54,870 --> 00:05:00,150
通过一个筛选条件，a=5  b=5.2 和c=OK来做一个判断

72
00:05:00,810 --> 00:05:03,690
那可以看到，目前是这样一个执行计划

73
00:05:04,380 --> 00:05:06,840
呃，他是一个全表扫描

74
00:05:06,990 --> 00:05:09,090
使用的统计信息是一个

75
00:05:09,095 --> 00:05:10,350
唯一的信息

76
00:05:10,650 --> 00:05:13,350
因为这个表中没有数据，我也没有做完的

77
00:05:14,700 --> 00:05:16,410
在这边可以看到

78
00:05:16,650 --> 00:05:18,840
他做的就是这样的一个查询

79
00:05:19,140 --> 00:05:24,450
先筛出来a=5，然后再去找b=5.2之后再去找c等

80
00:05:24,455 --> 00:05:25,350
于OK

81
00:05:28,260 --> 00:05:31,440
接下来我们为这张表增加一个复合索引

82
00:05:35,970 --> 00:05:39,330
复合索引的字段顺序是ABC

83
00:05:44,040 --> 00:05:44,640
我不知道

84
00:05:46,440 --> 00:05:48,090
我们可以来

85
00:05:48,095 --> 00:05:50,220
收集一下这张表的统计信息

86
00:05:54,930 --> 00:05:55,530
我想知道

87
00:05:58,350 --> 00:06:03,660
然后我们再执行一下，刚刚那条语句的执行计划来看，这个执行计划

88
00:06:03,665 --> 00:06:04,800
有什么变化？

89
00:06:05,700 --> 00:06:10,830
可以看到，这里依然是一个为统信息，因为表内还没有数据

90
00:06:12,870 --> 00:06:16,350
这里就可以用到这个刚刚创建的，索引

91
00:06:16,380 --> 00:06:18,300
ABC这个索引

92
00:06:18,930 --> 00:06:19,530
那

93
00:06:20,460 --> 00:06:23,550
这里所以你的取值范围是5.2 OK

94
00:06:23,610 --> 00:06:24,810
是一个检查

95
00:06:24,840 --> 00:06:26,400
前后的范围是一样的

96
00:06:29,190 --> 00:06:34,200
这也是一个比较优化的SQL，因为这个索引跟这个查询非常的契合

97
00:06:35,340 --> 00:06:37,530
那接下来我们看这样一个SQL

98
00:06:39,390 --> 00:06:43,230
我们把c=OK变成了c like

99
00:06:43,800 --> 00:06:47,280
用前缀，OK来做匹配这么一条sql

100
00:06:49,290 --> 00:06:51,570
那解读一下这个执行计划

101
00:06:52,410 --> 00:06:54,750
下面的还是一样，还是？

102
00:06:56,730 --> 00:06:58,950
走的这个伪执行计划

103
00:06:59,790 --> 00:07:03,150
然后这里从点查变成了一个范围查询

104
00:07:03,240 --> 00:07:05,940
具体的范围是5.2 OK

105
00:07:06,060 --> 00:07:07,920
到5.2 OL

106
00:07:08,010 --> 00:07:08,790
这样

107
00:07:08,850 --> 00:07:11,130
右侧是一个开区间的，这么一个范围

108
00:07:13,530 --> 00:07:16,290
他也是可以完全走这个索引扫描

109
00:07:20,610 --> 00:07:22,680
接下来我们再看下一个语句

110
00:07:25,560 --> 00:07:26,970
那这个语句

111
00:07:27,150 --> 00:07:29,820
跟最开始的第一语句的区别是

112
00:07:30,060 --> 00:07:31,770
我们把a=5

113
00:07:31,800 --> 00:07:34,350
变成了a in 12345

114
00:07:34,920 --> 00:07:39,390
对tidb来说，检查的查询位置只有两种

115
00:07:39,510 --> 00:07:40,770
等号和in

116
00:07:41,610 --> 00:07:46,920
刚刚是一个等号的案例，那这里用一个in答案，实际上它是一个并列的

117
00:07:46,925 --> 00:07:47,730
检察

118
00:07:48,240 --> 00:07:51,450
他就会分别去检查12345，跟

119
00:07:51,660 --> 00:07:54,660
B=5.2和c=OK的这样的组合

120
00:07:55,290 --> 00:07:57,720
这个也可以通过执行计划来看到

121
00:07:58,290 --> 00:08:00,840
她在这里也列出了这样?

122
00:08:01,890 --> 00:08:02,910
那这样

123
00:08:03,060 --> 00:08:06,480
他也是可以非常完美的用到ABC的这个，索引

124
00:08:10,260 --> 00:08:11,790
接下来就是按照

125
00:08:12,600 --> 00:08:13,230
对啊！

126
00:08:13,470 --> 00:08:18,780
将where条件中a的等值查询变成一个范围查询a小于5

127
00:08:19,710 --> 00:08:22,530
我们可以看到，这个执行计划

128
00:08:23,070 --> 00:08:24,690
发生了怎样的变化？

129
00:08:25,470 --> 00:08:28,800
那这里还是会走这个索引ABC

130
00:08:29,430 --> 00:08:34,620
但是具体用到索引的字段，从这里可以看出，就只有第一个字母，a

131
00:08:34,890 --> 00:08:37,650
一个取值范围从负无穷到五

132
00:08:38,220 --> 00:08:40,260
我这边有一个小于5

133
00:08:40,350 --> 00:08:41,970
所以它是一个开区间

134
00:08:42,540 --> 00:08:44,850
另外两个字段，b跟c

135
00:08:47,160 --> 00:08:49,530
由于a是一个范围查询

136
00:08:49,890 --> 00:08:52,650
在tidb中，目前这两个字段

137
00:08:52,890 --> 00:08:56,010
作为索引的后续的两个字段，是无法？

138
00:08:56,280 --> 00:08:58,170
构建一个索引上来的

139
00:08:58,350 --> 00:08:59,250
所以

140
00:08:59,370 --> 00:09:03,480
可以出去两个阶段，在这个查询中，没法用到，所以

141
00:09:05,760 --> 00:09:07,650
我们再看下一个案例

142
00:09:10,590 --> 00:09:15,810
下一案例是将a的查询条件变成a？

143
00:09:16,950 --> 00:09:19,260
在看tidb中，除了

144
00:09:19,440 --> 00:09:24,570
等号跟in之外，其他的查询位置都是范围查询

145
00:09:25,290 --> 00:09:28,080
所以这里看到这个

146
00:09:29,220 --> 00:09:32,910
执行计划跟刚刚上一个SQL是类似的

147
00:09:33,750 --> 00:09:35,430
a个字段

148
00:09:35,760 --> 00:09:38,460
可以走到点差，查的是说

149
00:09:38,880 --> 00:09:40,860
从null到null这样一个范围

150
00:09:41,070 --> 00:09:44,550
啊，但是有也知道是一个范围茶学院后面的一些

151
00:09:44,670 --> 00:09:47,280
B，跟c的阶段是没办法走，索引的

152
00:09:47,580 --> 00:09:49,410
所以看到再来一次浙江地方

153
00:09:49,500 --> 00:09:51,150
只有a能走，索引

154
00:09:54,210 --> 00:09:56,670
下一SQL也是类似的

155
00:09:57,810 --> 00:10:01,320
只不过我们把范围查询到了，字段有a

156
00:10:01,440 --> 00:10:02,580
变成b

157
00:10:02,850 --> 00:10:07,470
a是一个等值查询，b是一个范围查询，c也是一个等值查询

158
00:10:08,250 --> 00:10:13,560
那可以看到走索引的范围是ABC 中的，AB二个字段

159
00:10:13,565 --> 00:10:14,490
我们知道

160
00:10:15,240 --> 00:10:17,970
这里的取值范围是从

161
00:10:18,360 --> 00:10:20,730
5.20

162
00:10:21,390 --> 00:10:25,080
这样一个开区间，因为这里是b大于5.2

163
00:10:25,800 --> 00:10:27,570
然后到了

164
00:10:27,780 --> 00:10:28,800
正无穷

165
00:10:28,920 --> 00:10:30,240
这样一个B区间

166
00:10:30,270 --> 00:10:32,040
另外一个时段，C

167
00:10:32,070 --> 00:10:36,390
由于他跟在一个范围查询字段的号码

168
00:10:37,230 --> 00:10:42,540
啊，这里说的前后顺序，主要是他在索引中的顺序并不是指他在where条件中的顺序

169
00:10:42,545 --> 00:10:43,350
我开始

170
00:10:43,710 --> 00:10:45,420
由于她在一个

171
00:10:45,570 --> 00:10:47,760
范围查询b字段的后面

172
00:10:48,780 --> 00:10:50,820
他是没办法走索引的

173
00:10:55,470 --> 00:10:56,100
我知道

174
00:10:57,810 --> 00:10:59,460
好吧！

175
00:11:00,330 --> 00:11:02,520
那下一案例的我们把

176
00:11:02,940 --> 00:11:06,690
前两个字段都调回等值查询检查

177
00:11:07,080 --> 00:11:08,790
那最后一个c

178
00:11:08,880 --> 00:11:09,810
我们

179
00:11:10,170 --> 00:11:15,480
把它设置成这种用后缀或者作用非前缀来匹配的

180
00:11:15,840 --> 00:11:16,950
where语句

181
00:11:17,160 --> 00:11:18,600
我们可以看到

182
00:11:19,350 --> 00:11:21,960
在使用ABC这个索引的

183
00:11:23,220 --> 00:11:24,600
时候！

184
00:11:25,170 --> 00:11:27,960
只有AB两个阶段是能索引的

185
00:11:28,200 --> 00:11:32,760
c，虽然它是一个范围查询，或者说非检查

186
00:11:32,850 --> 00:11:37,500
但是由于它使用了非前缀做匹配以条件关键条件

187
00:11:39,180 --> 00:11:43,410
这些非前缀匹配的长期位置，目前是没办法走索引

188
00:11:43,740 --> 00:11:44,610
其实

189
00:11:44,615 --> 00:11:46,140
也是一个

190
00:11:46,410 --> 00:11:49,470
在索引上处于一个可以利用到的位置

191
00:11:49,860 --> 00:11:51,450
那也是没办法走索引

192
00:11:53,940 --> 00:11:56,250
然后我们要做出一些调整

193
00:11:57,060 --> 00:11:59,580
来创建一个新的，索引AC b

194
00:12:03,810 --> 00:12:06,510
我们来观察一下刚刚的

195
00:12:07,350 --> 00:12:10,890
几条sql的执行计划在这边会出现什么变化？

196
00:12:13,050 --> 00:12:17,070
首先是这条三个字段都是检查的sql

197
00:12:17,160 --> 00:12:20,280
可以看到，还是完美的走过这个作业ABC

198
00:12:23,100 --> 00:12:26,430
为了排除这个索引ABC的单元

199
00:12:27,150 --> 00:12:29,490
我们可以把它照出来

200
00:12:37,530 --> 00:12:40,650
OK，这样表达的只有一个AC b的索引

201
00:12:41,010 --> 00:12:46,320
我们再次之前刚刚对调三个检查的字符可以看到，由于没有了acd的干扰

202
00:12:47,910 --> 00:12:50,730
他就可以直接使用AcB这个索引

203
00:12:50,910 --> 00:12:53,430
是一个完美的检查

204
00:12:58,740 --> 00:13:00,600
然后来看一下这SQL

205
00:13:02,490 --> 00:13:04,050
那这条SQL呢？

206
00:13:04,320 --> 00:13:08,280
由于字段中额外承担中的a

207
00:13:09,120 --> 00:13:14,430
跟b都是一个数值，然后c1是一个范围看起来，但是由于索引的位置

208
00:13:14,435 --> 00:13:15,480
发生了改变

209
00:13:15,810 --> 00:13:20,160
c，变成了中间的时候，那由于c是范围查询，所以后面的b

210
00:13:20,280 --> 00:13:21,690
就没办法走，索引

211
00:13:21,990 --> 00:13:25,230
能从这个执行计划中也可以印证这一点

212
00:13:25,950 --> 00:13:29,970
他是一个从a OK到5，OL

213
00:13:30,030 --> 00:13:33,150
这边是一个开区间这样一个范围

214
00:13:33,990 --> 00:13:38,190
b字段由于没办法走索引，最后走一个

215
00:13:38,310 --> 00:13:39,270
表扫描

216
00:13:43,980 --> 00:13:44,610
天呐

217
00:13:46,530 --> 00:13:51,840
那再看一下，如果我们把c的外表条件换成了c前缀匹配

218
00:13:52,350 --> 00:13:54,240
由于c

219
00:13:54,810 --> 00:13:57,900
本身就是一个没办法走索引的

220
00:13:58,650 --> 00:13:59,880
查询位置

221
00:14:00,390 --> 00:14:02,940
like用c前缀做匹配

222
00:14:03,600 --> 00:14:08,910
啊，这边可以看到，索引AC b中就只有a可以走索引

223
00:14:09,540 --> 00:14:10,980
那是一个检查

224
00:14:11,520 --> 00:14:13,890
另外的两个字段c跟b

225
00:14:14,250 --> 00:14:19,050
由于c走不了索引，所以c后面的另外一个字段b也没办法走，索引

226
00:14:21,030 --> 00:14:24,120
那我们就第二章业务开发实践

227
00:14:24,180 --> 00:14:26,970
第一个案例叫做？？不可信？

228
00:14:27,930 --> 00:14:31,320
首先，我们来创创建一张表

229
00:14:31,410 --> 00:14:35,100
t4，然后向t4表中写入两行数据

230
00:14:36,360 --> 00:14:39,720
那从这里开始，案例我们要用到

231
00:14:39,870 --> 00:14:41,250
两个终端

232
00:14:42,240 --> 00:14:44,790
来模拟两个事物的冲突

233
00:14:47,460 --> 00:14:49,830
这样，我创建了另外一个

234
00:14:50,610 --> 00:14:53,310
show processlist，他是在这里面看一下

235
00:14:55,890 --> 00:15:00,300
当前，数据库上的时候，两个连接了，顺便再我两个table里面

236
00:15:03,510 --> 00:15:06,990
那PPT上的表格

237
00:15:07,170 --> 00:15:12,480
最左侧的是时间轴，我们要依照这个时间轴分别在两个终

238
00:15:12,485 --> 00:15:13,440
端里面？

239
00:15:13,650 --> 00:15:17,490
去来操作事物，a，跟事务b来摹拟事物之间的冲突

240
00:15:18,210 --> 00:15:22,200
那第一时间我们需要在事务a中社会化中执行一个begin

241
00:15:26,010 --> 00:15:28,200
12时间还是在15分钟

242
00:15:28,500 --> 00:15:30,690
执行一个update语句

243
00:15:31,080 --> 00:15:34,800
那执行完这个udate可以看到，row是1行

244
00:15:37,770 --> 00:15:40,020
那这时候要来到

245
00:15:40,050 --> 00:15:42,330
在t3，时间要来到事务b

246
00:15:42,540 --> 00:15:45,450
也就是我们的第二个终端之间一个begin

247
00:15:47,490 --> 00:15:50,340
同样也是啊，update一行数据

248
00:15:50,370 --> 00:15:54,630
那个这里可以看到rows是1杭

249
00:15:55,080 --> 00:16:00,390
需要注意的是，事务a跟事务b

250
00:16:00,960 --> 00:16:03,090
他所更新的

251
00:16:03,540 --> 00:16:05,070
值是不一样的

252
00:16:05,310 --> 00:16:09,720
呃，其中事务a需要把这一第一行数据更新为

253
00:16:10,530 --> 00:16:12,450
11这样一个状态

254
00:16:13,080 --> 00:16:18,390
事务b要把这些更新为12这样的状态，他们用的where条件是id=1

255
00:16:18,395 --> 00:16:19,920
并且，状态等于0

256
00:16:22,170 --> 00:16:24,360
再在t5这个时间轴上

257
00:16:24,750 --> 00:16:26,790
我们要回到事务a

258
00:16:27,330 --> 00:16:29,340
执行一个提交操作

259
00:16:34,950 --> 00:16:37,500
然后再另外一个事物执行提交

260
00:16:38,910 --> 00:16:42,450
可以看到，这两个事物都没有任何的报错

261
00:16:44,130 --> 00:16:46,710
我们去查询它最终结果

262
00:16:47,070 --> 00:16:48,630
对方的结果的时候

263
00:16:53,340 --> 00:16:53,940
我知道

264
00:16:54,150 --> 00:16:58,590
我可以看到，由于我在这边是在事务b先提交的

265
00:17:02,880 --> 00:17:06,720
那最终的结果就被改成事务b想要改成的样子

266
00:17:07,590 --> 00:17:10,950
虽然这边事务A提交成功了

267
00:17:11,250 --> 00:17:16,560
也没有任何报错，但是他丢失了自己的更新，那就叫一个丢失

268
00:17:16,565 --> 00:17:17,940
更新异常现象

269
00:17:18,420 --> 00:17:20,580
这是由于虽然这里

270
00:17:20,700 --> 00:17:23,010
表面上看是一个提交操作

271
00:17:23,610 --> 00:17:27,870
但在tidb3.0rc.2

272
00:17:28,020 --> 00:17:29,370
之前的版本

273
00:17:29,730 --> 00:17:31,050
tidb

274
00:17:31,830 --> 00:17:33,870
有一个开关叫做

275
00:17:34,350 --> 00:17:36,660
??

276
00:17:36,720 --> 00:17:41,580
就是说禁止事物自动方式，这么一个开关，那就开关默认是

277
00:17:41,640 --> 00:17:43,230
允许自动重试的

278
00:17:44,160 --> 00:17:49,470
当这里提交的时候，实际上会检测到一个数据的

279
00:17:50,040 --> 00:17:51,360
版本的冲突

280
00:17:52,500 --> 00:17:53,580
那这时候

281
00:17:54,450 --> 00:17:59,040
这个事物就会重试，重试之前要去获取一个新的签收

282
00:17:59,610 --> 00:18:03,180
获取一个签收，就相当于见到了一个新的事务

283
00:18:03,210 --> 00:18:08,130
而且这个事物的开始时间是晚于这边儿commit时间了

284
00:18:08,340 --> 00:18:12,510
相当于在重试的时候，这两个数据变成了一个串行的状态

285
00:18:14,250 --> 00:18:19,560
问题在于，由于这边他使用的是ID=1，并且状态等于零

286
00:18:19,565 --> 00:18:20,970
那一个筛选也条件

287
00:18:21,570 --> 00:18:24,360
由于她在事务b之后才开始

288
00:18:24,510 --> 00:18:29,490
事务b在重试的时候，读的数据是12 

289
00:18:29,520 --> 00:18:30,810
什么银行数据？

290
00:18:30,930 --> 00:18:36,210
那根据他的拆迁条件，一点实这样，它是筛选如何任何银行数据了

291
00:18:36,570 --> 00:18:39,540
最终，在重试的时候这个

292
00:18:39,810 --> 00:18:42,750
真实的？就是0行

293
00:18:42,990 --> 00:18:46,500
但是由于tidb自动重试的机制

294
00:18:46,680 --> 00:18:50,730
这些所有的操作都被隐藏在commit语句当中

295
00:18:51,150 --> 00:18:52,980
并不会，返回给客户端

296
00:18:53,130 --> 00:18:54,750
也就是说当

297
00:18:55,620 --> 00:18:59,250
您的集群使用的自动重试的机制的时候

298
00:18:59,610 --> 00:19:04,710
或者说您的这个事物运行在自动重试了这么一个

299
00:19:05,310 --> 00:19:06,450
场景下面

300
00:19:07,080 --> 00:19:07,800
啊？

301
00:19:08,130 --> 00:19:10,320
就有可能发生这种

302
00:19:11,160 --> 00:19:16,470
丢失更新的异常，而且这个丢失更新可能是不被你所知道的

303
00:19:18,150 --> 00:19:23,460
也就是说，在开了自动重事机制的集群下面

304
00:19:23,465 --> 00:19:25,710
？，此时不可以相信

305
00:19:26,700 --> 00:19:30,750
我可以我们进入下一个场景省select for update的使用

306
00:19:30,870 --> 00:19:34,260
一个场景是可以重试的业务场景

307
00:19:35,070 --> 00:19:37,410
我们需要创建一张新表t5

308
00:19:37,590 --> 00:19:39,330
并且写了三行数据

309
00:19:39,930 --> 00:19:42,240
可以看一下这三行数据的样子

310
00:19:44,700 --> 00:19:47,490
那可以看到它是一张

311
00:19:47,730 --> 00:19:52,500
账户余额表有三个账户，123，他们的初始余额一万

312
00:19:55,590 --> 00:20:00,030
这个测试还是跟刚刚的，之前的那个测试是一样

313
00:20:00,210 --> 00:20:02,940
那需要遵循这个时间轴去操作

314
00:20:03,240 --> 00:20:06,600
然后模拟的事物a 跟b事务的冲突

315
00:20:07,350 --> 00:20:09,030
昨天我们的是事务a

316
00:20:09,870 --> 00:20:10,770
这边

317
00:20:11,130 --> 00:20:12,360
开始一个数

318
00:20:13,530 --> 00:20:16,200
然后查询t5表中的内容

319
00:20:18,060 --> 00:20:18,690
哪他的时候

320
00:20:19,410 --> 00:20:22,950
那他这时候已经检测到了三行数据

321
00:20:24,210 --> 00:20:25,110
然后

322
00:20:26,310 --> 00:20:28,470
使用最大语句来模拟

323
00:20:29,490 --> 00:20:31,020
账号

324
00:20:31,650 --> 00:20:36,840
二跟一之间的转账是由账号二上账号一转账号1000

325
00:20:39,960 --> 00:20:44,010
那接下来我们在另外一个事务中作一个类似的操作

326
00:20:44,040 --> 00:20:49,050
只不过转账的账号由二转到一变成了由三转到一

327
00:20:52,710 --> 00:20:53,310
一部分

328
00:20:55,680 --> 00:20:56,490
OK

329
00:21:00,780 --> 00:21:04,380
然后我们在事务b抢先提交

330
00:21:06,990 --> 00:21:09,570
然后在回到事务a提交

331
00:21:14,130 --> 00:21:17,820
然后在两边去查询这个

332
00:21:18,120 --> 00:21:19,290
最终的余额

333
00:21:19,650 --> 00:21:20,820
你会发现

334
00:21:22,170 --> 00:21:24,840
虽然我在你肯定都是学校

335
00:21:24,870 --> 00:21:26,910
我人为是模拟的一个冲突

336
00:21:27,000 --> 00:21:31,290
然后提交比较慢的，这个事务a他是一个重试操作的

337
00:21:31,800 --> 00:21:34,230
但是最后的总账是没有问题

338
00:21:34,410 --> 00:21:36,750
就是说在并发的冲突的

339
00:21:37,560 --> 00:21:40,050
我这里即使发生了重试

340
00:21:40,410 --> 00:21:45,150
但由于这SQL的想法是每次都要获取一个新的余额的

341
00:21:45,420 --> 00:21:46,590
字段的值

342
00:21:46,800 --> 00:21:50,040
然后在新余额的字段值的基础上，再去做转账

343
00:21:50,250 --> 00:21:52,560
那这个时候，他的总账会不会有问题？

344
00:21:52,710 --> 00:21:57,180
也就是说，在本质上，他是一个可以重试的业务逻辑

345
00:21:57,720 --> 00:22:00,810
主要这种可以重试的业务给我们使用这种

346
00:22:00,900 --> 00:22:02,910
每次获取最新余额的

347
00:22:03,630 --> 00:22:05,850
或者说，基于SQL，去做了

348
00:22:05,855 --> 00:22:07,530
数学运算的方式

349
00:22:07,650 --> 00:22:09,540
就可以得到一个正确的结果

350
00:22:10,380 --> 00:22:15,690
那你让tidb去做重试的时候也可以降低你的事物，重试中的失败率

351
00:22:16,230 --> 00:22:18,270
就是一个比较推荐办法！

352
00:22:19,920 --> 00:22:24,360
那我们来看select for update的使用中的第二个案例不可重试的sql

353
00:22:25,890 --> 00:22:28,800
首先，我们来清空刚刚的这张表五

354
00:22:29,370 --> 00:22:31,290
然后把数据重新写回

355
00:22:31,440 --> 00:22:32,550
我知道

356
00:22:32,580 --> 00:22:36,150
可以看到，目前三个账户的余额都是一万

357
00:22:38,550 --> 00:22:41,340
然后我们开启事务a

358
00:22:42,570 --> 00:22:45,060
执行select update 语句

359
00:22:47,610 --> 00:22:50,880
那可以看到查到的账户中的余额是一万

360
00:22:52,110 --> 00:22:52,710
我不知道

361
00:22:53,040 --> 00:22:55,470
然后我们要开始像

362
00:22:56,190 --> 00:22:59,430
从账户一向账户二转账一万

363
00:23:00,450 --> 00:23:05,340
那接下来开始开启事务b做同样的操作并且来提交

364
00:23:09,960 --> 00:23:12,810
我这边看到事务b已经完成了提交

365
00:23:16,500 --> 00:23:19,470
这时候我们再回到是事务b来执行提交

366
00:23:20,700 --> 00:23:24,300
这就收到了一个报错是说

367
00:23:24,510 --> 00:23:26,910
他说 can not retry select for update seatement

368
00:23:27,900 --> 00:23:33,210
也就是说，在tidb当你开启事务，事务重试开关了

369
00:23:33,215 --> 00:23:34,050
20号

370
00:23:34,140 --> 00:23:38,160
当你的车扣中你的事务中有用到的话，非常有趣

371
00:23:39,090 --> 00:23:42,240
当可comit，如果检测到版本之间的冲突

372
00:23:42,570 --> 00:23:44,550
比如说有抢先人了你

373
00:23:44,820 --> 00:23:48,420
要更改的行行做出了提交有了更新的版本

374
00:23:48,570 --> 00:23:50,850
所以他们这里也是可以检测到

375
00:23:51,690 --> 00:23:55,200
但由于你的select for update这样的语句

376
00:23:55,320 --> 00:23:58,740
这就是select for update 语句 在tidb中的一个表现

377
00:24:01,200 --> 00:24:06,510
那我们可以在两个事务中查询最新的余额来验证这一点

378
00:24:06,750 --> 00:24:08,220
你可以看到

379
00:24:09,180 --> 00:24:11,370
这个转账是由这边

380
00:24:11,430 --> 00:24:14,400
抢先提交的事务b

381
00:24:14,460 --> 00:24:15,510
来达成的

382
00:24:15,690 --> 00:24:19,080
他是从账户1像账户3转账了一万

383
00:24:19,110 --> 00:24:21,000
账户三的余额变成了两万

384
00:24:23,670 --> 00:24:28,980
也就是说，tidb，如果使用select for update可以保障数据的一致性

385
00:24:29,850 --> 00:24:33,210
那时候带来的缺点就是说

386
00:24:33,570 --> 00:24:38,880
这里会引起晚提交数的失败，在冲突中的提交比较慢的事

387
00:24:38,885 --> 00:24:40,050
事会失败

388
00:24:41,460 --> 00:24:44,160
select for update 另一种使用场景

389
00:24:44,250 --> 00:24:47,670
就是被用来克服写偏斜

390
00:24:47,910 --> 00:24:50,220
让我们来看这个写偏斜的案例

391
00:24:51,090 --> 00:24:53,370
首先，创建一张表t6

392
00:24:57,780 --> 00:25:01,560
然后写入两行数据，你要看一下这行数据

393
00:25:04,170 --> 00:25:06,810
分别是10，20

394
00:25:08,490 --> 00:25:11,040
那这时候我开始一个事务a

395
00:25:14,220 --> 00:25:15,900
然后查询

396
00:25:17,220 --> 00:25:18,750
啊这两行数据

397
00:25:19,800 --> 00:25:21,990
并且用select for update这样的语句

398
00:25:22,530 --> 00:25:25,710
那这时候后来到一个第二个窗口

399
00:25:26,130 --> 00:25:27,660
开启一个事务b

400
00:25:27,840 --> 00:25:28,470
我不知道

401
00:25:28,980 --> 00:25:30,600
之前一样的语句

402
00:25:31,560 --> 00:25:33,960
对这个数据进二行数据了这个操作

403
00:25:35,010 --> 00:25:38,580
的然后我们又回来第一个事务窗口

404
00:25:39,330 --> 00:25:44,100
尝试去更改ID为一的这一行把他的值改为11

405
00:25:48,870 --> 00:25:54,180
接下来我们不提交事务1，接下来到事务2的窗口

406
00:25:55,770 --> 00:26:00,390
哎，对，第二次数据进行更改，尝试把第二个修改为二 二十四

407
00:26:02,670 --> 00:26:03,300
是啊！

408
00:26:04,290 --> 00:26:08,280
之后我们又回到第一个窗口，这样提交

409
00:26:09,030 --> 00:26:11,160
接下来的第二个窗口进行提交

410
00:26:11,370 --> 00:26:12,900
那可以看到

411
00:26:13,080 --> 00:26:15,300
依然报了这个八零零二的错误

412
00:26:15,420 --> 00:26:18,630
就是不能重试这种select for update语句

413
00:26:19,440 --> 00:26:20,400
呃

414
00:26:20,730 --> 00:26:26,010
他之所以在这里会报出这个错误，是因为在提交的时候，它检测到了

415
00:26:27,210 --> 00:26:32,520
有重复的一行，那这一行是在哪儿？被识别出来的，实际上

416
00:26:32,525 --> 00:26:33,570
就是在这里

417
00:26:33,840 --> 00:26:35,040
select for update

418
00:26:35,400 --> 00:26:37,170
他对这两双数据加速

419
00:26:37,710 --> 00:26:41,430
呃，由于tidb是乐观锁不会主动地锁住这些数据

420
00:26:41,460 --> 00:26:46,650
只是标识出说我在提交的时候要对这两行数据进行校验

421
00:26:47,460 --> 00:26:48,360
啊？

422
00:26:48,600 --> 00:26:51,060
虽然他更改的是第二行数据

423
00:26:51,390 --> 00:26:56,700
第一行数据是被另外一个事务提前给修改，并且提交可以，所以它在提交

424
00:26:56,705 --> 00:27:00,030
到时候检测到了第一套数据有一个更新的版本

425
00:27:00,510 --> 00:27:03,450
所以这里就会报一个不能重试的错误

426
00:27:04,350 --> 00:27:06,480
下一个案例是嵌套事务

427
00:27:08,430 --> 00:27:10,890
首先，我们创建一张表七

428
00:27:12,240 --> 00:27:14,310
可以看到表7有2个字段

429
00:27:14,340 --> 00:27:16,140
账号和状态

430
00:27:17,670 --> 00:27:20,250
啊，这时候我们开始一个事务a

431
00:27:20,400 --> 00:27:21,000
好

432
00:27:25,080 --> 00:27:28,020
然后执行一个对t7的查询

433
00:27:29,520 --> 00:27:30,120
没有

434
00:27:32,220 --> 00:27:32,880
我不知道

435
00:27:34,320 --> 00:27:35,400
对对对

436
00:27:36,840 --> 00:27:38,970
那这时候我不提交事务a

437
00:27:38,975 --> 00:27:41,100
另外开启一个事务b

438
00:27:44,040 --> 00:27:46,440
像表七中写入一行数据

439
00:27:51,120 --> 00:27:51,780
是很多

440
00:27:52,680 --> 00:27:55,800
然后提交对杭数据提交做的操作

441
00:27:57,480 --> 00:28:02,790
那这时候我们回到刚刚，还没有提交的事务a，尝试去更新刚刚事务b

442
00:28:02,795 --> 00:28:05,460
当右侧的数据写入的内涵

443
00:28:06,390 --> 00:28:08,700
可以看到，这里影响了这一行

444
00:28:09,210 --> 00:28:13,500
实际上，这个就是表明他没有筛选一行数据

445
00:28:15,000 --> 00:28:15,630
看看

446
00:28:16,800 --> 00:28:18,270
然后就先提交

447
00:28:21,090 --> 00:28:25,890
然后去查询表，t7中的数据发现

448
00:28:26,340 --> 00:28:29,610
并没有做出她想要的修改

449
00:28:30,390 --> 00:28:32,700
我想把这个状态就改为一天

450
00:28:34,380 --> 00:28:35,880
这个就是一个

451
00:28:36,000 --> 00:28:39,000
想让两个事务去嵌套的这么一个逻辑

452
00:28:39,005 --> 00:28:41,790
那tidb由于隔离级别比较高

453
00:28:42,120 --> 00:28:47,430
这个业务可能是从oracle或者db2隔离级别为

454
00:28:47,435 --> 00:28:49,080
rc的迁移过来

455
00:28:49,890 --> 00:28:53,670
在tidb上，这个比较高的隔离几天下来

456
00:28:55,140 --> 00:28:56,640
这里实际上

457
00:28:56,790 --> 00:28:58,470
在事物的一开始

458
00:28:58,650 --> 00:28:59,940
那大概这个位置

459
00:29:00,540 --> 00:29:02,700
就已经确定了一个

460
00:29:02,730 --> 00:29:05,880
本事务所能访问的数据的版本

461
00:29:06,390 --> 00:29:10,440
那在感受中，所有操作的数据都是基于这个版本的数据

462
00:29:11,250 --> 00:29:12,150


463
00:29:12,900 --> 00:29:17,400
右侧的事务b实际上是提交的时间就比较晚了

464
00:29:17,430 --> 00:29:20,610
在他提交的时候事务a

465
00:29:21,000 --> 00:29:26,310
早已开始，所以它能访问到的数据就是那张表是空的那个状态


466
00:29:27,270 --> 00:29:29,190
所以它更新不到这边

467
00:29:29,250 --> 00:29:31,050
之后写不了一行0

468
00:29:31,380 --> 00:29:34,170
她尝试去更新的时候是这样，打不上他目的

469
00:29:34,800 --> 00:29:38,220
那怎样才能在这个案例下完成这个嵌套呢？

470
00:29:39,240 --> 00:29:42,120
我们可以试着来做一个实验

471
00:29:45,120 --> 00:29:47,130
首先，清空这个表t7

472
00:29:50,760 --> 00:29:53,430
然后和刚才的步骤大体还是一样

473
00:29:53,460 --> 00:29:55,380
先之前一个bgein

474
00:29:55,770 --> 00:29:57,630
然后他执行一次查询

475
00:29:58,980 --> 00:30:02,640
那我们可以在这个查询这里，马上提交

476
00:30:03,870 --> 00:30:07,500
然后在右侧的事务b重新写入这一行数据

477
00:30:11,160 --> 00:30:16,470
由于刚刚已经做出了一个事务的提交，这边再去做一个update的操作

478
00:30:16,475 --> 00:30:20,430
做的时候，或者说我先加一个，begin，包括在事务里

479
00:30:21,510 --> 00:30:24,720
这种显示事务去操作它

480
00:30:25,140 --> 00:30:27,720
可以看到，这里就能更新一行数据

481
00:30:32,100 --> 00:30:34,260
那个时候我们再去查看

482
00:30:34,380 --> 00:30:36,450
表t7中的数据是什么呀？

483
00:30:38,790 --> 00:30:41,790
然后可以看到这个完成他想要做出的东西

484
00:30:42,150 --> 00:30:47,460
实际上也就是说，嗯，除非一个事务去在另外一个事务，之后开始

485
00:30:47,465 --> 00:30:51,030
它才能更新到前面一个事务已经提交的东西

486
00:30:52,080 --> 00:30:53,430
啊，这个是

487
00:30:53,610 --> 00:30:55,260
tidb

488
00:30:55,800 --> 00:30:58,680
无法做出这种事物嵌套的

489
00:31:00,030 --> 00:31:01,140
什么一个逻辑？

490
00:31:01,590 --> 00:31:05,130
类似的嵌套逻辑都要做出相应的修改

491
00:31:05,310 --> 00:31:08,310
左边的事务a，要不然就先提交

492
00:31:08,370 --> 00:31:10,800
要不然在后面想要去更新的时候

493
00:31:11,220 --> 00:31:13,920
在重新开始，开启一个新的事务

494
00:31:14,130 --> 00:31:19,050
在这儿边的update，再加一个begin就可以完成他的目标

495
00:31:22,260 --> 00:31:25,440
接下来我们来看tidb中的大事，如何建？

496
00:31:25,560 --> 00:31:28,830
tidb，对于事务量，还有一个严格的限制

497
00:31:29,010 --> 00:31:30,990
30万的配置操作

498
00:31:31,050 --> 00:31:36,360
因此，我们一般建议应用中要使用分页搜索的方式把大

499
00:31:36,365 --> 00:31:38,940
事务，拆成多个小事务

500
00:31:39,390 --> 00:31:42,600
现在人工的手动操作中

501
00:31:42,660 --> 00:31:47,970
实际上，去编写专业的SQL比较不太方便

502
00:31:47,975 --> 00:31:50,070
tidb这边提供了几个

503
00:31:50,100 --> 00:31:54,600
办事操作的开关，可以把大事务拆分的小事务

504
00:31:55,140 --> 00:31:58,530
需要注意的时候，它会破坏原则性

505
00:31:59,010 --> 00:32:04,320
因此，这些开关，而如果是写到应用的话，是我们完全不建议的方式

506
00:32:05,460 --> 00:32:08,190
就允许在手工

507
00:32:08,370 --> 00:32:12,660
复制数据表结构的，或者说复制表面数据的时候

508
00:32:13,080 --> 00:32:14,730
是允许使用

509
00:32:15,360 --> 00:32:20,670
这张测试我们需要用到sysbench的创建一张表，并且制作

510
00:32:20,675 --> 00:32:21,960
100万行数据

511
00:32:22,200 --> 00:32:23,610
我以前提前

512
00:32:23,790 --> 00:32:26,370
万成了这个操作，我们来看一下

513
00:32:27,600 --> 00:32:29,370
就是表中的数据量

514
00:32:35,100 --> 00:32:39,300
你可以看到，这边已经准备好了一张100万的数据量的表

515
00:32:40,710 --> 00:32:43,050
那接下来，我在我自己的库中

516
00:32:43,860 --> 00:32:48,900
根据这sysbench的表结构来模拟创建出两张表

517
00:32:50,940 --> 00:32:55,890
现在表已经创建好，那么尝试用insert into select这种语句

518
00:32:59,070 --> 00:33:00,720
来去复制

519
00:33:02,160 --> 00:33:04,560
sysbench这张表中的数据

520
00:33:09,270 --> 00:33:09,870
我不知道

521
00:33:12,060 --> 00:33:17,370
OK，由于我尝试直接去复制100万行数据，那他肯定是超过了30万

522
00:33:17,375 --> 00:33:18,570
KV都是你

523
00:33:19,380 --> 00:33:21,840
因为kv，里面还是计算索引的呢

524
00:33:21,990 --> 00:33:25,140
这里仅仅是数据就已经超过了100万

525
00:33:26,550 --> 00:33:31,860
然后sysbench的，报错那可以看到这个报错是说事物太大

526
00:33:32,760 --> 00:33:38,070
它的长度是300001，因为我们对于kt的限制量是30w个

527
00:33:38,075 --> 00:33:39,210
kv

528
00:33:39,360 --> 00:33:44,670
当他在尝试地写入尝试写入第30万零1，个的时候就尝试报错

529
00:33:44,675 --> 00:33:45,810
说到这个高考

530
00:33:48,060 --> 00:33:50,490
我们来验证一下

531
00:33:51,300 --> 00:33:52,590
t8表中

532
00:33:53,190 --> 00:33:55,890
是不是会写出来一些数据？那可以看到

533
00:33:56,010 --> 00:33:58,680
这个整个事务是被回滚

534
00:34:00,360 --> 00:34:05,670
tidb提供的事务的开关这个开关有一个统一的名字

535
00:34:05,675 --> 00:34:07,410
都叫batch

536
00:34:07,860 --> 00:34:09,120
我们来看一下

537
00:34:10,560 --> 00:34:13,050
我们系统变量具体叫什么名字？

538
00:34:19,830 --> 00:34:22,230
我们把关键字来搜索

539
00:34:25,980 --> 00:34:30,270
我们在这里要用到这个tidb_bach_insert

540
00:34:30,275 --> 00:34:33,330
他的指默认值是零，我们把它改成1

541
00:34:37,860 --> 00:34:40,110
这就表明我允许

542
00:34:40,320 --> 00:34:44,130
把一个大的insert的事务拆分成多个事务

543
00:34:44,520 --> 00:34:47,130
这时候，我们在尝试执行这条语句

544
00:34:49,680 --> 00:34:54,540
呃，由于大家可能知道这个操作是拆分的原则性的

545
00:34:54,720 --> 00:34:56,130
不破坏原子性

546
00:34:57,060 --> 00:35:01,950
也就是说，在这边我不断地去看t8的表的

547
00:35:02,730 --> 00:35:05,490
已有的数据量只会看到一个变化

548
00:35:13,650 --> 00:35:14,250
我想知道

549
00:35:16,350 --> 00:35:18,690
这里就可以看到他的

550
00:35:19,410 --> 00:35:20,640
逐渐的增长

551
00:35:25,350 --> 00:35:25,950
我想知道

552
00:35:32,130 --> 00:35:35,730
我们可以由于后面的测试，还要用到另外张表t9

553
00:35:36,030 --> 00:35:37,950
我们在现在

554
00:35:38,220 --> 00:35:40,650
也顺便把t9

555
00:35:41,070 --> 00:35:42,780
的数据也给拷过去

556
00:35:47,490 --> 00:35:48,090
哎呀

557
00:35:58,110 --> 00:36:03,420
OK，由于这边还没有设置那个变量，所以我们在这边设置一下变量

558
00:36:11,160 --> 00:36:14,280
我可以，然后在这边去复制t9

559
00:36:18,990 --> 00:36:19,590
我想听

560
00:36:24,300 --> 00:36:24,900
我想知道

561
00:36:29,610 --> 00:36:30,210
买的

562
00:36:30,750 --> 00:36:32,190
要确认一下进度

563
00:36:34,350 --> 00:36:34,980
我想知道

564
00:36:41,070 --> 00:36:43,350
t8，已经快写完了

565
00:36:46,950 --> 00:36:49,140
哦，这里可以看到

566
00:36:49,500 --> 00:36:52,920
在sql以及sql的返回上面

567
00:36:53,130 --> 00:36:58,440
跟mysql应对这个大事务方面是没有任何区别的

568
00:36:58,650 --> 00:37:02,370
但也要注意到时候这里面实际上tidb就会拆分他的原则性

569
00:37:02,610 --> 00:37:05,490
但到一定的批量的批次的大小

570
00:37:05,580 --> 00:37:08,100
去把那个大事务拆成为多个小事务

571
00:37:08,430 --> 00:37:10,950
如果在执行过程中

572
00:37:11,340 --> 00:37:12,750
出现了故障

573
00:37:12,755 --> 00:37:14,190
啊，导致

574
00:37:14,640 --> 00:37:19,950
tidb会崩溃，嗯，实际上是会写入一部分数据，然后另一部分数据是写入失败

575
00:37:19,955 --> 00:37:20,580
啊？

576
00:37:22,350 --> 00:37:25,650
因此，我们不建议把这个开关放到应用中

577
00:37:27,120 --> 00:37:30,990
去使用应用来调用这个功能就是非常危险

578
00:37:31,170 --> 00:37:32,400
会导致不可控

579
00:37:40,860 --> 00:37:43,350
我们来看一下t9写入多少？

580
00:37:44,670 --> 00:37:46,380
OK t9也写好了

581
00:37:49,800 --> 00:37:53,700
那这个batch_insert的问题已经解决了，我们来看一下

582
00:37:53,880 --> 00:37:57,510
在这里头怎么去通过一个开关的自动拆分？

583
00:37:59,010 --> 00:38:04,320
首先，我们来尝试去删除一个超过数量限制的

584
00:38:04,410 --> 00:38:05,340
行数

585
00:38:07,470 --> 00:38:09,240
然后来看一下它的报错

586
00:38:13,890 --> 00:38:17,070
ok 这边会收到一报错，报错说事务量过大

587
00:38:17,460 --> 00:38:22,770
刚刚看到这边有一个另外的参数，叫一个另外的系统变量的

588
00:38:22,775 --> 00:38:24,390
tidb_batch_delete

589
00:38:24,600 --> 00:38:29,910
它的作用跟刚刚的那个insert和之类似的，只不过它的作用范围是delete

590
00:38:31,380 --> 00:38:33,930
我们首先把它tidb_batch_delete改完1

591
00:38:34,560 --> 00:38:37,470
然后再尝试去执行这个删除

592
00:38:37,920 --> 00:38:43,230
那大家知道他是拆散了原子性的，我们可以用另外一个窗口

593
00:38:43,235 --> 00:38:46,620
我去跟踪他的记录，我可以说这边他写

594
00:38:49,890 --> 00:38:52,560
在这边来看一下t8的数据量

595
00:38:57,270 --> 00:38:57,870
哎呀

596
00:38:57,900 --> 00:39:00,240
可以看到，他已经删除了一部分数据

597
00:39:03,030 --> 00:39:05,010
然后再逐步的删除中

598
00:39:15,030 --> 00:39:15,630
我想知道

599
00:39:19,230 --> 00:39:20,220
我不知道

600
00:39:30,450 --> 00:39:35,760
删除这个操作，从他的语义上来判断，实际上是最容易写的

601
00:39:35,765 --> 00:39:36,510
所以

602
00:39:36,990 --> 00:39:38,310
我们在做

603
00:39:38,460 --> 00:39:40,500
控制好数据量的sql

604
00:39:40,830 --> 00:39:45,420
就是说你即使不通过，batch的开关可以通过

605
00:39:46,500 --> 00:39:51,810
delete from 加一个where条件，再用limit语句可以去控制每次删除的行数

606
00:39:51,815 --> 00:39:53,670
然后就循环delete limit

607
00:39:54,360 --> 00:39:56,040
也可以在那里面说这个语句

608
00:39:56,190 --> 00:39:58,110
就可以达成你的目标

609
00:39:58,740 --> 00:40:02,040
也看到这边已经删除了小于

610
00:40:02,400 --> 00:40:05,550
id值小于50万的

611
00:40:05,730 --> 00:40:07,770
49999行记录

612
00:40:11,790 --> 00:40:12,840
OK

613
00:40:12,845 --> 00:40:15,420
那接下来我们来看一下

614
00:40:16,320 --> 00:40:17,910
在吃饭，这个设置

615
00:40:18,360 --> 00:40:21,300
那刚刚这个案例是说

616
00:40:23,820 --> 00:40:25,290
delete的操作

617
00:40:30,000 --> 00:40:33,420
那我们再重新删一次t9

618
00:40:33,570 --> 00:40:36,510
来仔细地观察一下她删除了记录

619
00:40:38,220 --> 00:40:40,140
她原本有100万张记录

620
00:40:44,850 --> 00:40:45,450
我想知道

621
00:40:46,350 --> 00:40:48,000
在这里可以

622
00:40:48,840 --> 00:40:53,970
隐约的看出它是按照一个固定量的大小去做分批的提交

623
00:40:54,330 --> 00:40:58,560
这个参数是在哪儿控制的？实际上就是另外一个参数

624
00:40:59,250 --> 00:41:00,180
这边

625
00:41:00,360 --> 00:41:03,360
同样用batch搜索出来的

626
00:41:03,780 --> 00:41:06,720
一个系统变量，就是

627
00:41:07,020 --> 00:41:08,880
tidb_dml_batch_size

628
00:41:09,390 --> 00:41:13,050
它的默认值是两万，需要注意的是

629
00:41:13,350 --> 00:41:15,480
当但batch_delete

630
00:41:16,590 --> 00:41:18,930
和batch_inset 都为0的时候

631
00:41:19,080 --> 00:41:21,570
这个参数两万，实际上不生效了

632
00:41:21,600 --> 00:41:23,190
就是只有在

633
00:41:23,280 --> 00:41:28,590
一个batch开关，或者说至少一个batch开关打开之后，这个batch_size才是生效的

634
00:41:28,595 --> 00:41:29,670
我就没做了

635
00:41:30,600 --> 00:41:35,220
那我们可以把这个batch_size的量给调大

636
00:41:36,540 --> 00:41:39,390
我们尝试给他改到五万

637
00:41:44,100 --> 00:41:44,700
我想听

638
00:41:45,450 --> 00:41:47,970
然后我们继续删除

639
00:41:48,390 --> 00:41:49,920
t9表中的数据

640
00:41:50,040 --> 00:41:52,320
直至把他都删完

641
00:41:53,040 --> 00:41:56,040
那我们这边小于100万的记录，都会被删掉

642
00:41:59,250 --> 00:42:00,090
OK

643
00:42:00,180 --> 00:42:05,490
然后去这边观察一下他大概是按一个多少行数去

644
00:42:05,760 --> 00:42:06,570
构建

645
00:42:16,590 --> 00:42:17,190
我不知道

646
00:42:21,900 --> 00:42:22,500
我想知道

647
00:42:24,660 --> 00:42:27,630
看上去跟刚才的那个

648
00:42:28,740 --> 00:42:33,390
这次是两万的备注，这样就不太一样了，这边删除了一个

649
00:42:33,810 --> 00:42:35,190
类似5万的感觉

650
00:42:35,460 --> 00:42:38,010
那就是说我们那个开关是生效

651
00:42:40,890 --> 00:42:41,970
我不知道

652
00:42:44,490 --> 00:42:46,440
那这边已经清空了

653
00:42:46,740 --> 00:42:48,840
所有的数据，只剩下一行

654
00:42:48,990 --> 00:42:51,510
这样就是id等于100万的门槛

655
00:42:56,850 --> 00:42:58,740
那可以看到这行数据

656
00:43:03,150 --> 00:43:08,460
那这几个参数，实际上由于它比较危险啊，所以在tidb我们

657
00:43:08,465 --> 00:43:11,190
产品特制作了一个比较严格的限制

658
00:43:12,090 --> 00:43:15,450
举个例子来说，你不能把它设置为全局变量

659
00:43:17,460 --> 00:43:21,660
我们尝试把tidb，但是batch_insert开关设置了一个gloabl级别

660
00:43:21,665 --> 00:43:23,370
那就会收到一个报错

661
00:43:23,550 --> 00:43:26,220
说它是一个session变量

662
00:43:26,250 --> 00:43:28,110
不能被设gloabl

663
00:43:28,890 --> 00:43:31,920
另外一个参数，delete也是一样的

664
00:43:32,610 --> 00:43:34,110
也是有这样的限制

665
00:43:40,290 --> 00:43:43,830
控制batch，大小的这个参数batch_size

666
00:43:43,950 --> 00:43:47,940
也同样有着不能被设置为一个gloabl别变量的约束

667
00:43:48,660 --> 00:43:53,970
那就是为了保障我们全局的安全，如果你不小心在设置了一个全局的变量

668
00:43:54,660 --> 00:43:59,610
但他都通过batch_insert或batch_delete式来执行insert和delete语句

669
00:43:59,850 --> 00:44:04,140
那对其他的这种正常的事物的影响是非常大的

670
00:44:04,290 --> 00:44:05,520
他可能

671
00:44:05,610 --> 00:44:10,920
在超过你默认的两万行的时候，实际上还在我们30万kV的约束下是

672
00:44:10,925 --> 00:44:12,000
可以提交了

673
00:44:12,690 --> 00:44:16,200
如果你设置了个batch_size的，要全局去影响他

674
00:44:16,205 --> 00:44:21,510
就会导致他这个明明可以提交的大事，或者说还到

675
00:44:21,515 --> 00:44:23,550
不事务受限制的时候受不了

676
00:44:24,090 --> 00:44:27,810
就被强迫的拆成多个小事务两万块，两万块一条条

677
00:44:28,290 --> 00:44:33,600
这个危险性就是非常大的，如果中间断掉的话，实际上用户大概就是感知不到

678
00:44:35,670 --> 00:44:37,980
因此，我们做了这样的约束

679
00:44:42,240 --> 00:44:46,740
另外，我们来看一下，那我们尝试把这个

680
00:44:46,745 --> 00:44:49,470
batch_size调到30万

681
00:44:50,670 --> 00:44:54,930
大家知道sysbench，这张表什么，他是有一个额外的索引，所以我们来看一下

682
00:44:59,430 --> 00:45:03,300
看一下t8的表结构，她除了主键之外，还有一个，索引

683
00:45:03,510 --> 00:45:08,190
这个主键，他由于是整形的，因此她不占据一个额外的

684
00:45:08,340 --> 00:45:13,650
空间，也就是说不不不，不写入额外的kv可以因为特别组件经过转换

685
00:45:13,655 --> 00:45:16,290
之后就会是这张表的

686
00:45:16,440 --> 00:45:18,180
行业数据的

687
00:45:18,420 --> 00:45:19,590
特别的t

688
00:45:20,640 --> 00:45:22,050
和另外的一个

689
00:45:22,260 --> 00:45:27,570
手段啊，k做了另外一个，所以那这个所有手机上的额额外

690
00:45:27,575 --> 00:45:31,410
再有一个特例空间了，因此这种表要写的一个数据的话

691
00:45:31,530 --> 00:45:33,120
已经抢两次，可以呗？

692
00:45:33,690 --> 00:45:36,990
那我就得把这个dml_batch_size调到30万

693
00:45:37,170 --> 00:45:42,480
他们写入一行数据，要写两个kv，那这个三层的行一起交，实际上

694
00:45:42,570 --> 00:45:44,430
就会影响到60万kv

695
00:45:44,580 --> 00:45:46,980
0万kv，就会超过我们，限制

696
00:45:47,550 --> 00:45:49,050
我们来验证一下是不是这样？

697
00:45:56,940 --> 00:46:00,540
我们来执行一个delete的操作，把刚刚

698
00:46:00,780 --> 00:46:04,200
没有清空完数据的那个t8表

699
00:46:05,400 --> 00:46:07,620
数据来做一个清空

700
00:46:11,130 --> 00:46:14,460
那可以看到，这边报错了，因为他尝试以

701
00:46:14,820 --> 00:46:17,010
30万行

702
00:46:17,040 --> 00:46:18,840
为一个k去提交

703
00:46:19,170 --> 00:46:24,480
那这时候由于这个提交量特别大，然后他那个索引的话就达到了60万的kv

704
00:46:24,540 --> 00:46:28,620
还是会引起我们这个事务超限了这么一个报错

705
00:46:29,280 --> 00:46:31,740
呃，这个例子的是说

706
00:46:32,310 --> 00:46:37,050
我们这两个参数之间就说我们的dml_batch_size

707
00:46:37,055 --> 00:46:39,480
是没有和

708
00:46:39,600 --> 00:46:43,800
事务量做联动的，你可以把它设置到任意的值

709
00:46:44,250 --> 00:46:49,560
但是在后面还是有一个事务量，在约束，所以如果你要去设置它的话

710
00:46:49,565 --> 00:46:51,690
就这样控制着她

711
00:46:52,260 --> 00:46:56,190
控制在我们考虑索引情况下的30万以下

712
00:46:57,150 --> 00:47:02,460
我这个案例如果想去操作这个的话比较极限的操作是把这里设置为15万

713
00:47:03,510 --> 00:47:05,220
再加上索引就是30万

714
00:47:09,930 --> 00:47:10,530
我不知道

715
00:47:15,240 --> 00:47:20,550
那接下来我们把这个dml_batch_size改成为它的默认值两万

716
00:47:21,870 --> 00:47:23,940
尝试另一种写法

717
00:47:24,840 --> 00:47:29,040
刚刚我们用的都是这种自动去交的方法，自动技教育局

718
00:47:29,370 --> 00:47:32,550
现在我们用显示事务的方式来执行这种策略

719
00:47:34,590 --> 00:47:36,750
看一下t8表中

720
00:47:40,470 --> 00:47:42,420
数据大概有多少量？

721
00:47:51,870 --> 00:47:54,570
我可以他还有50万零一行的数据

722
00:47:59,280 --> 00:47:59,880
我不知道

723
00:48:02,130 --> 00:48:04,680
然后我们在这个显示的事务中

724
00:48:05,310 --> 00:48:06,900
执行那个的delete语句

725
00:48:09,270 --> 00:48:14,550
呃，由于事务还没有提交，我是没办法在其他的事务中去跟踪到他的进度

726
00:48:14,580 --> 00:48:16,500
可以看到，这边执行成功

727
00:48:16,590 --> 00:48:18,870
影响了50万行

728
00:48:19,680 --> 00:48:20,460
然后

729
00:48:20,610 --> 00:48:24,060
由于显示数目，你要做提交还是回滚的决定？

730
00:48:24,090 --> 00:48:25,770
这边我们选择了提交

731
00:48:27,570 --> 00:48:32,490
提交之后，我就会收到一个报错，就是说事务量过大

732
00:48:32,670 --> 00:48:36,930
这个时候，由于我们这个开关的适用范围，实际上只存在于

733
00:48:37,710 --> 00:48:43,020
自动提交的sql，对于非自动提交的sql，这些开关不生效，这个也是产品

734
00:48:43,025 --> 00:48:44,970
设计上的一个考虑

735
00:48:45,360 --> 00:48:47,010
是为了保护

736
00:48:47,130 --> 00:48:49,950
这些显示事务的安全

737
00:48:50,010 --> 00:48:51,240
因为我们

738
00:48:51,540 --> 00:48:53,130
大部分的这种

739
00:48:54,180 --> 00:48:59,100
业务请求过来的sql都是在显示事务去执行，很少有自从这张的情况

740
00:48:59,460 --> 00:49:00,990
也是多了一种保护

741
00:49:07,440 --> 00:49:12,750
刚刚收到的是我们提供了两个开关，嗯嗯，batch_insert，还有一个

742
00:49:12,900 --> 00:49:14,400
dbatch_size

743
00:49:14,490 --> 00:49:18,990
batch_update呢？这实际上是由于他会操作本身

744
00:49:19,290 --> 00:49:23,010
就很难被回滚，或者说你

745
00:49:23,880 --> 00:49:29,190
切换成小事务提交之后，反正我把他改回原值，因此我们为了

746
00:49:29,195 --> 00:49:30,210
整个

747
00:49:30,900 --> 00:49:36,210
数据的安全就没有提供这个开关，那对于update实际上

748
00:49:36,215 --> 00:49:40,320
要通过业务去sql，用之后来实现batch开关

749
00:49:40,710 --> 00:49:41,700
我们这边

750
00:49:41,790 --> 00:49:44,130
再举一下，一个分页sql的案例

751
00:49:45,240 --> 00:49:49,530
呃，由于这两张表数据量也不太够了，我们将切换到

752
00:49:50,430 --> 00:49:55,740
还是可以sbtest1表就是我这个是上次压测的一晚上的数据

753
00:49:55,920 --> 00:49:56,940
那个数据库

754
00:49:58,260 --> 00:50:03,420
然后看一下这张表的数据量，或者说这张表的数据大概长什么样？

755
00:50:04,890 --> 00:50:05,880
我不知道

756
00:50:09,870 --> 00:50:14,310
那这张表还只有100万的数据量然后他数据大概长这样

757
00:50:14,640 --> 00:50:17,910
我们要拿他的数据做一个update

758
00:50:18,630 --> 00:50:19,470
实验

759
00:50:22,260 --> 00:50:23,850
我们尝试吧！

760
00:50:24,330 --> 00:50:26,400
把，bat这个字段的值

761
00:50:26,910 --> 00:50:27,870
改掉

762
00:50:29,700 --> 00:50:35,010
那这是一个分页sql的案例，由于买mysql的语法中，后面

763
00:50:35,015 --> 00:50:36,870
没办法加

764
00:50:37,200 --> 00:50:42,510
limit，order by 然后在家页面大小这种语法，他只能在里面调一个页面卖

765
00:50:43,980 --> 00:50:45,330
下了雨吧那

766
00:50:45,360 --> 00:50:50,370
没办法，没办法加超赛我们就没办法直接的写出

767
00:50:50,490 --> 00:50:54,240
这种分页sql要通过这个where id in 

768
00:50:54,570 --> 00:50:59,580
然后在里面根据ID做分页的方式来写这个分页sql

769
00:50:59,610 --> 00:51:01,680
对对对，他这个要这个

770
00:51:01,685 --> 00:51:03,810
我们想要跟进到那个职位

771
00:51:05,250 --> 00:51:05,850
啊？

772
00:51:12,360 --> 00:51:15,120
ok，这样一个分页就可以提交了

773
00:51:15,270 --> 00:51:17,850
那么，只要反复的执行这个分页

774
00:51:20,160 --> 00:51:21,090
打打打打

775
00:51:22,050 --> 00:51:22,950
我知道

776
00:51:24,630 --> 00:51:26,250
就可以达成

777
00:51:26,670 --> 00:51:29,490
把update，大事务拆分的这么一个目标

778
00:51:36,720 --> 00:51:40,380
ok，这就是一个update改写成分页这么一个案例

779
00:51:40,470 --> 00:51:43,710
所谓的验证，我这边是不是生效可以在这边？

780
00:51:44,820 --> 00:51:46,080
另外一个窗口

781
00:51:46,800 --> 00:51:48,270
去做一个验证

782
00:51:58,890 --> 00:52:02,670
where条件就是那个pad等于我改成之后那个值

783
00:52:13,770 --> 00:52:15,330
你说我们谁做的？

784
00:52:19,320 --> 00:52:20,190
哎呀

785
00:52:20,700 --> 00:52:25,020
OK，可以看到刚刚我分三页每页1万行的方式

786
00:52:25,470 --> 00:52:30,780
作出了修改，而这边可以看到，3万行也改成了我的新的目标的

787
00:52:32,850 --> 00:52:36,390
接下来我们来看一下事务重试的一个实践

788
00:52:36,810 --> 00:52:42,120
tidb是基于客户的一个模型，然后再配mvcc

789
00:52:42,125 --> 00:52:44,850
来实现了事务的一个
790
00:52:45,510 --> 00:52:46,530
隔离

791
00:52:46,710 --> 00:52:49,140
或者说是实现了事务的acid

792
00:52:51,210 --> 00:52:56,520
在tidb中，由于完成mvcc的一个相关的特性，也就是说你得到的是

793
00:52:56,525 --> 00:52:59,220
这个版本就在一定时间内

794
00:52:59,280 --> 00:53:02,670
与已保留，然后超过，这个时间之后

795
00:53:03,210 --> 00:53:06,240
你所读到的之前的镜像就会被

796
00:53:06,600 --> 00:53:10,800
tidb去GC掉就是垃圾清除策略

797
00:53:13,200 --> 00:53:17,910
也是确保了我们的内存不会被持续的占的比较高

798
00:53:18,570 --> 00:53:23,880
这个案例需要做一个比较长时间的模拟，大家可以根据这里的

799
00:53:23,885 --> 00:53:25,830
方法去来

800
00:53:25,950 --> 00:53:28,350
手动来操作一个

801
00:53:28,470 --> 00:53:30,390
执行时间超过了

802
00:53:30,960 --> 00:53:32,370
GC限制的

803
00:53:32,430 --> 00:53:33,780
一个事务
804
00:53:33,990 --> 00:53:34,860
是吗？

805
00:53:36,240 --> 00:53:39,900
这边就不做一个

806
00:53:40,230 --> 00:53:41,580
现场的演练

807
00:53:41,610 --> 00:53:46,920
我们可以给大家来讲一下这张表，这张这GC控制的内容

808
00:53:46,925 --> 00:53:47,820
没有

809
00:53:54,780 --> 00:53:57,660
那家他们的名字叫做mysql.tidb

810
00:54:02,160 --> 00:54:04,320
能可以看到他有几行数据

811
00:54:05,190 --> 00:54:07,410
那影响gc

812
00:54:07,530 --> 00:54:10,980
啊，保留时间的最直接的这行

813
00:54:11,670 --> 00:54:15,210
variable_name叫做tikv_gc_file_time

814
00:54:15,810 --> 00:54:19,290
它的默认值是十分钟，也就是说，在十分钟内

815
00:54:19,350 --> 00:54:20,790
你开启了一个事

816
00:54:21,690 --> 00:54:23,070
我都保障了

817
00:54:23,400 --> 00:54:25,290
在这个十分钟之内

818
00:54:25,410 --> 00:54:27,990
也是能访问到这个历史上的数据的

819
00:54:27,995 --> 00:54:30,570
有超过十分钟之后，我是保障的

820
00:54:31,080 --> 00:54:36,090
具体他什么时候被gc掉，实际上是跟另外一个参数有关

821
00:54:36,210 --> 00:54:38,820
叫tikv_gc_run_interval

822
00:54:39,210 --> 00:54:42,480
她的默认值只是十分钟，然后这里面的实际上

823
00:54:42,540 --> 00:54:44,550
有游泳的实验作文的修改

824
00:54:44,610 --> 00:54:46,140
这个不是一个默认值

825
00:54:46,440 --> 00:54:51,750
tikv_gc_run_interval每隔多久，我的gc work就会工作

826
00:54:51,755 --> 00:54:52,560
不知道

827
00:54:52,710 --> 00:54:57,750
把那些已经超过或者达到了tikv机器来看的

828
00:54:58,170 --> 00:55:01,080
时间设置MV CC的版本

829
00:55:01,740 --> 00:55:03,420
给gc掉

830
00:55:04,200 --> 00:55:07,830
那也就是说，嗯，我这两个时间加起来

831
00:55:08,430 --> 00:55:12,750
肯定就是一个mvcc版本，最大能存留的时间

832
00:55:13,260 --> 00:55:15,090
我可能上一轮

833
00:55:15,240 --> 00:55:18,870
，设置了gc work，刚刚执行完

834
00:55:19,200 --> 00:55:24,390
当然执行完了，我开启了一个新的事务，那个事物我可能她都在这里测试十分钟

835
00:55:25,020 --> 00:55:28,770
在十分钟之后，只要我的下次word还没有工作

836
00:55:28,775 --> 00:55:30,360
我就不会被GC掉

837
00:55:30,630 --> 00:55:33,330
那具体什么时候GC，要等这个

838
00:55:33,360 --> 00:55:35,490
下一次run的时候才会被gc

839
00:55:37,980 --> 00:55:40,980
我这边可以看到上一次run的信息

840
00:55:41,520 --> 00:55:44,790
tikv_gc_last_run_time一个实践

841
00:55:44,910 --> 00:55:50,220
可以简单地通过这个实践来加上这个intervall，我来判断下一次gc work

842
00:55:50,225 --> 00:55:51,210
什么工作？

843
00:55:51,510 --> 00:55:52,620
可以判断了

844
00:55:52,830 --> 00:55:54,780
大概下一次

845
00:55:54,840 --> 00:55:59,880
即使gc work工作的时候，就要把当前已经达到gc来看的,gc版本主要干着

846
00:56:01,530 --> 00:56:06,720
而是这样一种机制，大家如果感兴趣的话，可以做一下页面上的实践

847
00:56:09,480 --> 00:56:14,790
继续来看，再去调的时候会影响到当前所有还没被gc的

848
00:56:14,795 --> 00:56:15,780
快照

849
00:56:15,900 --> 00:56:17,370
的版本

850
00:56:17,520 --> 00:56:18,630
这三个

851
00:56:20,430 --> 00:56:25,740
它在业务上的应用实际上一般都集中在

852
00:56:26,400 --> 00:56:31,710
去做全量备份的时候，比如mysqldump，做一个备份那你可以mysqldump脚本

853
00:56:31,715 --> 00:56:32,550
里面

854
00:56:32,700 --> 00:56:36,390
提前写好，把这个gc_life_time调整的比较长

855
00:56:36,510 --> 00:56:39,840
假设你这个全量备份要执行一个小时

856
00:56:39,990 --> 00:56:42,060
你这里面的安全，可以把？

857
00:56:42,600 --> 00:56:47,910
gc_life_time先调到三个小时，然后开始执行备份，当备份完成之后

858
00:56:48,780 --> 00:56:52,260
再去把gc_life_time，改为之前的值

859
00:56:52,500 --> 00:56:57,810
可能之前设置一条值，你可能想让它在业务正常运转的时候就保留一小时的快照

860
00:56:57,815 --> 00:56:58,980
就ok了
861
00:56:59,730 --> 00:57:02,070
大概是这么一种方式是比较推荐的

862
00:57:06,780 --> 00:57:07,380
我知道

863
00:57:08,070 --> 00:57:10,170
页面上面举了一个例子

864
00:57:10,470 --> 00:57:15,780
那可以通过调整这个mvcc信息保留的时间，把这条路比较长，然后

865
00:57:15,785 --> 00:57:19,080
再次模拟这个执行时间长了二分钟的sql

866
00:57:19,800 --> 00:57:25,110
这里为什么二分钟呢？因为就是刚刚所有的机器来看，加上gc_run

867
00:57:26,250 --> 00:57:27,660
他保障

868
00:57:28,020 --> 00:57:33,330
或者说，它确保一个事务在执行长达20分钟的时候，肯定就会被gc

869
00:57:33,335 --> 00:57:34,110
几点？

870
00:57:34,260 --> 00:57:38,430
那当你调长了他的gc来看，就是说

871
00:57:38,700 --> 00:57:44,010
gc ，让它们在1小时内都不会被干掉，那你就可以执行这个长达20

872
00:57:44,015 --> 00:57:45,090
分钟的sql

873
00:57:45,360 --> 00:57:47,820
这个大家感兴趣可以去做一下实验

874
00:57:48,870 --> 00:57:52,440
另外一个是写超时的限制

875
00:57:52,890 --> 00:57:58,200
tidb对于写超时是用另外一个参数来控制这个参数存在于

876
00:57:58,205 --> 00:58:00,900
tidb.??的配置文件里边儿

877
00:58:01,140 --> 00:58:03,450
就是说tidb

878
00:58:03,600 --> 00:58:05,610
那它叫做

879
00:58:06,030 --> 00:58:08,730
呃，??

880
00:58:10,590 --> 00:58:15,390
那具体需要调这个参数的场景不太多

881
00:58:15,690 --> 00:58:21,000
只有insert into select语句 ，当select语句

882
00:58:21,005 --> 00:58:22,590
已经超过了

883
00:58:24,210 --> 00:58:26,490
这个？？

884
00:58:26,670 --> 00:58:30,540
呃，这个参数，它的单位是秒么？默认值是590

885
00:58:30,870 --> 00:58:36,180
就是说这一个写事tidb有的默认590秒的最大

886
00:58:36,185 --> 00:58:36,960
限制

887
00:58:37,500 --> 00:58:40,710
那当这个写事务中的读取的部分

888
00:58:41,460 --> 00:58:45,090
就是insert into select ，中的select部分

889
00:58:45,360 --> 00:58:50,670
如果执行时间已经超过了写超时的限制，那由于它本质上是insert语句

890
00:58:51,270 --> 00:58:53,310
因此，那他就会

891
00:58:53,820 --> 00:58:55,080
被写超时

892
00:58:55,260 --> 00:58:58,140
可识别的，然后就会报出一个

893
00:58:58,380 --> 00:59:00,570
超事务 超时的这么一个宝凑

894
00:59:01,920 --> 00:59:04,290
那我们来看一下它具体的位置

895
00:59:09,000 --> 00:59:14,310
他在我的部署目录下我的部署目录叫data time_cluster_2.1

896
00:59:15,210 --> 00:59:16,920
在部署路径下

897
00:59:17,220 --> 00:59:18,900
呃呃，这个

898
00:59:18,905 --> 00:59:20,010
config文件夹

899
00:59:21,240 --> 00:59:24,840
那具体的文件就是tidb.toml

900
00:59:29,550 --> 00:59:30,150
我知道

901
00:59:35,310 --> 00:59:38,730
这里没有列出来说明他是一个隐藏参数

902
00:59:39,210 --> 00:59:44,520
我们可以把它配到刚刚提到的那个？？

903
00:59:49,230 --> 00:59:49,830
我不知道

904
00:59:53,190 --> 00:59:56,610
先找到tikv-client他这个分段

905
00:59:56,615 --> 00:59:57,270
不知道

906
00:59:58,350 --> 01:00:01,110
OK 然后只要加? 因为这就可以

907
01:00:05,820 --> 01:00:06,420
我不知道

908
01:00:13,740 --> 01:00:19,050
需要注意的一点是说这个参数必须要控制在tikv gc端

909
01:00:19,055 --> 01:00:21,300
配备必须让他知道

910
01:00:21,630 --> 01:00:26,940
那也就是说，他们准备什么时590秒，而不是600秒

911
01:00:27,090 --> 01:00:28,230
问问这个事儿

912
01:00:28,590 --> 01:00:30,360
十分钟也就600秒

913
01:00:30,870 --> 01:00:34,500
所以它的默认值被调低了十秒

914
01:00:35,190 --> 01:00:38,700
那当你的gc看为一小时的时候

915
01:00:38,705 --> 01:00:39,720
这里

916
01:00:39,810 --> 01:00:43,290
建议控制在一小时以内，可以是3590

917
01:00:50,070 --> 01:00:54,150
我们来重启一下tidb server来确认

918
01:00:54,990 --> 01:00:56,910
这个参数能否被识别

919
01:00:59,520 --> 01:01:04,830
我们选择了这个启动启停，脚本停止了，来去停止tidb sever

920
01:01:04,835 --> 01:01:06,240
看一下收入分笑

921
01:01:08,730 --> 01:01:12,900
我可以看到这时候tidb server已经被停掉，只能先把他启起来

922
01:01:17,610 --> 01:01:18,360
我不知道

923
01:01:20,490 --> 01:01:22,200
ok，现在才他启起来了

924
01:01:22,380 --> 01:01:23,460
我不知道

925
01:01:24,510 --> 01:01:28,380
那可以从tidb的一个变量中来读到

926
01:01:29,100 --> 01:01:30,300
配置文件的值

927
01:01:30,480 --> 01:01:31,500
我觉得

928
01:01:32,100 --> 01:01:32,700
我不知道

929
01:01:49,350 --> 01:01:52,440
这个变量的叫做

930
01:01:52,980 --> 01:01:54,480
tidb_conig

931
01:01:54,485 --> 01:01:57,030
你可以看到，这是它的值

932
01:01:57,840 --> 01:02:00,720
我们来找tidb_client他这一组

933
01:02:01,110 --> 01:02:06,120
我可以看到这个参数是被识别，也就是说是

934
01:02:06,210 --> 01:02:10,380
tidb支持的参数，也不过在模板中，我们把它隐藏掉

935
01:02:10,500 --> 01:02:12,960
因为认为去修改的话，比较危险

936
01:02:13,590 --> 01:02:16,440
只有当你非常明确它的作用之后

937
01:02:17,430 --> 01:02:22,740
并且你把它设置的比他地位提起来，他们要小，那这个时候才是安全可控

938
01:02:22,745 --> 01:02:23,370
他们

939
01:02:27,990 --> 01:02:33,300
接下来我们来看一下使用门户口外雨伞来保障，结果集稳定

940
01:02:34,440 --> 01:02:37,290
这里面需要用到一个

941
01:02:39,660 --> 01:02:43,740
早熟的脚本，这个脚本在

942
01:02:44,130 --> 01:02:46,080
ppt中是提供的

943
01:02:49,020 --> 01:02:51,390
我们来先切换到

944
01:02:51,960 --> 01:02:55,380
我的数据库之下，然后来执行这一条sql

945
01:03:00,690 --> 01:03:01,560
OK

946
01:03:02,790 --> 01:03:08,100
这个造数脚本大概就写两张表，然后通过两张表的关联的方式

947
01:03:08,850 --> 01:03:13,170
还去模拟这个复合y和c复合物

948
01:03:13,710 --> 01:03:16,170
第一条语句就是复合group by

949
01:03:16,650 --> 01:03:21,270
他查询了，可那class字段和stuname字段

950
01:03:21,275 --> 01:03:22,290
兵器

951
01:03:22,650 --> 01:03:23,610
对

952
01:03:23,700 --> 01:03:28,350
这个courscore做了一个最大值的聚合

953
01:03:29,520 --> 01:03:33,390
这边grop by也是 class 和stuname

954
01:03:33,395 --> 01:03:35,640
两个字段，那这是一个

955
01:03:36,000 --> 01:03:38,070
合法的group语法

956
01:03:38,370 --> 01:03:40,680
在mysql中提供另外一种语法

957
01:03:40,685 --> 01:03:45,990
也就是你select 一些字段，但你

958
01:03:45,995 --> 01:03:47,550
grop by一部分

959
01:03:48,540 --> 01:03:51,510
通过第一个数 group by语法我们可以看到

960
01:03:51,660 --> 01:03:55,020
class 和stuname 有三种不同的组合

961
01:03:55,650 --> 01:04:00,960
额，分别是一对应这个路飞，然后三对那个派大星

962
01:04:00,965 --> 01:04:03,810
然后三个用的海绵宝宝

963
01:04:04,470 --> 01:04:08,010
第二个语句，这个飞赴国外语法的话

964
01:04:08,190 --> 01:04:13,500
由于它只group by这个字段，那它是不同的组合，这个两种是一种

965
01:04:13,505 --> 01:04:14,970
一般都三班

966
01:04:15,360 --> 01:04:20,670
呃，由于三班有跟学生姓名两种不同的组合，具体删选一行

967
01:04:20,675 --> 01:04:21,600
去哪里啊？

968
01:04:22,200 --> 01:04:26,040
在tidb是不保障返回结果结构顺序

969
01:04:27,630 --> 01:04:31,920
也就是说，如果你想保障的话，就要？？语法去保障

970
01:04:33,180 --> 01:04:36,570
我们来反复的执行一下这条语句

971
01:04:38,070 --> 01:04:41,670
模拟一下，看是否能把另外一个事务给删掉了

972
01:04:45,090 --> 01:04:50,130
你这次没有成功，可能由于这两个位置都出现在了同一个tikv，为什么？

973
01:04:57,270 --> 01:04:58,080
不知道

974
01:05:05,910 --> 01:05:08,370
我们把数据清掉，重新来一遍

975
01:05:13,080 --> 01:05:13,680
我不知道

976
01:05:14,190 --> 01:05:17,670
那可以看到，这次模拟的时候就返回了不同的数据

977
01:05:18,270 --> 01:05:19,980
在mysql中

978
01:05:20,880 --> 01:05:26,190
如果你使用一个黑色荷花鱼塘，反复去执行这语句的时候，可能会看到

979
01:05:26,580 --> 01:05:31,890
一个看上去是稳定的结果，因为mysql一个单机的数据库

980
01:05:31,895 --> 01:05:33,660
刚刚我们第一次模拟的时候

981
01:05:33,780 --> 01:05:37,740
有可能那两个？？就做到了同一个tikv上面

982
01:05:38,700 --> 01:05:43,740
mysql，他们永远都是这种场景，就是说我所有的数据都来自一个单机

983
01:05:44,010 --> 01:05:45,540
他返回的？

984
01:05:46,230 --> 01:05:48,300
路径或者说

985
01:05:48,360 --> 01:05:50,370
通过索引也好会

986
01:05:50,610 --> 01:05:55,290
在一个短时间内看上去是一个恒定的结果

987
01:05:56,190 --> 01:05:59,850
那由于你语意并没有保障，我要返回哪一行？

988
01:05:59,855 --> 01:06:05,160
那是反派大星哪一行，还返回海绵宝宝那一行在语义上是不保证的

989
01:06:05,640 --> 01:06:09,300
又又由于tidb是一个分布系统，如果你这个表

990
01:06:09,480 --> 01:06:13,230
是跨了？，这两个？不在同一个tikv上

991
01:06:13,650 --> 01:06:17,640
由由于tidb的下面的tikv是分布式计算的

992
01:06:17,790 --> 01:06:22,200
具体哪个tikv为先返回这个主要的这一行数据？

993
01:06:22,620 --> 01:06:25,950
那是没有保障，没有异常的地方

994
01:06:28,050 --> 01:06:31,110
mysql中也提供了一个开关

995
01:06:32,820 --> 01:06:35,670
叫做sql_mode的中一个

996
01:06:38,700 --> 01:06:40,650
中的一处格外壮观

997
01:06:42,300 --> 01:06:45,750
我们来首先看一下当前的sql_mode是什么

998
01:06:46,230 --> 01:06:47,160
不知道

999
01:06:49,980 --> 01:06:51,690
那刚才是公共楼梯

1000
01:06:51,900 --> 01:06:53,160
我们来说

1001
01:06:53,640 --> 01:06:55,800
对当前的sql_mode，做出一个修改

1002
01:07:00,510 --> 01:07:01,110
我知道

1003
01:07:03,900 --> 01:07:08,100
除了这两个开关之外，我们再加入另外一个开关

1004
01:07:10,890 --> 01:07:13,320
就叫做??！

1005
01:07:14,550 --> 01:07:15,930
对对对

1006
01:07:16,590 --> 01:07:21,030
我们再来来查询一下，sql_mode，这时候就带着这个欧盟出口外的开关

1007
01:07:21,270 --> 01:07:26,400
那在执行??的语法的时候，就会收到一个报错

1008
01:07:26,970 --> 01:07:30,360
啊，这个报错是说你这条sql语句

1009
01:07:30,420 --> 01:07:35,160
和我这个sql_mode的数据被这个开关是不兼容的

1010
01:07:35,190 --> 01:07:37,800
比如说它在语法上做出了这个约束

1011
01:07:37,980 --> 01:07:40,830
一般的数据库也是由这种约束

1012
01:07:40,920 --> 01:07:42,990
他是不允许出现的出group by

1013
01:07:43,440 --> 01:07:45,180
因为是group by

1014
01:07:45,990 --> 01:07:48,960
就有很大的几率出现，结果集的不稳定

1015
01:07:49,200 --> 01:07:52,440
他在语义上是没办法保障结果集的稳定

1016
01:07:55,110 --> 01:07:59,400
那本篇tidbsql优化与业务实践

1017
01:07:59,580 --> 01:08:01,710
就讲解到这里，谢谢大家

1018
01:08:06,420 --> 01:08:07,020
我不知道
